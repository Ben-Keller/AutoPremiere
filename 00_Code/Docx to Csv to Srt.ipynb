{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "7e27f65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import docx\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from collections import defaultdict\n",
    "from difflib import SequenceMatcher, get_close_matches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45412874",
   "metadata": {},
   "source": [
    "<h3> Transcripts to CSVs </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "c4d795f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def clean_subtitle(text):\n",
    "    # Remove asterisks and text between brackets\n",
    "    text = re.sub(r'\\*|\\[.*?\\]', '', text)\n",
    "    text = re.sub(r'[\\u2012\\u2013\\u2014\\u2015]', '-', text)\n",
    "    text = text.replace(\";\",\":\")\n",
    "    return text.strip()\n",
    "\n",
    "def convert_language_to_csv(language, input_file, subtitles):\n",
    "    doc = docx.Document(input_file)\n",
    "    subtitle_block = \"\"\n",
    "    current_time_range = None\n",
    "    current_highlight_color = None\n",
    "    for paragraph in doc.paragraphs:\n",
    "        text = paragraph.text.strip()\n",
    "        text = clean_subtitle(text)  # Clean the subtitle text\n",
    "        # Check if the paragraph contains a time range\n",
    "        time_range_match = re.match(r'^(\\d+[:;]\\d+(?::\\d+){0,2}\\s*-\\s*\\d+[:;]\\d+(?::\\d+){0,2})\\s*\\**', text)\n",
    "        if time_range_match:\n",
    "            time_range = time_range_match.group(1)\n",
    "            # If there's a previous subtitle block, add it to the dictionary\n",
    "            if subtitle_block and current_time_range:\n",
    "                subtitles[current_time_range][language] = {\n",
    "                    \"text\": subtitle_block,\n",
    "                    \"highlight_color\": current_highlight_color,\n",
    "                    \"comments\": \"\"  # Initialize an empty \"Comments\" column\n",
    "                }\n",
    "            subtitle_block = \"\"\n",
    "            current_time_range = time_range\n",
    "            current_highlight_color = None  # Reset the highlight color for a new time range\n",
    "        else:\n",
    "            # Extract the highlight color for each run in the paragraph\n",
    "            for run in paragraph.runs:\n",
    "                if run.font.highlight_color is not None:\n",
    "                    current_highlight_color = run.font.highlight_color\n",
    "            subtitle_block += text + \"\\n\"\n",
    "\n",
    "    # Add the last subtitle block to the dictionary\n",
    "    if subtitle_block and current_time_range:\n",
    "        subtitles[current_time_range][language] = {\n",
    "            \"text\": subtitle_block,\n",
    "            \"highlight_color\": current_highlight_color,\n",
    "            \"comments\": \"\"  # Initialize an empty \"Comments\" column\n",
    "        }\n",
    "\n",
    "def interview_to_csv(input_files, output_csv_file):\n",
    "    # Initialize a dictionary to store subtitles for all languages\n",
    "    all_subtitles = defaultdict(lambda: defaultdict(str))\n",
    "\n",
    "    # Iterate through each language and convert to CSV\n",
    "    for language, input_file in input_files.items():\n",
    "        convert_language_to_csv(language, input_file, all_subtitles)\n",
    "\n",
    "    # Write the combined subtitles to the CSV file\n",
    "    with open(output_csv_file, 'w', newline='', encoding='utf-8') as f:\n",
    "        csv_writer = csv.writer(f)\n",
    "        # Write the header row\n",
    "        header = [\"Start Time\", \"End Time\"] + list(input_files.keys()) + [\"Highlight\", \"Comments\"]\n",
    "        csv_writer.writerow(header)\n",
    "        # Write the data rows with all languages stacked\n",
    "        for time_range, language_subtitles in all_subtitles.items():\n",
    "            try:\n",
    "                start_time, end_time = map(str.strip, time_range.split(\"-\"))\n",
    "                highlight_color = language_subtitles[list(input_files.keys())[0]][\"highlight_color\"]\n",
    "                row = [start_time, end_time] + [clean_subtitle(language_subtitles.get(lang, {\"text\": \"\"})[\"text\"]) for lang in input_files.keys()] + [highlight_color, \"\"]\n",
    "                csv_writer.writerow(row)\n",
    "            except:\n",
    "                print(\"broken: \", time_range)#,language_subtitles)\n",
    "\n",
    "    print(f\"Conversion completed. Data saved to {output_csv_file}\")\n",
    "\n",
    "# # Test\n",
    "# input_files = {\n",
    "#     \"English\": \"../02_Transcripts/Wayuu/Transcripts (EN)/dunas (EN).docx\",\n",
    "#     \"Spanish\": \"../02_Transcripts/Wayuu/Transcripts (ES)/dunas (ES).docx\"\n",
    "# }\n",
    "# output_csv_file = \"../04_Interview CSV/dunas.csv\"\n",
    "\n",
    "# # Convert all languages to CSV using the pipeline function\n",
    "# interview_to_csv(input_files, output_csv_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "d48d0dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weildler inside\n",
      "Conversion completed. Data saved to ../04_Interview CSV/Wayuu/weildler inside.csv\n",
      "neko urbana\n",
      "Conversion completed. Data saved to ../04_Interview CSV/Wayuu/neko urbana.csv\n",
      "abuelo pescador\n",
      "Conversion completed. Data saved to ../04_Interview CSV/Wayuu/abuelo pescador.csv\n",
      "abuela pescadora\n",
      "Conversion completed. Data saved to ../04_Interview CSV/Wayuu/abuela pescadora.csv\n",
      "tejedora abuela\n",
      "Conversion completed. Data saved to ../04_Interview CSV/Wayuu/tejedora abuela.csv\n",
      "joaquin\n",
      "Conversion completed. Data saved to ../04_Interview CSV/Wayuu/joaquin.csv\n",
      "healing woman\n",
      "Conversion completed. Data saved to ../04_Interview CSV/Wayuu/healing woman.csv\n",
      "pinta abuela\n",
      "Conversion completed. Data saved to ../04_Interview CSV/Wayuu/pinta abuela.csv\n",
      "salinero oscar\n",
      "Conversion completed. Data saved to ../04_Interview CSV/Wayuu/salinero oscar.csv\n",
      "magalys hammock\n",
      "Conversion completed. Data saved to ../04_Interview CSV/Wayuu/magalys hammock.csv\n",
      "neko father\n",
      "Conversion completed. Data saved to ../04_Interview CSV/Wayuu/neko father.csv\n",
      "neko piedra\n",
      "Conversion completed. Data saved to ../04_Interview CSV/Wayuu/neko piedra.csv\n",
      "palabrero luis\n",
      "Conversion completed. Data saved to ../04_Interview CSV/Wayuu/palabrero luis.csv\n",
      "weildler outside\n",
      "Conversion completed. Data saved to ../04_Interview CSV/Wayuu/weildler outside.csv\n",
      "ana weaving\n",
      "Conversion completed. Data saved to ../04_Interview CSV/Wayuu/ana weaving.csv\n",
      "weildler pre\n",
      "Conversion completed. Data saved to ../04_Interview CSV/Wayuu/weildler pre.csv\n",
      "magalys electrico\n",
      "Conversion completed. Data saved to ../04_Interview CSV/Wayuu/magalys electrico.csv\n",
      "neko weaving\n",
      "Conversion completed. Data saved to ../04_Interview CSV/Wayuu/neko weaving.csv\n",
      "romelia\n",
      "Conversion completed. Data saved to ../04_Interview CSV/Wayuu/romelia.csv\n",
      "wolunka\n",
      "Conversion completed. Data saved to ../04_Interview CSV/Wayuu/wolunka.csv\n",
      "eliana\n",
      "Conversion completed. Data saved to ../04_Interview CSV/Wayuu/eliana.csv\n",
      "salinero young\n",
      "Conversion completed. Data saved to ../04_Interview CSV/Wayuu/salinero young.csv\n",
      "dunas\n",
      "Conversion completed. Data saved to ../04_Interview CSV/Wayuu/dunas.csv\n"
     ]
    }
   ],
   "source": [
    "#run the processing pipeline overall interviews\n",
    "\n",
    "transcripts_dir = \"../02_Transcripts/Wayuu/\"\n",
    "\n",
    "def get_languages_and_interviews(transcripts_dir):\n",
    "    interviews_dict = {}  # Dictionary to store interviews and their languages and file paths\n",
    "\n",
    "    for language_folder in os.listdir(transcripts_dir):\n",
    "        language_dir_path = os.path.join(transcripts_dir, language_folder)\n",
    "        \n",
    "        # Check if it's a valid language folder (e.g., \"Transcripts (EN)\")\n",
    "        if os.path.isdir(language_dir_path) and language_folder.startswith(\"Transcripts (\"):\n",
    "            language = language_folder.split(\" (\")[1].split(\")\")[0]\n",
    "            \n",
    "            for interview_file in os.listdir(language_dir_path):\n",
    "                if interview_file.endswith(\".docx\") and not os.path.basename(interview_file).startswith(\"~$\"):\n",
    "                    interview_name, ext = os.path.splitext(interview_file)\n",
    "                    interview_code = interview_name.split(\"(\")[0].strip().lower()  # Extract the interview code (e.g., \"dunas\")\n",
    "                    interview_path = os.path.join(language_dir_path, interview_file)\n",
    "                    \n",
    "                    # Create or update the entry for this interview code\n",
    "                    if interview_code not in interviews_dict:\n",
    "                        interviews_dict[interview_code] = {}\n",
    "                    \n",
    "                    # Append language and file path to the input_files dictionary\n",
    "                    interviews_dict[interview_code][language] = interview_path\n",
    "\n",
    "    return interviews_dict    \n",
    "\n",
    "def process_all_interviews(transcripts_dir, output_csv_dir):\n",
    "    # Get the combined dictionary of languages and interviews\n",
    "    interviews_dict = get_languages_and_interviews(transcripts_dir)\n",
    "    \n",
    "    for interview_code in interviews_dict.keys():\n",
    "        print(interview_code)\n",
    "        # Process the interview using the input_files and interview_code\n",
    "        output_csv_file = os.path.join(output_csv_dir, f\"{interview_code}.csv\")\n",
    "        interview_to_csv(interviews_dict[interview_code], output_csv_file)\n",
    "        \n",
    "\n",
    "# Output directory for CSV files\n",
    "output_csv_dir = \"../04_Interview CSV/Wayuu/\"\n",
    "\n",
    "# Process all interviews in the transcripts directory\n",
    "process_all_interviews(transcripts_dir, output_csv_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64031e0b",
   "metadata": {},
   "source": [
    "<h3>CSVs to SRTs</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "a71ce7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../04_Interview CSV/Wayuu/salinero oscar.csv\n",
      "['EN', 'ES']\n",
      "../04_Interview CSV/Wayuu/dunas.csv\n",
      "['EN', 'ES']\n",
      "../04_Interview CSV/Wayuu/Neko piedra.csv\n",
      "['EN', 'ES']\n",
      "../04_Interview CSV/Wayuu/tejedora abuela.csv\n",
      "['EN', 'ES']\n",
      "../04_Interview CSV/Wayuu/Ana weaving.csv\n",
      "['EN', 'ES']\n",
      "../04_Interview CSV/Wayuu/Healing Woman.csv\n",
      "['EN', 'ES']\n",
      "../04_Interview CSV/Wayuu/Wolunka.csv\n",
      "['EN', 'ES']\n",
      "../04_Interview CSV/Wayuu/Magalys electrico.csv\n",
      "['EN', 'ES']\n",
      "../04_Interview CSV/Wayuu/abuela pescadora.csv\n",
      "['EN', 'ES']\n",
      "../04_Interview CSV/Wayuu/romelia.csv\n",
      "['EN', 'ES']\n",
      "../04_Interview CSV/Wayuu/Neko weaving.csv\n",
      "['EN', 'ES']\n",
      "../04_Interview CSV/Wayuu/neko father.csv\n",
      "['EN', 'ES']\n",
      "../04_Interview CSV/Wayuu/Joaquin.csv\n",
      "['EN', 'ES']\n",
      "../04_Interview CSV/Wayuu/Neko urbana.csv\n",
      "['EN', 'ES']\n",
      "../04_Interview CSV/Wayuu/salinero young.csv\n",
      "['EN', 'ES']\n",
      "../04_Interview CSV/Wayuu/Eliana.csv\n",
      "['EN', 'ES']\n",
      "../04_Interview CSV/Wayuu/weildler pre.csv\n",
      "['EN', 'ES']\n",
      "../04_Interview CSV/Wayuu/Abuelo pescador.csv\n",
      "['EN', 'ES']\n",
      "../04_Interview CSV/Wayuu/pinta abuela.csv\n",
      "['EN', 'ES']\n",
      "../04_Interview CSV/Wayuu/weildler outside.csv\n",
      "['EN', 'ES']\n",
      "../04_Interview CSV/Wayuu/palabrero luis.csv\n",
      "['EN', 'ES']\n",
      "../04_Interview CSV/Wayuu/weildler inside.csv\n",
      "['EN', 'ES']\n",
      "../04_Interview CSV/Wayuu/Magalys Hammock.csv\n",
      "['EN', 'ES']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Input and output directories\n",
    "csv_dir = \"../04_Interview CSV/Wayuu/\"\n",
    "subtitles_dir = \"../05_Subtitles/Wayuu/\"\n",
    "\n",
    "# Function to convert a CSV file to SRT for multiple languages\n",
    "def csv_to_srt_multiple_languages(csv_file):\n",
    "    print(csv_file)\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    # Get the language columns dynamically (excluding specific columns)\n",
    "    exclude_columns = [\"Start Time\", \"End Time\", \"Highlight\", \"Comments\"]\n",
    "    language_columns = [col for col in df.columns if col not in exclude_columns]\n",
    "    \n",
    "    print(language_columns)\n",
    "\n",
    "    # Initialize a dictionary to store lines for each language\n",
    "    language_srt_lines = {col: [] for col in language_columns}\n",
    "    combined_srt_lines = []\n",
    "    counter = 1\n",
    "\n",
    "    # Loop through each row in the CSV\n",
    "    for index, row in df.iterrows():\n",
    "        # Format the timestamps in SRT format\n",
    "        start_time = f\"{counter}\\n{row['Start Time'].replace('.', ',')} --> {row['End Time'].replace('.', ',')}\"\n",
    "\n",
    "        # Append the text for each language to their respective lines\n",
    "        for lang in language_columns:\n",
    "            language_srt_lines[lang].append(start_time)\n",
    "            language_srt_lines[lang].append(f\"{row[lang]}\\n\")\n",
    "\n",
    "        # Append the text to the combined SRT\n",
    "        combined_srt_lines.append(start_time)\n",
    "        combined_srt_lines.append('\\n----\\n'.join([str(row[lang]) for lang in language_columns]) + '\\n')\n",
    "\n",
    "        # Increment the counter\n",
    "        counter += 1\n",
    "\n",
    "    # Determine the output SRT file paths for combined and individual SRTs\n",
    "    base_filename = os.path.splitext(os.path.basename(csv_file))[0]\n",
    "    combined_langs = '-'.join(language_columns)\n",
    "    combined_srt_filename = f\"{base_filename} ({combined_langs}).srt\"\n",
    "    combined_srt_dir = os.path.join(subtitles_dir,\"SRT Export (\"+combined_langs+\")\")\n",
    "    os.makedirs(combined_srt_dir, exist_ok=True)\n",
    "\n",
    "    combined_srt_path= os.path.join(combined_srt_dir, combined_srt_filename)\n",
    "\n",
    "    # Create the folder for combined SRT\n",
    "    os.makedirs(subtitles_dir, exist_ok=True)\n",
    "\n",
    "    # Write the combined SRT file\n",
    "    with open(combined_srt_path, 'w', encoding='utf-8') as combined_srt_file:\n",
    "        combined_srt_file.write('\\n'.join(combined_srt_lines))\n",
    "\n",
    "    # Create folders for each language and write the individual SRT files\n",
    "    for lang in language_columns:\n",
    "        lang_output_dir = os.path.join(subtitles_dir, f\"SRT Export ({lang})\")\n",
    "        os.makedirs(lang_output_dir, exist_ok=True)\n",
    "        lang_srt_filename = f\"{base_filename} ({lang}).srt\"\n",
    "        lang_srt_path = os.path.join(lang_output_dir, lang_srt_filename)\n",
    "        with open(lang_srt_path, 'w', encoding='utf-8') as lang_srt_file:\n",
    "            lang_srt_file.write('\\n'.join(language_srt_lines[lang]))\n",
    "\n",
    "    #print(f'Combined SRT file \"{combined_srt_path}\" and individual SRT files have been created.')\n",
    "\n",
    "\n",
    "# Process all CSV files in the input directory\n",
    "for filename in os.listdir(csv_dir):\n",
    "    if filename.endswith('.csv'):\n",
    "        csv_file = os.path.join(csv_dir, filename)\n",
    "        csv_to_srt_multiple_languages(csv_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64b3435",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45fba496",
   "metadata": {},
   "source": [
    "<h3> Check status of txts, csv, xmls, srts </h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "6917d109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   EN Transcripts  ES Transcripts  EN Subs  ES Subs   XMLs  \\\n",
      "code                                                                         \n",
      "magalys hammock              True            True     True     True   True   \n",
      "palabrero luis               True            True     True     True   True   \n",
      "weildler pre                 True            True     True     True  False   \n",
      "tejedora abuela              True            True     True     True   True   \n",
      "pinta abuela                 True            True     True     True   True   \n",
      "salinero oscar               True            True     True     True   True   \n",
      "neko weaving                 True            True     True     True   True   \n",
      "eliana                       True            True     True     True   True   \n",
      "salinero young               True            True     True     True   True   \n",
      "romelia                      True            True     True     True   True   \n",
      "neko piedra                  True            True     True     True   True   \n",
      "dunas                        True            True     True     True  False   \n",
      "ana weaving                  True            True     True     True   True   \n",
      "healing woman                True            True     True     True   True   \n",
      "wolunka                      True            True     True     True   True   \n",
      "weildler inside              True            True     True     True   True   \n",
      "abuela pescadora             True            True     True     True   True   \n",
      "joaquin                      True            True     True     True   True   \n",
      "abuelo pescador              True            True     True     True   True   \n",
      "weildler outside             True            True     True     True   True   \n",
      "neko father                  True            True     True     True   True   \n",
      "neko urbana                  True            True     True     True   True   \n",
      "magalys electrico            True            True     True     True   True   \n",
      "\n",
      "                   Undefined Count  \n",
      "code                                \n",
      "magalys hammock                  0  \n",
      "palabrero luis                   0  \n",
      "weildler pre                     5  \n",
      "tejedora abuela                  0  \n",
      "pinta abuela                     0  \n",
      "salinero oscar                   0  \n",
      "neko weaving                     0  \n",
      "eliana                           0  \n",
      "salinero young                   0  \n",
      "romelia                          0  \n",
      "neko piedra                      0  \n",
      "dunas                            0  \n",
      "ana weaving                     35  \n",
      "healing woman                    0  \n",
      "wolunka                          0  \n",
      "weildler inside                  0  \n",
      "abuela pescadora                 0  \n",
      "joaquin                          0  \n",
      "abuelo pescador                  0  \n",
      "weildler outside                 0  \n",
      "neko father                      0  \n",
      "neko urbana                     15  \n",
      "magalys electrico                0  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "def getCodesPresent(folderpath,ext):\n",
    "    codes = []\n",
    "    for filename in os.listdir(folderpath):\n",
    "        if filename.endswith(ext) and os.path.getsize(os.path.join(folderpath,filename))>1000:\n",
    "            code=filename.lower().split(ext.lower())[0].strip()\n",
    "            codes.append(code)\n",
    "    return codes\n",
    "\n",
    "enTexts=getCodesPresent('../02_Transcripts/Wayuu/Transcripts (EN)/',' (EN).docx')\n",
    "esTexts=getCodesPresent('../02_Transcripts/Wayuu/Transcripts (ES)/',' (ES).docx')\n",
    "xmls=getCodesPresent('../03_Interview XML/Wayuu/','- synced.xml')\n",
    "enSubs=getCodesPresent('../05_Subtitles/Wayuu/SRT Export (EN)/',' (EN).srt')\n",
    "esSubs=getCodesPresent('../05_Subtitles/Wayuu/SRT Export (ES)/',' (ES).srt')\n",
    "\n",
    "def getUndefinedCount(code):\n",
    "    try:\n",
    "        docx_file='../02_Transcripts/Wayuu/Transcripts (EN)/'+code+' (EN).docx'  \n",
    "        search_string=\"xxx\"\n",
    "        count = 0\n",
    "        # Load the DOCX document\n",
    "        doc = docx.Document(docx_file)\n",
    "        # Iterate through paragraphs and search for the string (case-insensitive)\n",
    "        for paragraph in doc.paragraphs:\n",
    "            if search_string.lower() in paragraph.text.lower():\n",
    "                count += paragraph.text.lower().count(search_string.lower())\n",
    "        return count\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "lists_dict ={\"EN Transcripts\":enTexts,\n",
    "            \"ES Transcripts\":esTexts,\n",
    "            \"EN Subs\":enSubs,\n",
    "            \"ES Subs\":esSubs,\n",
    "            \"XMLs\":xmls}\n",
    "    \n",
    "\n",
    "# Create a DataFrame with unique codes\n",
    "unique_codes = list(set(code for sublist in lists_dict.values() for code in sublist))\n",
    "df = pd.DataFrame({'code': unique_codes})\n",
    "\n",
    "# Add columns for each list with True/False values\n",
    "for list_name, code_list in lists_dict.items():\n",
    "    df[list_name] = df['code'].isin(code_list)\n",
    "\n",
    "# Add column for count of XXX in document    \n",
    "df[\"Undefined Count\"]=df[\"code\"].apply(getUndefinedCount)\n",
    "    \n",
    "# Set 'code' as the index\n",
    "df.set_index('code', inplace=True)\n",
    " \n",
    "# Print the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6752946b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c751b5c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5710b4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d7bb8fc",
   "metadata": {},
   "source": [
    "<h3> Convert Script to Csv </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951d6f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_transcript_csvs(folder_path):\n",
    "\n",
    "    # Get a list of all CSV files in the folder\n",
    "    csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "    # Initialize an empty DataFrame\n",
    "    concatenated_df = pd.DataFrame()\n",
    "\n",
    "    # Iterate through CSV files and concatenate them\n",
    "    for csv_file in csv_files:\n",
    "        interview_code = os.path.splitext(csv_file)[0]  # Extract interview code from file name\n",
    "        csv_path = os.path.join(folder_path, csv_file)\n",
    "        df = pd.read_csv(csv_path)\n",
    "\n",
    "        # Add an \"Interview\" column with the interview code\n",
    "        df['Interview'] = interview_code\n",
    "\n",
    "        # Concatenate the dataframes\n",
    "        concatenated_df = pd.concat([concatenated_df, df], ignore_index=True)\n",
    "\n",
    "    return concatenated_df\n",
    "\n",
    "# Example usage:\n",
    "folder_path = \"../04_Interview CSV/Wayuu/\"\n",
    "concatenated_transcripts = concatenate_transcript_csvs(folder_path)\n",
    "print(concatenated_transcripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "1fb53e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Start Time End Time                                                 EN  \\\n",
      "0       00:00    00:02                           Where are you from Neko?   \n",
      "1       00:03    00:06                I am from a territory called Akualü   \n",
      "2       00:07    00:10                Although the elders call it Manaure   \n",
      "3       00:11    00:16  Ah, you came from the wild west and now you're...   \n",
      "4       00:18    00:21  In Nazareth or township of Nazareth as they ca...   \n",
      "5       00:22    00:30  We are in the territory of Usijou´, in Alewalü...   \n",
      "6       00:31    00:36  Yes, it is the only one with some characterist...   \n",
      "7       00:39    00:45  Yes of course. My grandmother and my mother's ...   \n",
      "8       00:47    00:51  Where is the sea? If over there, from here you...   \n",
      "9       00:52    00:56               Yes it's true.\\nYes, they lived here   \n",
      "10      00:57    01:01  But is the sea far from here? Yes, it's far away.   \n",
      "11      01:02    01:09  They said they moved, they had left their\\nthi...   \n",
      "12      01:10    01:18  There where the pieces of amuchi (ceramics) ar...   \n",
      "13      01:19    01:27  They decided to go to the seashore because\\nTh...   \n",
      "14      01:28    01:33  Then they left, but they came back again. Yeah...   \n",
      "15      01:35    01:42  This was what you were talking about, right? Y...   \n",
      "16      01:43    01:49  You can't touch it, you can only see it. If yo...   \n",
      "17      01:51    01:50  When you touch it you take away the energies o...   \n",
      "18      02:00    02:02                        Same with your arrival here   \n",
      "19      02:03    02:09  TRUE. You had to harmonize with the territory ...   \n",
      "20      02:10    02:18  This belonged to them right? Yes, that's why t...   \n",
      "21      02:21    02:28  This was their territory and they said that no...   \n",
      "22      02:29    02:36       Then we, the Pausayu, arrived to inhabit it.   \n",
      "23      02:37    02:40  I understand. And what did they bring from the...   \n",
      "24      02:41    02:46  The sand, they threw it here so that it would ...   \n",
      "25      02:47    02:53  That is, they brought the sand from the beach ...   \n",
      "26      02:56    03:03  The old people say that through a dream they w...   \n",
      "27      03:04    03:07  I'm telling you so you can say it, this part\\n...   \n",
      "28      03:08    03:12  Guille said that in the dream they were told\\n...   \n",
      "29      03:13    03:18  That, if they loved this land so much, they co...   \n",
      "30      03:19    03:26  and that's what they did. This is how this pla...   \n",
      "31      03:27    03:34  You could say that. That started from a dream\\...   \n",
      "32      03:39    03:48  So they brought him here, right? Yeah.\\nThey b...   \n",
      "33      03:49    03:58  As you can see this before this was small, but...   \n",
      "34      03:59    04:05  Yes, now I understand. How nice to know the hi...   \n",
      "35      04:06    04:10  Yes of course, in fact, all this that is here\\...   \n",
      "36      04:13    04:21  Yeah. It is very good to make known what\\nwe h...   \n",
      "37      04:22    04:29  You will already know that this place exists i...   \n",
      "38      04:30    04:37  Through stories like these you will learn not ...   \n",
      "39      04:38    04:45  Since there are also many jewels of\\nthe deceased   \n",
      "40      04:46    04:52  That is why it is a sacred place because here ...   \n",
      "41      04:55    05:03  People say that here in the north is where\\nar...   \n",
      "42      05:04    05:07  And that is why it is important to make them k...   \n",
      "43      05:08    05:15  Well, thank you very much for what you shared ...   \n",
      "44      05:16    05:20       For coming from so far to know our territory   \n",
      "45      05:22    05:29  After winter it doesn't bloom here? No,\\nDoes ...   \n",
      "46      05:30    05:38  The animals walk and do not get their paws wet...   \n",
      "47      05:39    05:45  And if it rains a lot? It may rain a lot but s...   \n",
      "48      05:46    05:47                            The territory is sacred   \n",
      "49      05:48    05:55  That was destined. Yes, that's why they were c...   \n",
      "50      05:56    06:02  People who come to Nazareth say that their\\nan...   \n",
      "51      06:03    06:11  Those from Dusakawi (health association) said ...   \n",
      "52      06:14    06:22  They say they will come back here again.\\nYes,...   \n",
      "53      06:23    06:31  I think it's good that they come again so that...   \n",
      "54      06:32    06:39  Yes, we have to arrive earlier, look, they are...   \n",
      "55      06:40    06:47  Because it is already getting dark and we alre...   \n",
      "56      06:48    06:50            You are in Alewalü in the Alewalü Dunes   \n",
      "57      06:51    06:54              Smile smile. Stretch your hands. That   \n",
      "58      06:57    07:01  That, that raise your hands, aha say hello, sa...   \n",
      "59      07:02    07:03                                            Alewalu   \n",
      "\n",
      "                                                   ES         Highlight  \\\n",
      "0                                ¿De dónde eres Neko?               NaN   \n",
      "1                 Soy de un territorio llamado Akualü  BRIGHT_GREEN (4)   \n",
      "2             Aunque los mayores lo denominan Manaure  BRIGHT_GREEN (4)   \n",
      "3      Ah, vienes del lejano oeste y ahora estas aquí  BRIGHT_GREEN (4)   \n",
      "4   En Nazareth o corregimiento de Nazareth como l...               NaN   \n",
      "5   Estamos en el territorio de Usijou´, en Alewal...               NaN   \n",
      "6   Si, es el único con unas características\\nnatu...               NaN   \n",
      "7   Si claro. De aquí era mi abuela y la abuela de...               NaN   \n",
      "8   ¿Por dónde está el mar? si por allá, de aquí s...               NaN   \n",
      "9                Si es verdad.\\nSi, ellos vivían aquí               NaN   \n",
      "10   ¿pero el mar esta lejos de aquí? Si, está lejos.               NaN   \n",
      "11  Ellos dijeron que se mudaron, habían dejado su...               NaN   \n",
      "12  Ahí donde están los trozos de amuchi (cerámica...               NaN   \n",
      "13  Ellos decidieron irse para la orilla del mar p...               NaN   \n",
      "14  Entonces se fueron, pero regresaron otra vez. ...               NaN   \n",
      "15  Esto era de lo que hablabas ¿no? Si.\\n¿puedo t...               NaN   \n",
      "16  No lo puedes tocar, solo puedes verlo. Si lo t...               NaN   \n",
      "17  Al tocarlo te llevas las energías de los muert...               NaN   \n",
      "18                          Igual con tu llegada aquí               NaN   \n",
      "19  Cierto. Debiste armonizar con el territorio po...               NaN   \n",
      "20  ¿Esto pertenecía a ellos no? Si, por eso sus a...               NaN   \n",
      "21  Este era su territorio y ellos decían que nadi...               NaN   \n",
      "22  Después llegamos nosotros los Pausayu para hab...               NaN   \n",
      "23      Entiendo. Y ¿Qué fue lo que trajeron del mar?               NaN   \n",
      "24  La arena, ellos lo echaban aquí para que queda...               NaN   \n",
      "25  Es decir, que ellos traían la arena de la play...               NaN   \n",
      "26  Dicen los viejos que a través de un sueño les ...               NaN   \n",
      "27  Te lo digo para que lo digas, esta parte\\ndesp...               NaN   \n",
      "28  Guille decía que en el sueño a ellos les dijer...               NaN   \n",
      "29  Que, si amaban tanto esta tierra, podían traer...               NaN   \n",
      "30  y eso hicieron. Así es como se origino este lugar               NaN   \n",
      "31  Podrías decir eso. Que comenzó desde un sueño\\...               NaN   \n",
      "32  Entonces lo trajeron aquí ¿no? Si.\\nLo traían ...               NaN   \n",
      "33  Como puedes ver esto antes esto era pequeño, p...               NaN   \n",
      "34  Si, ahora comprendo. Que lindo conocer la hist...               NaN   \n",
      "35  Si claro, de hecho, todo esto que está aquí\\nt...               NaN   \n",
      "36  si. Es muy bueno dar a conocer lo que\\ntenemos...               NaN   \n",
      "37  Ya sabrán que en La Guajira existe este lugar,...               NaN   \n",
      "38  A través de historias como estas conocerán no ...               NaN   \n",
      "39  Ya que aquí también se encuentran muchas joyas...               NaN   \n",
      "40  Por eso es un lugar sagrado porque aquí están ...               NaN   \n",
      "41  Las personas dicen que aquí en el norte es don...               NaN   \n",
      "42  Y por eso es importante darlos a conocer. Si c...               NaN   \n",
      "43  Bueno, muchas gracias por lo que nos compartis...               NaN   \n",
      "44  Por venir desde tan lejos para conocer nuestro...               NaN   \n",
      "45  ¿Después del invierno no florece aquí? No,\\n¿s...               NaN   \n",
      "46  los animales caminan y no se mojan las patas.\\...               NaN   \n",
      "47  Y si ¿llueve mucho? Puede que llueva mucho per...               NaN   \n",
      "48                           El territorio es sagrado               NaN   \n",
      "49  Eso estaba destinado. Si, por eso los crearon ...               NaN   \n",
      "50  Las personas que vienen a Nazareth dicen que s...               NaN   \n",
      "51  Los de Dusakawi (asociación en salud), dijeron...               NaN   \n",
      "52  Ellos dicen que volverán otra vez por aquí.\\nS...               NaN   \n",
      "53  Me parece bien que vengan de nuevo para que\\nc...               NaN   \n",
      "54  Si, tenemos que llegar mas temprano, mira que ...               NaN   \n",
      "55  Porque ya se está haciendo de noche y ya tenem...               NaN   \n",
      "56           Estas en Alewalü en las Dunas de Alewalü               NaN   \n",
      "57              Sonríe, sonríe. Estira las manos. Eso               NaN   \n",
      "58   Eso, eso levanten las manos, aja saluda, saluda.               NaN   \n",
      "59                                            Alewalü               NaN   \n",
      "\n",
      "    Comments  \n",
      "0        NaN  \n",
      "1        NaN  \n",
      "2        NaN  \n",
      "3        NaN  \n",
      "4        NaN  \n",
      "5        NaN  \n",
      "6        NaN  \n",
      "7        NaN  \n",
      "8        NaN  \n",
      "9        NaN  \n",
      "10       NaN  \n",
      "11       NaN  \n",
      "12       NaN  \n",
      "13       NaN  \n",
      "14       NaN  \n",
      "15       NaN  \n",
      "16       NaN  \n",
      "17       NaN  \n",
      "18       NaN  \n",
      "19       NaN  \n",
      "20       NaN  \n",
      "21       NaN  \n",
      "22       NaN  \n",
      "23       NaN  \n",
      "24       NaN  \n",
      "25       NaN  \n",
      "26       NaN  \n",
      "27       NaN  \n",
      "28       NaN  \n",
      "29       NaN  \n",
      "30       NaN  \n",
      "31       NaN  \n",
      "32       NaN  \n",
      "33       NaN  \n",
      "34       NaN  \n",
      "35       NaN  \n",
      "36       NaN  \n",
      "37       NaN  \n",
      "38       NaN  \n",
      "39       NaN  \n",
      "40       NaN  \n",
      "41       NaN  \n",
      "42       NaN  \n",
      "43       NaN  \n",
      "44       NaN  \n",
      "45       NaN  \n",
      "46       NaN  \n",
      "47       NaN  \n",
      "48       NaN  \n",
      "49       NaN  \n",
      "50       NaN  \n",
      "51       NaN  \n",
      "52       NaN  \n",
      "53       NaN  \n",
      "54       NaN  \n",
      "55       NaN  \n",
      "56       NaN  \n",
      "57       NaN  \n",
      "58       NaN  \n",
      "59       NaN  \n",
      "We are in the territory of Usijou´, in Alewalü.\n",
      "I don't know if you've heard that it's a sacred place. We are in the territory of Usijou´, in Alewalü.\n",
      "22.0 25.686274509803923 0.0784313725490196 0\n",
      "We are in the territory of Usijou´, in Alewalü.\n",
      "I don't know if you've heard that it's a sacred place. I don't know if you've heard that it's a sacred place.\n",
      "25.686274509803923 29.92156862745098 0.0784313725490196 47\n",
      "Yes of course. My grandmother and my mother's grandmother were from here. Yes of course. My grandmother and my mother's grandmother were from here.\n",
      "39.0 45.0 0.0821917808219178 0\n",
      "TRUE. You had to harmonize with the territory because we\n",
      "surround the souls of those who lived here You must harmonize with the territory because we\n",
      "122.93939393939394 125.84848484848484 0.06060606060606061 -1\n",
      "Where is the sea? If over there, from here you can see the sea yes, over there, from here you can see the sea\n",
      "46.935483870967744 49.903225806451616 0.06451612903225806 -1\n",
      "There where the pieces of amuchi (ceramics) are,\n",
      "are their ancestral remains (bone) There where the pieces of amuchi (ceramic) are,\n",
      "70.0 74.53012048192771 0.0963855421686747 0\n",
      "The territory is sacred the territory is sacred\n",
      "346.0 347.0 0.043478260869565216 0\n",
      "The old people say that through a dream they were told\n",
      "to bring the sand from there The ancestors say that through a dream they were told\n",
      "175.9156626506024 180.38554216867468 0.08433734939759036 -1\n",
      "That was destined. Yes, that's why they were created\n",
      "ancestors who saw here That was destined. Yes, that's why they were created\n",
      "348.0 352.85333333333335 0.09333333333333334 0\n",
      "People say that here in the north is where\n",
      "are the most sacred places People say that here in the north is where\n",
      "295.0 299.8695652173913 0.11594202898550725 0\n",
      "Through stories like these you will learn not only\n",
      "the place but its spirituality Through stories like these they will know not only\n",
      "270.0 274.320987654321 0.08641975308641975 0\n",
      "Yeah. It is very good to make known what\n",
      "we have because it is part of our Wayuu culture Yeah. It is very good to make known what\n",
      "253.0 256.6363636363636 0.09090909090909091 0\n",
      "Yeah. It is very good to make known what\n",
      "we have because it is part of our Wayuu culture We have it because it is part of our Wayuu culture.\n",
      "256.72727272727275 261.3636363636364 0.09090909090909091 41\n",
      "Because it is already getting dark and we already have\n",
      "we have to leave because of how sacred it is it is already getting dark and we already have\n",
      "400.4949494949495 403.7474747474747 0.0707070707070707 7\n",
      "CSV file with speaker, start time, end time, duration, and matched transcript created at ../01_Scripts/Wayuu/output_timecodes.csv.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Function to convert different time formats to seconds (unchanged)\n",
    "def convert_time_to_seconds(time_str):\n",
    "    try:\n",
    "        if ':' in time_str:\n",
    "            parts = time_str.split(':')\n",
    "            if len(parts) == 2:\n",
    "                minutes, seconds = map(int, parts)\n",
    "                return minutes * 60 + seconds\n",
    "\n",
    "        parts = time_str.split(':')\n",
    "        if len(parts) == 3 or len(parts) == 4:\n",
    "            hours, minutes, seconds, *milliseconds = map(int, parts)\n",
    "            total_seconds = hours * 3600 + minutes * 60 + seconds\n",
    "            if milliseconds:\n",
    "                total_seconds += milliseconds[0] / 100\n",
    "            return total_seconds\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "    raise ValueError(f\"Unrecognized time format: {time_str}\")\n",
    "\n",
    "# Function to format time in MM:SS (unchanged)\n",
    "def format_time(seconds):\n",
    "    minutes, seconds = divmod(seconds, 60)\n",
    "    return f\"{minutes:02d}:{seconds:02d}\"\n",
    "\n",
    "def find_start_character_index(string, subsequence, cutoff=0.6):\n",
    "\n",
    "    # Initialize the start index.\n",
    "    start_index = -1\n",
    "\n",
    "    # Iterate through the string using a sliding window approach.\n",
    "    for i in range(len(string) - len(subsequence) + 1):\n",
    "        window = string[i:i + len(subsequence)]\n",
    "\n",
    "        # Use difflib's SequenceMatcher to calculate similarity.\n",
    "        similarity = SequenceMatcher(None, subsequence, window).ratio()\n",
    "\n",
    "        # If the similarity exceeds the cutoff, consider it a match.\n",
    "        if similarity >= cutoff:\n",
    "            start_index = i\n",
    "            break\n",
    "\n",
    "    return start_index\n",
    "\n",
    "# Function to match script text with transcript\n",
    "def match_script_with_transcript(docx_file_path, transcript_csv_path):\n",
    "    doc = docx.Document(docx_file_path)\n",
    "    transcript_df = pd.read_csv(transcript_csv_path)\n",
    "    print(transcript_df)\n",
    "\n",
    "    speaker = \"\"\n",
    "    transcript_lines = []\n",
    "\n",
    "    for para in doc.paragraphs:\n",
    "        text = para.text.strip()\n",
    "\n",
    "        if text:\n",
    "            match = re.match(r'^([A-Za-z]+)$', text)\n",
    "            if match:\n",
    "                speaker = match.group(1)\n",
    "            else:\n",
    "                closest_match = get_close_matches(text, transcript_df[\"EN\"], n=1, cutoff=0.6)\n",
    "                if closest_match:\n",
    "                    matched_row = transcript_df[transcript_df[\"EN\"] == closest_match[0]].iloc[0]\n",
    "                    start_time_str = matched_row[\"Start Time\"]\n",
    "                    start_time = convert_time_to_seconds(start_time_str)\n",
    "                    print(matched_row[\"EN\"],text)\n",
    "                    transcript_duration=convert_time_to_seconds(matched_row[\"End Time\"]) - convert_time_to_seconds(matched_row[\"Start Time\"])                    \n",
    "                    offset = find_start_character_index(matched_row[\"EN\"],text[:8], cutoff=.8)\n",
    "                    seconds_per_letter =transcript_duration / len(matched_row[\"EN\"])\n",
    "                    start_time+=offset*seconds_per_letter\n",
    "                    duration_seconds = len(text) * seconds_per_letter\n",
    "                    end_time = start_time + duration_seconds\n",
    "                    \n",
    "                    print(start_time,end_time,seconds_per_letter,offset)\n",
    "\n",
    "                    start_time_mmss = format_time(int(start_time))\n",
    "                    end_time_mmss = format_time(int(end_time))\n",
    "                    transcript_lines.append([speaker, start_time_mmss, end_time_mmss, duration_seconds, text])\n",
    "\n",
    "    return transcript_lines\n",
    "\n",
    "# Function to write matched transcript to CSV (unchanged)\n",
    "def write_matched_transcript_to_csv(transcript_lines, output_csv_path):\n",
    "    with open(output_csv_path, \"w\", newline=\"\") as csvfile:\n",
    "        fieldnames = [\"Speaker\", \"Start Time\", \"End Time\", \"Duration (Seconds)\", \"Transcript\"]\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        for line in transcript_lines:\n",
    "            speaker, start_time_mmss, end_time_mmss, duration_seconds, text = line\n",
    "            writer.writerow({\"Speaker\": speaker, \"Start Time\": start_time_mmss, \"End Time\": end_time_mmss, \"Duration (Seconds)\": duration_seconds, \"Transcript\": text})\n",
    "\n",
    "script_path = \"../01_Scripts/Wayuu/Dunas Script.docx\"\n",
    "transcript_path = \"../04_Interview CSV/Wayuu/dunas.csv\"#should use the concatenated csv\n",
    "output_csv_path = \"../01_Scripts/Wayuu/output_timecodes.csv\"\n",
    "\n",
    "transcript_lines = match_script_with_transcript(script_path, transcript_path)\n",
    "write_matched_transcript_to_csv(transcript_lines, output_csv_path)\n",
    "print(f\"CSV file with speaker, start time, end time, duration, and matched transcript created at {output_csv_path}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd38378",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "c873f58f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a47c9ea3",
   "metadata": {},
   "source": [
    "<h3> Check status of txts, csv, xmls, srts </h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "fe347c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   EN Transcripts  ES Transcripts  EN Subs  ES Subs   XMLs\n",
      "code                                                                      \n",
      "magalys hammock              True            True     True     True  False\n",
      "palabrero luis               True            True     True     True  False\n",
      "weildler pre                 True            True     True     True  False\n",
      "tejedora abuela              True            True     True     True  False\n",
      "pinta abuela                 True            True     True     True  False\n",
      "salinero oscar               True            True     True     True  False\n",
      "neko weaving                 True            True     True     True  False\n",
      "eliana                       True            True     True     True  False\n",
      "salinero young               True            True    False     True  False\n",
      "romelia                      True            True     True     True  False\n",
      "neko piedra                  True            True     True     True  False\n",
      "dunas                        True            True     True     True  False\n",
      "ana weaving                  True            True     True     True  False\n",
      "healing woman                True            True     True     True  False\n",
      "wolunka                      True            True     True     True  False\n",
      "weildler inside              True            True     True     True  False\n",
      "abuela pescadora             True            True     True     True  False\n",
      "joaquin                      True            True     True     True  False\n",
      "abuelo pescador              True            True     True     True  False\n",
      "weildler outside             True            True     True     True  False\n",
      "neko father                  True            True     True     True  False\n",
      "neko urbana                  True            True    False     True  False\n",
      "magalys electrico            True            True     True     True  False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def getCodesPresent(folderpath,ext):\n",
    "    codes = []\n",
    "    for filename in os.listdir(folderpath):\n",
    "        if filename.endswith(ext) and os.path.getsize(os.path.join(folderpath,filename))>1000:\n",
    "            code=filename.lower().split(ext.lower())[0]\n",
    "            codes.append(code)\n",
    "    return codes\n",
    "\n",
    "enTexts=getCodesPresent('../02_Transcripts/Wayuu/Transcripts (EN)/',' (EN).docx')\n",
    "esTexts=getCodesPresent('../02_Transcripts/Wayuu/Transcripts (ES)/',' (ES).docx')\n",
    "xmls=getCodesPresent('../03_Interview XML/Wayuu/','.xml')\n",
    "enSubs=getCodesPresent('../05_Subtitles/Wayuu/SRT Export (EN)/',' (EN).srt')\n",
    "esSubs=getCodesPresent('../05_Subtitles/Wayuu/SRT Export (ES)/',' (ES).srt')\n",
    "\n",
    "lists_dict ={\"EN Transcripts\":enTexts,\n",
    "            \"ES Transcripts\":esTexts,\n",
    "            \"EN Subs\":enSubs,\n",
    "            \"ES Subs\":esSubs,\n",
    "            \"XMLs\":xmls}\n",
    "    \n",
    "\n",
    "# Create a DataFrame with unique codes\n",
    "unique_codes = list(set(code for sublist in lists_dict.values() for code in sublist))\n",
    "df = pd.DataFrame({'code': unique_codes})\n",
    "\n",
    "# Add columns for each list with True/False values\n",
    "for list_name, code_list in lists_dict.items():\n",
    "    df[list_name] = df['code'].isin(code_list)\n",
    "\n",
    "# Set 'code' as the index\n",
    "df.set_index('code', inplace=True)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dd1552",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c75104",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503fd01e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
