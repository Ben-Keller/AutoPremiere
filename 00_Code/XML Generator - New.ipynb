{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Imports </h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "import csv\n",
    "import xml.etree.ElementTree as ET\n",
    "import copy\n",
    "import random\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open csv and preprocess, merging consecutive rows\n",
    "#build xml structure\n",
    "#iterate through csv\n",
    "## extract audio and video sequence info\n",
    "## add audio, video, and subtitle info to xml\n",
    "#export xml\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Preprocess script csv</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "script_folder = \"../01_Scripts/Wayuu/\"\n",
    "xml_folder = \"../03_Interview XML/\"\n",
    "csv_folder_path = \"../04_Interview CSV/\"\n",
    "script_path=\"dunas-script.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Speaker Interview Start Time End Time  Duration (Seconds)  \\\n",
      "0   Magalys     dunas       0:22     0:25            3.686275   \n",
      "1   Magalys     dunas       0:25     0:29            4.235294   \n",
      "2   Magalys     dunas       0:30     0:33            3.000000   \n",
      "3      Neko     dunas       0:39     0:45            6.000000   \n",
      "4   Magalys     dunas       2:02     2:05            2.909091   \n",
      "5   Magalys     dunas       0:46     0:49            2.967742   \n",
      "6   Magalys     dunas       1:10     1:14            4.530120   \n",
      "7   Magalys     dunas       5:46     5:47            1.000000   \n",
      "8   Magalys     dunas       2:55     3:00            4.469880   \n",
      "9   Magalys     dunas       5:48     5:52            4.853333   \n",
      "10  Magalys     dunas       4:55     4:59            4.869565   \n",
      "11  Magalys     dunas       4:30     4:34            4.320988   \n",
      "12  Magalys     dunas       4:13     4:16            3.636364   \n",
      "13  Magalys     dunas       4:16     4:21            4.636364   \n",
      "14  Magalys     dunas       6:40     6:43            3.252525   \n",
      "\n",
      "                                           Transcript  \n",
      "0     We are in the territory of Usijou´, in Alewalü.  \n",
      "1   I don't know if you've heard that it's a sacre...  \n",
      "2                                           Test line  \n",
      "3   Yes of course. My grandmother and my mother's ...  \n",
      "4    You must harmonize with the territory because we  \n",
      "5      yes, over there, from here you can see the sea  \n",
      "6     There where the pieces of amuchi (ceramic) are,  \n",
      "7                             the territory is sacred  \n",
      "8   The ancestors say that through a dream they we...  \n",
      "9   That was destined. Yes, that's why they were c...  \n",
      "10         People say that here in the north is where  \n",
      "11  Through stories like these they will know not ...  \n",
      "12           Yeah. It is very good to make known what  \n",
      "13  We have it because it is part of our Wayuu cul...  \n",
      "14     it is already getting dark and we already have  \n"
     ]
    }
   ],
   "source": [
    "scriptCsv=pd.read_csv(script_folder+script_path)\n",
    "print(scriptCsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Speaker Interview Start Time End Time  Duration (Seconds)  \\\n",
      "0   Magalys     dunas       0:22     0:33           10.921569   \n",
      "3      Neko     dunas       0:39     0:45            6.000000   \n",
      "4   Magalys     dunas       2:02     2:05            2.909091   \n",
      "5   Magalys     dunas       0:46     0:49            2.967742   \n",
      "6   Magalys     dunas       1:10     1:14            4.530120   \n",
      "7   Magalys     dunas       5:46     5:47            1.000000   \n",
      "8   Magalys     dunas       2:55     3:00            4.469880   \n",
      "9   Magalys     dunas       5:48     5:52            4.853333   \n",
      "10  Magalys     dunas       4:55     4:59            4.869565   \n",
      "11  Magalys     dunas       4:30     4:34            4.320988   \n",
      "12  Magalys     dunas       4:13     4:21            8.272727   \n",
      "14  Magalys     dunas       6:40     6:43            3.252525   \n",
      "\n",
      "                                           Transcript  \n",
      "0   We are in the territory of Usijou´, in Alewalü...  \n",
      "3   Yes of course. My grandmother and my mother's ...  \n",
      "4    You must harmonize with the territory because we  \n",
      "5      yes, over there, from here you can see the sea  \n",
      "6     There where the pieces of amuchi (ceramic) are,  \n",
      "7                             the territory is sacred  \n",
      "8   The ancestors say that through a dream they we...  \n",
      "9   That was destined. Yes, that's why they were c...  \n",
      "10         People say that here in the north is where  \n",
      "11  Through stories like these they will know not ...  \n",
      "12  Yeah. It is very good to make known what We ha...  \n",
      "14     it is already getting dark and we already have  \n"
     ]
    }
   ],
   "source": [
    "##merge consecutive rows \n",
    "\n",
    "# Function to convert time format to seconds\n",
    "def time_to_seconds(time_str):\n",
    "    time_obj = datetime.strptime(str(time_str), \"%M:%S\")\n",
    "    return time_obj.minute * 60 + time_obj.second\n",
    "\n",
    "# Function to merge consecutive rows with start times within 10 seconds\n",
    "def merge_consecutive_transcripts(df):\n",
    "    merged_rows = []\n",
    "    current_row = None\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        if current_row is None:\n",
    "            current_row = row\n",
    "        else:\n",
    "            end_time_current = time_to_seconds(current_row['End Time'])\n",
    "            start_time_next = time_to_seconds(row['Start Time'])\n",
    "            if start_time_next >= end_time_current and start_time_next - end_time_current <= 3:\n",
    "                current_row['End Time'] = row['End Time']\n",
    "                current_row['Duration (Seconds)'] += row['Duration (Seconds)']\n",
    "                current_row['Transcript'] += ' ' + row['Transcript']\n",
    "            else:\n",
    "                merged_rows.append(current_row)\n",
    "                current_row = row\n",
    "    \n",
    "    if current_row is not None:\n",
    "        merged_rows.append(current_row)\n",
    "    \n",
    "    merged_df = pd.DataFrame(merged_rows)\n",
    "    return merged_df\n",
    "\n",
    "# Call the function\n",
    "merged_transcripts_df = merge_consecutive_transcripts(scriptCsv)\n",
    "print(merged_transcripts_df)\n",
    "\n",
    "# # Sample DataFrame\n",
    "# data = {\n",
    "#     'Speaker': ['Magalys', 'Magalys', 'Neko', 'Magalys', 'Magalys'],\n",
    "#     'Interview': ['dunas', 'dunas', 'dunas', 'dunas', 'dunas'],\n",
    "#     'Start Time': ['0:22', '0:25', '0:39', '2:02', '0:46'],\n",
    "#     'End Time': ['0:25', '0:29', '0:45', '2:05', '0:49'],\n",
    "#     'Duration (Seconds)': [3.68627451, 4.235294118, 6, 2.909090909, 2.967741935],\n",
    "#     'Transcript': ['We are in the territory of Usijou¬¥, in Alewal√º.',\n",
    "#                    \"I don't know if you've heard that it's a sacred place.\",\n",
    "#                    \"Yes of course. My grandmother and my mother's grandmother were from here.\",\n",
    "#                    'You must harmonize with the territory because we',\n",
    "#                    'yes, over there, from here you can see the sea']\n",
    "# }\n",
    "\n",
    "# df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>build xml structure</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_xml(xml_name):\n",
    "    \n",
    "    # Create the root element\n",
    "    root = ET.Element(\"xmeml\", version=\"4\")\n",
    "    \n",
    "    # Create the sequence element with attributes\n",
    "    sequence = ET.SubElement(root, \"sequence\", id=\"sequence-2\", TL_SQAudioVisibleBase=\"0\", TL_SQVideoVisibleBase=\"0\",\n",
    "                             TL_SQVisibleBaseTime=\"0\", TL_SQAVDividerPosition=\"0.5\", TL_SQHideShyTracks=\"0\",\n",
    "                             TL_SQHeaderWidth=\"236\", TL_SQDataTrackViewControlState=\"0\",\n",
    "                             Monitor_ProgramZoomOut=\"340011984312000\", Monitor_ProgramZoomIn=\"0\",\n",
    "                             TL_SQTimePerPixel=\"1.6034289012958367\", MZ_EditLine=\"333083126376000\",\n",
    "                             MZ_Sequence_PreviewFrameSizeHeight=\"1080\", MZ_Sequence_PreviewFrameSizeWidth=\"1920\",\n",
    "                             MZ_Sequence_AudioTimeDisplayFormat=\"200\", MZ_Sequence_PreviewUseMaxRenderQuality=\"false\",\n",
    "                             MZ_Sequence_PreviewUseMaxBitDepth=\"false\", MZ_Sequence_VideoTimeDisplayFormat=\"110\",\n",
    "                             MZ_WorkOutPoint=\"15235011792000\", MZ_WorkInPoint=\"0\", MZ_ZeroPoint=\"0\", explodedTracks=\"true\")\n",
    "    \n",
    "    # Add the uuid element\n",
    "    uuid = ET.SubElement(sequence, \"uuid\")\n",
    "    uuid.text = \"50e61931-251f-4069-8193-a3fbad7f93ff\"\n",
    "    \n",
    "    # Add the duration element\n",
    "    duration = ET.SubElement(sequence, \"duration\")\n",
    "    duration.text = \"31533\"\n",
    "    \n",
    "    # Add the rate element with nested timebase and ntsc elements\n",
    "    rate = ET.SubElement(sequence, \"rate\")\n",
    "    timebase = ET.SubElement(rate, \"timebase\")\n",
    "    timebase.text = \"24\"\n",
    "    ntsc = ET.SubElement(rate, \"ntsc\")\n",
    "    ntsc.text = \"TRUE\"\n",
    "    \n",
    "    # Add the name element\n",
    "    name_element = ET.SubElement(sequence, \"name\")\n",
    "    name_element.text = xml_name\n",
    "    \n",
    "    # Add the media element with nested video and audio elements\n",
    "    media = ET.SubElement(sequence, \"media\")\n",
    "\n",
    "    \n",
    "    # Add the timecode element with nested rate, string, frame, and displayformat elements\n",
    "    timecode = ET.SubElement(sequence, \"timecode\")\n",
    "    rate = ET.SubElement(timecode, \"rate\")\n",
    "    timebase = ET.SubElement(rate, \"timebase\")\n",
    "    timebase.text = \"24\"\n",
    "    ntsc = ET.SubElement(rate, \"ntsc\")\n",
    "    ntsc.text = \"TRUE\"\n",
    "    string = ET.SubElement(timecode, \"string\")\n",
    "    string.text = \"00:00:00:00\"\n",
    "    frame = ET.SubElement(timecode, \"frame\")\n",
    "    frame.text = \"0\"\n",
    "    displayformat = ET.SubElement(timecode, \"displayformat\")\n",
    "    displayformat.text = \"NDF\"\n",
    "    \n",
    "    # Add the labels element with nested label2 element\n",
    "    labels = ET.SubElement(sequence, \"labels\")\n",
    "    label2 = ET.SubElement(labels, \"label2\")\n",
    "    label2.text = \"Forest\"\n",
    "    \n",
    "\n",
    "    # Create the ElementTree object with the root element\n",
    "    tree = ET.ElementTree(root)\n",
    "    \n",
    "    # Generate a random Idd\n",
    "    idd = str(random.randint(1, 1000))\n",
    "    \n",
    "    # Save the XML to a file\n",
    "    filename = f\"{xml_name.replace(' ', '_')}-{idd}.xml\"\n",
    "    tree.write(f\"{filename}\", encoding=\"utf-8\", xml_declaration=True)\n",
    "    print(f\"XML saved to {filename}\")\n",
    "\n",
    "    return filename \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML saved to test-6.xml\n",
      "test-6.xml\n"
     ]
    }
   ],
   "source": [
    "filename = create_xml(\"test\")\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> try to refeactor these away</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_method = 'project_timecode'  # video_timecode or project_timecode \n",
    "\n",
    "video_clip_list = []\n",
    "audio_clip_list = []\n",
    "id_mapping = {}\n",
    "# global sequence_start\n",
    "# global sequence_end\n",
    "\n",
    "subtitle_counter=1\n",
    "sequence_start=0\n",
    "sequence_end=0\n",
    "audio_sequence_start=0\n",
    "audio_sequence_end=0\n",
    "xml_file_assigned=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Helper functions for XML generation </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converts Time to Frames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78662"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_time_to_frames(time, rate):\n",
    "    # print('Time', time, 'Rate', rate)\n",
    "    parts = time.split(\":\")\n",
    "    hours = int(parts[0])\n",
    "    minutes = int(parts[1])\n",
    "    seconds = int(parts[2])\n",
    "    frames = int(parts[3])\n",
    "    \n",
    "    # Calculate the total duration in frames\n",
    "    total_frames = (\n",
    "        hours * 3600 * rate +  # Convert hours to frames\n",
    "        minutes * 60 * rate +  # Convert minutes to frames\n",
    "        seconds * rate +  # Convert seconds to frames\n",
    "        frames\n",
    "    )\n",
    "    \n",
    "    return total_frames\n",
    "\n",
    "convert_time_to_frames('00:54:36:38', 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_to_ticks(frame_number, frame_rate):\n",
    "    total_ticks_in_a_second = 254016000000\n",
    "    tick_value = int((frame_number * total_ticks_in_a_second) / frame_rate)\n",
    "    return tick_value\n",
    "\n",
    "# frame_to_ticks(24, 24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> XML processing functions </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate New ids for the each Clip item in seperate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'clipitem-1a8c77182ced477da9b92929bc322677'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_unique_id():\n",
    "    unique_id = f\"clipitem-{uuid.uuid4().hex}\"\n",
    "    return unique_id\n",
    "\n",
    "generate_unique_id()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the id of clips in specific XML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_xml_ids(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    print('Assigning unique IDs to clipitem elements...')\n",
    "\n",
    "    # Generate unique IDs for clipitem elements\n",
    "      # Store the mapping of old IDs to new unique IDs\n",
    "    for clip_item in root.findall('.//clipitem'):  # Adjust the XPath expression based on the actual location of clipitem elements\n",
    "        current_id = clip_item.attrib['id']\n",
    "        unique_id = generate_unique_id()\n",
    "        id_mapping[current_id] = unique_id\n",
    "        clip_item.attrib['id'] = unique_id\n",
    "\n",
    "    \n",
    "        # Update the references in the links section\n",
    "    for link in root.findall('.//link'):\n",
    "        linkclipref = link.find('linkclipref')\n",
    "        if linkclipref is not None and linkclipref.text in id_mapping:\n",
    "            linkclipref.text = id_mapping[linkclipref.text]\n",
    "    print(id_mapping)\n",
    "\n",
    "    # Save the modified XML file\n",
    "    tree.write(xml_file, encoding=\"utf-8\")\n",
    "\n",
    "# update_xml_ids(xml_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract time in  start and end time format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('00:00:00:00', '00:23:00:00')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_timecode(timecode_range):\n",
    "    start_time, end_time = timecode_range.split(\" - \")\n",
    "    start_time = start_time.strip().replace(\" \", \"\")\n",
    "    end_time = end_time.strip().replace(\" \", \"\")\n",
    "    # print('Start Time',start_time,'End Time', end_time)\n",
    "    return start_time, end_time\n",
    "\n",
    "extract_timecode(\"00:00:00:00 - 00:23:00:00\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Extract sequences </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract sequence info through xml file and extract the clips that match with the start and end time using frame comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sequence_info(\n",
    "    xml_file, start_time, end_time, extract_method=\"project_timecode\"\n",
    "):\n",
    "    global sequence_start, sequence_end\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Extract sequence information\n",
    "    sequence = root.find(\"sequence\")\n",
    "    sequence_info = {\n",
    "        \"duration\": int(sequence.find(\"duration\").text),\n",
    "        \"rate\": {\n",
    "            \"timebase\": int(sequence.find(\"rate/timebase\").text),\n",
    "            \"ntsc\": sequence.find(\"rate/ntsc\").text == \"TRUE\",\n",
    "        },\n",
    "    }\n",
    "    sequence_rate = sequence_info[\"rate\"][\"timebase\"]\n",
    "\n",
    "    # Convert start and end times to frames\n",
    "    start_frame = convert_time_to_frames(start_time, 24)\n",
    "    end_frame = convert_time_to_frames(end_time, 24)\n",
    "    proTickIn = frame_to_ticks(start_frame, 24)\n",
    "    proTickOut = frame_to_ticks(end_frame, 24)\n",
    "\n",
    "    total_clip_frames = end_frame - start_frame\n",
    "    total_clip_proticks = proTickOut - proTickIn\n",
    "\n",
    "    # print('Start and End Frame',start_frame ,end_frame)\n",
    "    # print(sequence_rate,'sequence_rate')\n",
    "\n",
    "    # Extract video clip information\n",
    "    video_clips = []\n",
    "    for track_index, track in enumerate(root.findall(\".//video/track\")):  # Iterate over all tracks within the <video> tag\n",
    "        # track_idx = 0\n",
    "        track_targeted = track.attrib[\"MZ.TrackTargeted\"]\n",
    "        for clip_item in track.findall(\"clipitem\"):  # Only consider clip items within the <video> tag\n",
    "            \n",
    "            video_start_cut_diff=abs(start_frame - int(clip_item.find(\"start\").text))\n",
    "            video_end_cut_diff=abs(end_frame - int(clip_item.find(\"end\").text))\n",
    "            extracted_clip_duration=end_time-start_time\n",
    "            actual_clip_duration=int(clip_item.find(\"duration\").text)\n",
    "\n",
    "\n",
    "            links = clip_item.findall(\"link\")\n",
    "            track_idx = [\n",
    "                int(link.find(\"trackindex\").text)\n",
    "                for link in clip_item.findall(\"link\")\n",
    "                if link.find(\"mediatype\").text == \"video\"\n",
    "            ]\n",
    "            print(\"Track Index\", track_idx)\n",
    "            print(\"Clip ID\", clip_item.attrib[\"id\"])\n",
    "\n",
    "            clip_info = {\n",
    "                \"id\": clip_item.attrib[\"id\"],  # Get the clip ID\n",
    "                \"name\": clip_item.find(\"name\").text,\n",
    "                \"duration\": int(clip_item.find(\"duration\").text),\n",
    "                \"rate\": {\n",
    "                    \"timebase\": int(clip_item.find(\"rate/timebase\").text),\n",
    "                    \"ntsc\": clip_item.find(\"rate/ntsc\").text == \"TRUE\",\n",
    "                },\n",
    "                \"in\": int(clip_item.find(\"in\").text),\n",
    "                \"out\": int(clip_item.find(\"out\").text),\n",
    "                \"start\": int(clip_item.find(\"start\").text),\n",
    "                \"end\": int(clip_item.find(\"end\").text),\n",
    "                \"track_index\": track_index+1,\n",
    "                \"MZ_TrackTargeted\": track_targeted,\n",
    "                \"links\": [],  # Initialize an empty list to store links,\n",
    "                \"video_clip_element\": None,  # Store the clip item element for later use\n",
    "                \"linked_audio_clip_elements_list\": [],  # Initialize an empty list to store linked clip items\n",
    "            }\n",
    "\n",
    "            if extract_method == \"video_timecode\":\n",
    "                clip_comparison = (\n",
    "                    clip_info[\"in\"] <= start_frame <= clip_info[\"out\"]\n",
    "                ) or (clip_info[\"in\"] <= end_frame <= clip_info[\"out\"])\n",
    "            else:\n",
    "                clip_comparison = (\n",
    "                    clip_info[\"start\"] <= start_frame <= clip_info[\"end\"]\n",
    "                ) or (clip_info[\"start\"] <= end_frame <= clip_info[\"end\"])\n",
    "\n",
    "            \n",
    "\n",
    "            for link in links:\n",
    "                link_info = {\n",
    "                    \"linkclipref\": link.find(\"linkclipref\").text,\n",
    "                    \"mediatype\": link.find(\"mediatype\").text,\n",
    "                    \"trackindex\": int(link.find(\"trackindex\").text),\n",
    "                    \"clipindex\": int(link.find(\"clipindex\").text),\n",
    "                }\n",
    "                if link.find(\"groupindex\") is not None:\n",
    "                    link_info[\"groupindex\"] = int(link.find(\"groupindex\").text)\n",
    "                clip_info[\"links\"].append(link_info)\n",
    "                if link.find(\"mediatype\").text == \"audio\":\n",
    "                    audio_clip_items = root.findall(\".//audio//clipitem\")\n",
    "                    for audio_clip_item in audio_clip_items:\n",
    "                        if (\n",
    "                            audio_clip_item.attrib[\"id\"]\n",
    "                            == link.find(\"linkclipref\").text\n",
    "                        ):\n",
    "                            audio_clip_item.find(\"in\").text = str(start_frame)\n",
    "                            audio_clip_item.find(\"out\").text = str(end_frame)\n",
    "                              \n",
    "                            audio_clip_item.find(\"start\").text = str(sequence_start)\n",
    "                            audio_clip_item.find(\"end\").text = str(sequence_end)\n",
    "                            audio_clip_item.find(\"pproTicksIn\").text = str(proTickIn)\n",
    "                            audio_clip_item.find(\"pproTicksOut\").text = str(proTickOut)\n",
    "                                \n",
    "                            \n",
    "                            clip_info[\"linked_audio_clip_elements_list\"].append(\n",
    "                                {\n",
    "                                    \"audio_clip_item\": audio_clip_item,\n",
    "                                    \"trackindex\": int(link.find(\"trackindex\").text),\n",
    "                                    \"sourceindex\": int(\n",
    "                                        audio_clip_item.find(\n",
    "                                            \".//sourcetrack/trackindex\"\n",
    "                                        ).text\n",
    "                                    ),\n",
    "                                }\n",
    "                            )\n",
    "\n",
    "            # Check if the clip's in or out frame falls within the given start and end frames\n",
    "            # print('Clip Frame Inside file Found: ',clip_info['in'] <= start_frame <= clip_info['out'])\n",
    "            print(\n",
    "                \"Clip Frame Inside file Found: \",\n",
    "                clip_info[\"start\"] <= start_frame <= clip_info[\"end\"]\n",
    "                or clip_info[\"start\"] <= end_frame <= clip_info[\"end\"],\n",
    "            )\n",
    "            print(\"clip_comparison\", clip_comparison)\n",
    "            print(\"In - Matching - Out\")\n",
    "            # print(clip_info['in'],start_frame,clip_info['out'])\n",
    "            print(clip_info[\"start\"], start_frame, clip_info[\"end\"])\n",
    "            print(clip_info[\"start\"], end_frame, clip_info[\"end\"])\n",
    "            if clip_comparison:\n",
    "                clip_item.find(\"in\").text = str(start_frame)\n",
    "                clip_item.find(\"out\").text = (\n",
    "                    str(end_frame)\n",
    "                    if extract_method == \"video_timecode\"\n",
    "                    else str(start_frame + total_clip_frames)\n",
    "                )\n",
    "                clip_item.find(\"start\").text = str(sequence_start)\n",
    "                clip_item.find(\"end\").text = str(sequence_end)\n",
    "                clip_item.find(\"pproTicksIn\").text = str(proTickIn)\n",
    "                clip_item.find(\"pproTicksOut\").text = (\n",
    "                    str(proTickOut)\n",
    "                    if extract_method == \"video_timecode\"\n",
    "                    else str(proTickIn + total_clip_proticks)\n",
    "                )\n",
    "                clip_info[\"video_clip_element\"] = clip_item\n",
    "                video_clips.append(clip_info)\n",
    "                print(\"Next Sequence Start\", sequence_start)\n",
    "                print(\"Next Sequence End\", sequence_end)\n",
    "\n",
    "    # print(clip_info, start_frame, end_frame)\n",
    "\n",
    "    # Create result dictionary\n",
    "    result = { \"video_clips\": video_clips}\n",
    "    # print('Result',result)\n",
    "\n",
    "    if not video_clips:  # Check if video_clips list is empty\n",
    "        return None\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overlap Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#overlap function used for extracting video sequences\n",
    "def overlap(segment1, segment2):\n",
    "    \"\"\"Check if two segments overlap and return the overlapped segment if they do\"\"\"\n",
    "    start1, end1 = segment1\n",
    "    start2, end2 = segment2\n",
    "    if start1 > end2 or start2 > end1:\n",
    "        # Segments do not overlap\n",
    "        return None\n",
    "    else:\n",
    "        # Segments overlap, return the overlapped segment\n",
    "        return max(start1, start2), min(end1, end2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract Video sequences from the xml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_video_sequence(xml_file, start_time, end_time):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    global sequence_start, sequence_end\n",
    "\n",
    "    # Convert start and end times to frames\n",
    "    start_frame = convert_time_to_frames(start_time, 24)\n",
    "    end_frame = convert_time_to_frames(end_time, 24)\n",
    "\n",
    "\n",
    "    # Extract video clip information\n",
    "    video_clips = []\n",
    "    for track_index, track in enumerate(root.findall(\".//video/track\")):  # Iterate over all tracks within the <video> tag\n",
    "        track_targeted = track.attrib[\"MZ.TrackTargeted\"]\n",
    "        for clip_item in track.findall(\"clipitem\"):  # Only consider clip items within the <video> tag\n",
    "\n",
    "            \n",
    "\n",
    "            clip_info = {\n",
    "                \"id\": clip_item.attrib[\"id\"],  # Get the clip ID\n",
    "                \"new_id\": generate_unique_id(),  # Generate a new unique ID for the clip item\",\n",
    "                \"name\": clip_item.find(\"name\").text,\n",
    "                \"duration\": int(clip_item.find(\"duration\").text),\n",
    "                \"rate\": {\n",
    "                    \"timebase\": int(clip_item.find(\"rate/timebase\").text),\n",
    "                    \"ntsc\": clip_item.find(\"rate/ntsc\").text == \"TRUE\",\n",
    "                },\n",
    "                \"in\": int(clip_item.find(\"in\").text),\n",
    "                \"out\": int(clip_item.find(\"out\").text),\n",
    "                \"start\": int(clip_item.find(\"start\").text),\n",
    "                \"end\": int(clip_item.find(\"end\").text),\n",
    "                \"track_index\": track_index+1,\n",
    "                \"MZ_TrackTargeted\": track_targeted,\n",
    "                \"video_clip_element\": None,  # Store the clip item element for later use\n",
    "            }\n",
    "\n",
    "            # Check if the clip's in or out frame falls within the given start and end frames\n",
    "            if (\n",
    "                clip_info[\"start\"] <= start_frame <= clip_info[\"end\"]\n",
    "                or clip_info[\"start\"] <= end_frame <= clip_info[\"end\"]\n",
    "            ):\n",
    "                \n",
    "                # Calculate the overlapped segment and the corresponding sequence segment\n",
    "                overlapped_segment = overlap((clip_info[\"start\"], clip_info[\"end\"]), (start_frame, end_frame))\n",
    "\n",
    "                if overlapped_segment is not None:\n",
    "                    overlap_start, overlap_end = overlapped_segment\n",
    "                    ratio_start = (overlap_start - clip_info[\"start\"]) / (clip_info[\"end\"] - clip_info[\"start\"])\n",
    "                    ratio_end = (overlap_end - clip_info[\"start\"]) / (clip_info[\"end\"] - clip_info[\"start\"])\n",
    "\n",
    "                    clip_start_time = 0 if sequence_end == 0 else sequence_end \n",
    "                    clip_end_time = clip_start_time + (overlap_end - overlap_start)\n",
    "\n",
    "                    # Update the clip's in, out, start, and end in the XML tree based on the overlapped segment\n",
    "                    clip_item.find(\"in\").text = str(clip_info[\"in\"] + round(ratio_start * (clip_info[\"out\"] - clip_info[\"in\"])))\n",
    "                    clip_item.find(\"out\").text = str(clip_info[\"in\"] + round(ratio_end * (clip_info[\"out\"] - clip_info[\"in\"])))\n",
    "                    clip_item.find(\"start\").text = str(clip_start_time)\n",
    "                    clip_item.find(\"end\").text = str(clip_end_time)\n",
    "\n",
    "                    clip_info[\"video_clip_element\"] = clip_item\n",
    "                    video_clips.append(clip_info)\n",
    "\n",
    "    if not video_clips:  # Check if video_clips list is empty\n",
    "        return None\n",
    "    else:\n",
    "        sequence_start = 0 if sequence_end == 0 else sequence_end \n",
    "        sequence_end = sequence_start + (end_frame - start_frame)\n",
    "\n",
    "    # Create result dictionary\n",
    "    result = {\"video_clips\": video_clips}\n",
    "    return result\n",
    "\n",
    "# Test the function with the given XML file and start/end times\n",
    "# extract_video_sequence('ben - synced.xml', '00:00:00:00', '00:00:10:00')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract Audio sequences from the xml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio_sequence(xml_file, start_time, end_time):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    global audio_sequence_start ,audio_sequence_end\n",
    "\n",
    "    # Convert start and end times to frames\n",
    "    start_frame = convert_time_to_frames(start_time, 24)\n",
    "    end_frame = convert_time_to_frames(end_time, 24)\n",
    "\n",
    "    # Extract video clip information\n",
    "    audio_clips = []\n",
    "    for track_index, track in enumerate(root.findall(\".//audio/track\")):  # Iterate over all tracks within the <video> tag\n",
    "        track_targeted = track.attrib[\"MZ.TrackTargeted\"]\n",
    "        currentExplodedTrackIndex = track.attrib[\"currentExplodedTrackIndex\"]\n",
    "        for clip_item in track.findall(\"clipitem\"):  # Only consider clip items within the <video> tag\n",
    "            clip_info = {\n",
    "                \"id\": clip_item.attrib[\"id\"],  # Get the clip ID\n",
    "                \"name\": clip_item.find(\"name\").text,\n",
    "                \"duration\": int(clip_item.find(\"duration\").text),\n",
    "                \"rate\": {\n",
    "                    \"timebase\": int(clip_item.find(\"rate/timebase\").text),\n",
    "                    \"ntsc\": clip_item.find(\"rate/ntsc\").text == \"TRUE\",\n",
    "                },\n",
    "                \"in\": int(clip_item.find(\"in\").text),\n",
    "                \"out\": int(clip_item.find(\"out\").text),\n",
    "                \"start\": int(clip_item.find(\"start\").text),\n",
    "                \"end\": int(clip_item.find(\"end\").text),\n",
    "                \"track_index\": track_index+1,\n",
    "                \"MZ_TrackTargeted\": track_targeted,\n",
    "                \"currentExplodedTrackIndex\": currentExplodedTrackIndex,\n",
    "                \"audio_clip_element\": None,  # Store the clip item element for later use\n",
    "                \"sourceindex\": int(clip_item.find(\".//sourcetrack/trackindex\").text),\n",
    "            }\n",
    "            \n",
    "\n",
    "            # Check if the clip's in or out frame falls within the given start and end frames\n",
    "            if (\n",
    "                clip_info[\"start\"] <= start_frame <= clip_info[\"end\"]\n",
    "                or clip_info[\"start\"] <= end_frame <= clip_info[\"end\"]\n",
    "            ):\n",
    "                # Calculate the overlapped segment and the corresponding sequence segment\n",
    "                overlapped_segment = overlap((clip_info[\"start\"], clip_info[\"end\"]), (start_frame, end_frame))\n",
    "                if overlapped_segment is not None:\n",
    "                    overlap_start, overlap_end = overlapped_segment\n",
    "                    ratio_start = (overlap_start - clip_info[\"start\"]) / (clip_info[\"end\"] - clip_info[\"start\"])\n",
    "                    ratio_end = (overlap_end - clip_info[\"start\"]) / (clip_info[\"end\"] - clip_info[\"start\"])\n",
    "\n",
    "                    clip_start_time = 0 if audio_sequence_end == 0 else audio_sequence_end \n",
    "                    clip_end_time = clip_start_time + (overlap_end - overlap_start)\n",
    "\n",
    "                    # Update the clip's in, out, start, and end in the XML tree based on the overlapped segment\n",
    "                    clip_item.find(\"in\").text = str(clip_info[\"in\"] + round(ratio_start * (clip_info[\"out\"] - clip_info[\"in\"])))\n",
    "                    clip_item.find(\"out\").text = str(clip_info[\"in\"] + round(ratio_end * (clip_info[\"out\"] - clip_info[\"in\"])))\n",
    "                    clip_item.find(\"start\").text = str(clip_start_time)\n",
    "                    clip_item.find(\"end\").text = str(clip_end_time)\n",
    "\n",
    "\n",
    "                    clip_item.find(\"pproTicksIn\").text = str(frame_to_ticks(overlap_start, 24))\n",
    "                    clip_item.find(\"pproTicksOut\").text = str(frame_to_ticks(overlap_end, 24))\n",
    "\n",
    "\n",
    "                    clip_info[\"audio_clip_element\"] = clip_item\n",
    "                    audio_clips.append(clip_info)\n",
    "\n",
    "    if not audio_clips:  # Check if audio_clips list is empty\n",
    "        return None\n",
    "    else:\n",
    "        audio_sequence_start = 0 if audio_sequence_end == 0 else audio_sequence_end \n",
    "        audio_sequence_end = audio_sequence_start + (end_frame - start_frame)\n",
    "\n",
    "    # Create result dictionary\n",
    "    result = {\"audio_clips\": audio_clips}\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code Merges the rows which can be merged based on time and narrator name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions go through all the xml files and call the  extract clips function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_xml_files(xml_folder, start_time, end_time, narrator_name):\n",
    "    global xml_file_assigned,video_clip_list,audio_clip_list, sequence_start, sequence_end, audio_sequence_start, audio_sequence_end\n",
    "    for filename in os.listdir(xml_folder):\n",
    "        if filename.endswith(\".xml\") and narrator_name.lower() in filename.lower():\n",
    "            # print(filename,narrator_name)\n",
    "            xml_file = os.path.join(xml_folder, filename)\n",
    "            if xml_file not in xml_file_assigned:\n",
    "                update_xml_ids(xml_file)\n",
    "                xml_file_assigned.append(xml_file)\n",
    "            video_clips = extract_video_sequence(xml_file, start_time, end_time)\n",
    "            audio_clips = extract_audio_sequence(xml_file, start_time, end_time)\n",
    "            video_clip_list.append(video_clips)\n",
    "            audio_clip_list.append(audio_clips)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append Video to XML File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_video_to_xml(file_name, xml_json_data):\n",
    "    print(f\"Adding Video Tracks to {file_name}\")\n",
    "    # print(xml_json_data)\n",
    "    # Parse the XML data\n",
    "    tree = ET.parse(file_name)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Find the media element\n",
    "    media = root.find('.//media')\n",
    "\n",
    "    # Append the provided code inside the media element\n",
    "    video = ET.SubElement(media, \"video\")\n",
    "\n",
    "    # Add the format element with nested samplecharacteristics element\n",
    "    format_ = ET.SubElement(video, \"format\")\n",
    "    samplecharacteristics = ET.SubElement(format_, \"samplecharacteristics\")\n",
    "    \n",
    "    # Add the rate element with nested timebase and ntsc elements inside samplecharacteristics\n",
    "    rate = ET.SubElement(samplecharacteristics, \"rate\")\n",
    "    timebase = ET.SubElement(rate, \"timebase\")\n",
    "    timebase.text = \"24\"\n",
    "    ntsc = ET.SubElement(rate, \"ntsc\")\n",
    "    ntsc.text = \"TRUE\"\n",
    "    \n",
    "    # Add the codec element with nested name and appspecificdata elements\n",
    "    codec = ET.SubElement(samplecharacteristics, \"codec\")\n",
    "    name = ET.SubElement(codec, \"name\")\n",
    "    name.text = \"Apple ProRes 422\"\n",
    "    appspecificdata = ET.SubElement(codec, \"appspecificdata\")\n",
    "    \n",
    "    # Add the appname, appmanufacturer, and appversion elements inside appspecificdata\n",
    "    appname = ET.SubElement(appspecificdata, \"appname\")\n",
    "    appname.text = \"Final Cut Pro\"\n",
    "    appmanufacturer = ET.SubElement(appspecificdata, \"appmanufacturer\")\n",
    "    appmanufacturer.text = \"Apple Inc.\"\n",
    "    appversion = ET.SubElement(appspecificdata, \"appversion\")\n",
    "    appversion.text = \"7.0\"\n",
    "    \n",
    "    # Add the data element with nested qtcodec element inside appspecificdata\n",
    "    data = ET.SubElement(appspecificdata, \"data\")\n",
    "    qtcodec = ET.SubElement(data, \"qtcodec\")\n",
    "    codecname = ET.SubElement(qtcodec, \"codecname\")\n",
    "    codecname.text = \"Apple ProRes 422\"\n",
    "    codectypename = ET.SubElement(qtcodec, \"codectypename\")\n",
    "    codectypename.text = \"Apple ProRes 422\"\n",
    "    codectypecode = ET.SubElement(qtcodec, \"codectypecode\")\n",
    "    codectypecode.text = \"apcn\"\n",
    "    codecvendorcode = ET.SubElement(qtcodec, \"codecvendorcode\")\n",
    "    codecvendorcode.text = \"appl\"\n",
    "    spatialquality = ET.SubElement(qtcodec, \"spatialquality\")\n",
    "    spatialquality.text = \"1024\"\n",
    "    temporalquality = ET.SubElement(qtcodec, \"temporalquality\")\n",
    "    temporalquality.text = \"0\"\n",
    "    keyframerate = ET.SubElement(qtcodec, \"keyframerate\")\n",
    "    keyframerate.text = \"0\"\n",
    "    datarate = ET.SubElement(qtcodec, \"datarate\")\n",
    "    datarate.text = \"0\"\n",
    "    \n",
    "    # Add the width, height, anamorphic, pixelaspectratio, fielddominance, and colordepth elements inside samplecharacteristics\n",
    "    width = ET.SubElement(samplecharacteristics, \"width\")\n",
    "    width.text = \"1920\"\n",
    "    height = ET.SubElement(samplecharacteristics, \"height\")\n",
    "    height.text = \"1080\"\n",
    "    anamorphic = ET.SubElement(samplecharacteristics, \"anamorphic\")\n",
    "    anamorphic.text = \"FALSE\"\n",
    "    pixelaspectratio = ET.SubElement(samplecharacteristics, \"pixelaspectratio\")\n",
    "    pixelaspectratio.text = \"square\"\n",
    "    fielddominance = ET.SubElement(samplecharacteristics, \"fielddominance\")\n",
    "    fielddominance.text = \"none\"\n",
    "    colordepth = ET.SubElement(samplecharacteristics, \"colordepth\")\n",
    "    colordepth.text = \"24\"\n",
    "    video_tracks = []\n",
    "    # Get the track elements\n",
    "    for clip in xml_json_data:\n",
    "        for video_clip in clip[\"video_clips\"]:\n",
    "            if video_clip[\"track_index\"] not in video_tracks:\n",
    "                video_tracks.append({'MZ_TrackTargeted':video_clip[\"MZ_TrackTargeted\"],'track_index':video_clip[\"track_index\"]})\n",
    "\n",
    "    \n",
    "    # print(video_tracks,\"total video tracks\")\n",
    "    appended_video_clip=[]\n",
    "    \n",
    "    # Make video_tracks unique based on track_index\n",
    "    # video_tracks = [dict(t) for t in {tuple(d.items()) for d in video_tracks}]\n",
    "    \n",
    "\n",
    "\n",
    "    # Create video track elements and append video clips\n",
    "    print(video_tracks,\"total video tracks\")\n",
    "    for track in video_tracks:\n",
    "        video_track = ET.SubElement(video, \"track\", TL_SQTrackShy=\"0\", TL_SQTrackExpandedHeight=\"25\",\n",
    "                                    TL_SQTrackExpanded=\"0\", MZ_TrackTargeted=f\"{track['MZ_TrackTargeted']}\")\n",
    "        for clip in xml_json_data:\n",
    "            for video_clip in clip[\"video_clips\"]:\n",
    "                if int(track['track_index']) == int(video_clip[\"track_index\"]) and video_clip[\"new_id\"] not in appended_video_clip:\n",
    "                    video_track.append(copy.deepcopy(video_clip[\"video_clip_element\"]))\n",
    "                    appended_video_clip.append(video_clip[\"new_id\"])\n",
    "\n",
    "\n",
    "    # Save the modified XML to a new file\n",
    "    modified_tree = ET.ElementTree(root)\n",
    "    modified_tree.write(file_name)    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append Audio to XML File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def append_audio_to_xml(file_name, xml_json_data):\n",
    "    print(f\"Adding Audio Tracks to {file_name}\")\n",
    "    # Parse the XML data\n",
    "    audio_tracks = []\n",
    "    track_index = []\n",
    "    source_index = []\n",
    "    for clip in xml_json_data:\n",
    "        for audio_clip in clip[\"audio_clips\"]:\n",
    "            if audio_clip['currentExplodedTrackIndex'] not in track_index:\n",
    "                track_index.append(audio_clip['currentExplodedTrackIndex'])\n",
    "                source_index.append(audio_clip['sourceindex'])\n",
    "                audio_tracks.append({'source_index': audio_clip['sourceindex'],\n",
    "                                     'MZ_TrackTargeted': audio_clip['MZ_TrackTargeted'],\n",
    "                                     'currentExplodedTrackIndex':audio_clip['currentExplodedTrackIndex']})\n",
    "\n",
    "    audio_track_count = len(set(source_index))\n",
    "\n",
    "    # print('audio_tracks',audio_tracks)\n",
    "    # print('track_index',track_index)\n",
    "    # print('source_index',source_index)\n",
    "    # print('audio_track_count',audio_track_count)\n",
    "    \n",
    "    tree = ET.parse(file_name)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Find the media element\n",
    "    media = root.find('.//media')\n",
    "\n",
    "    # Add the audio element inside media\n",
    "    audio = ET.SubElement(media, \"audio\")\n",
    "\n",
    "    # constant stuff\n",
    "\n",
    "    # Create subelements and append them to the audio element\n",
    "    num_output_channels = ET.SubElement(audio, 'numOutputChannels')\n",
    "    num_output_channels.text = '2'\n",
    "\n",
    "    format_element = ET.SubElement(audio, 'format')\n",
    "    sample_characteristics = ET.SubElement(format_element, 'samplecharacteristics')\n",
    "    depth = ET.SubElement(sample_characteristics, 'depth')\n",
    "    depth.text = '16'\n",
    "    sample_rate = ET.SubElement(sample_characteristics, 'samplerate')\n",
    "    sample_rate.text = '48000'\n",
    "\n",
    "    outputs = ET.SubElement(audio, 'outputs')\n",
    "\n",
    "    group_1 = ET.SubElement(outputs, 'group')\n",
    "    index_1 = ET.SubElement(group_1, 'index')\n",
    "    index_1.text = '1'\n",
    "    num_channels_1 = ET.SubElement(group_1, 'numchannels')\n",
    "    num_channels_1.text = '1'\n",
    "    downmix_1 = ET.SubElement(group_1, 'downmix')\n",
    "    downmix_1.text = '0'\n",
    "    channel_1 = ET.SubElement(group_1, 'channel')\n",
    "    channel_index_1 = ET.SubElement(channel_1, 'index')\n",
    "    channel_index_1.text = '1'\n",
    "\n",
    "    group_2 = ET.SubElement(outputs, 'group')\n",
    "    index_2 = ET.SubElement(group_2, 'index')\n",
    "    index_2.text = '2'\n",
    "    num_channels_2 = ET.SubElement(group_2, 'numchannels')\n",
    "    num_channels_2.text = '1'\n",
    "    downmix_2 = ET.SubElement(group_2, 'downmix')\n",
    "    downmix_2.text = '0'\n",
    "    channel_2 = ET.SubElement(group_2, 'channel')\n",
    "    channel_index_2 = ET.SubElement(channel_2, 'index')\n",
    "    channel_index_2.text = '2'\n",
    "\n",
    "    appended_video_clip=[]\n",
    "\n",
    "     # Create audio track elements and append audio clips\n",
    "    for audio_track_index in audio_tracks:\n",
    "        audio_track = ET.SubElement(audio, \"track\", TL_SQTrackAudioKeyframeStyle=\"0\", TL_SQTrackShy=\"0\",\n",
    "                                    TL_SQTrackExpandedHeight=\"25\", TL_SQTrackExpanded=\"0\",\n",
    "                                    MZ_TrackTargeted=f\"{audio_track_index['MZ_TrackTargeted']}\", PannerCurrentValue=\"0.5\", PannerIsInverted=\"true\",\n",
    "                                    PannerStartKeyframe=\"-91445760000000000,0.5,0,0,0,0,0,0\", PannerName=\"Balance\",\n",
    "                                    currentExplodedTrackIndex=f\"{audio_track_index['currentExplodedTrackIndex']}\", totalExplodedTrackCount=f\"{audio_track_count}\",\n",
    "                                    premiereTrackType=\"Stereo\")\n",
    "\n",
    "        for clip in xml_json_data:\n",
    "            for audio_clip in clip[\"audio_clips\"]:\n",
    "                if int(audio_track_index['currentExplodedTrackIndex']) == int(audio_clip[\"currentExplodedTrackIndex\"]):\n",
    "                    audio_track.append(copy.deepcopy(audio_clip[\"audio_clip_element\"]))\n",
    "                    appended_video_clip.append(audio_clip[\"id\"])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Save the modified XML to a new file\n",
    "    modified_tree = ET.ElementTree(root)\n",
    "    modified_tree.write(file_name)\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracts the given clips from the xml files and saves them in a seperate xml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the run_extraction() function serves as the main entry point for running the extraction process. \n",
    "# It calls functions to process a CSV file, filter the resulting list of clips, \n",
    "# and creates an XML file with the audio and video from the filtered clipa\n",
    "\n",
    "def run_extraction(script_csv_file,exported_xml_project_name):\n",
    "    global video_clip_list,audio_clip_list     \n",
    "    video_clip_list = [item for item in video_clip_list if item is not None] \n",
    "    audio_clip_list = [item for item in audio_clip_list if item is not None]\n",
    "    \n",
    "    filename = create_xml(exported_xml_project_name)\n",
    "    \n",
    "    process_xml_files(xml_folder, start_time, end_time, narrator_name)\n",
    "\n",
    "    append_video_to_xml(f\"../xml exports/{filename}\", video_clip_list)\n",
    "    append_audio_to_xml(f\"../xml exports/{filename}\", audio_clip_list)\n",
    "    \n",
    "    print(video_clip_list)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
