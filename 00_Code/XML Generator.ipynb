{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Imports </h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "import csv\n",
    "import xml.etree.ElementTree as ET\n",
    "import copy\n",
    "import random\n",
    "import uuid\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Preprocess script csv</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert time format to seconds\n",
    "def time_to_seconds(time_str):\n",
    "    time_obj=time_str.split(\":\")\n",
    "    if len(time_obj)==2:\n",
    "        return int(time_obj[0]) * 60 + int(time_obj[1])\n",
    "    if len(time_obj)==3:\n",
    "        return int(time_obj[0]) * 60 + int(time_obj[1])+ int(time_obj[2])/24\n",
    "    else:\n",
    "        print(\"time obj broken\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to merge consecutive rows with start times within 10 seconds\n",
    "def merge_consecutive_rows(df):\n",
    "    merged_rows = []\n",
    "    current_row = None\n",
    "    \n",
    "    for index, row in df.dropna(how='all').iterrows():\n",
    "        if current_row is None:\n",
    "            current_row = row\n",
    "        else:\n",
    "            end_time_current = time_to_seconds(current_row['End Time'])\n",
    "            #print(row['Start Time'])\n",
    "            start_time_next = time_to_seconds(row['Start Time'])\n",
    "            if start_time_next >= end_time_current and start_time_next - end_time_current <= 6:\n",
    "                current_row['End Time'] = row['End Time']\n",
    "                current_row['Transcript'] += ' ' + row['Transcript']\n",
    "            else:\n",
    "                current_row['Duration'] = convert_time_to_frames(current_row['End Time'], 24) - convert_time_to_frames(current_row['Start Time'], 24)\n",
    "                merged_rows.append(current_row)\n",
    "                \n",
    "                current_row = row\n",
    "    \n",
    "    if current_row is not None:\n",
    "        current_row['Duration'] = convert_time_to_frames(current_row['End Time'], 24) - convert_time_to_frames(current_row['Start Time'], 24)\n",
    "        merged_rows.append(current_row)\n",
    "    \n",
    "    merged_df = pd.DataFrame(merged_rows)\n",
    "    return merged_df\n",
    "\n",
    "# script_df = merge_consecutive_rows(scriptCsv)\n",
    "# print(script_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>build xml structure</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_xml(xml_name):\n",
    "    \n",
    "    # Create the root element\n",
    "    root = ET.Element(\"xmeml\", version=\"4\")\n",
    "    \n",
    "    # Create the sequence element with attributes\n",
    "    sequence = ET.SubElement(root, \"sequence\", id=\"sequence-2\", TL_SQAudioVisibleBase=\"0\", TL_SQVideoVisibleBase=\"0\",\n",
    "                             TL_SQVisibleBaseTime=\"0\", TL_SQAVDividerPosition=\"0.5\", TL_SQHideShyTracks=\"0\",\n",
    "                             TL_SQHeaderWidth=\"236\", TL_SQDataTrackViewControlState=\"0\",\n",
    "                             Monitor_ProgramZoomOut=\"340011984312000\", Monitor_ProgramZoomIn=\"0\",\n",
    "                             TL_SQTimePerPixel=\"1.6034289012958367\", MZ_EditLine=\"333083126376000\",\n",
    "                             MZ_Sequence_PreviewFrameSizeHeight=\"1080\", MZ_Sequence_PreviewFrameSizeWidth=\"1920\",\n",
    "                             MZ_Sequence_AudioTimeDisplayFormat=\"200\", MZ_Sequence_PreviewUseMaxRenderQuality=\"false\",\n",
    "                             MZ_Sequence_PreviewUseMaxBitDepth=\"false\", MZ_Sequence_VideoTimeDisplayFormat=\"110\",\n",
    "                             MZ_WorkOutPoint=\"15235011792000\", MZ_WorkInPoint=\"0\", MZ_ZeroPoint=\"0\", explodedTracks=\"true\")\n",
    "    \n",
    "    # Add the uuid element\n",
    "    uuid = ET.SubElement(sequence, \"uuid\")\n",
    "    uuid.text = \"50e61931-251f-4069-8193-a3fbad7f93ff\"\n",
    "    \n",
    "    # Add the duration element\n",
    "    duration = ET.SubElement(sequence, \"duration\")\n",
    "    duration.text = \"31533\"\n",
    "    \n",
    "    # Add the rate element with nested timebase and ntsc elements\n",
    "    rate = ET.SubElement(sequence, \"rate\")\n",
    "    timebase = ET.SubElement(rate, \"timebase\")\n",
    "    timebase.text = \"24\"\n",
    "    ntsc = ET.SubElement(rate, \"ntsc\")\n",
    "    ntsc.text = \"TRUE\"\n",
    "    \n",
    "    # Add the name element\n",
    "    name_element = ET.SubElement(sequence, \"name\")\n",
    "    name_element.text = xml_name\n",
    "    \n",
    "    # Add the media element with nested video and audio elements\n",
    "    media = ET.SubElement(sequence, \"media\")\n",
    "\n",
    "    \n",
    "    # Add the timecode element with nested rate, string, frame, and displayformat elements\n",
    "    timecode = ET.SubElement(sequence, \"timecode\")\n",
    "    rate = ET.SubElement(timecode, \"rate\")\n",
    "    timebase = ET.SubElement(rate, \"timebase\")\n",
    "    timebase.text = \"24\"\n",
    "    ntsc = ET.SubElement(rate, \"ntsc\")\n",
    "    ntsc.text = \"TRUE\"\n",
    "    string = ET.SubElement(timecode, \"string\")\n",
    "    string.text = \"00:00:00:00\"\n",
    "    frame = ET.SubElement(timecode, \"frame\")\n",
    "    frame.text = \"0\"\n",
    "    displayformat = ET.SubElement(timecode, \"displayformat\")\n",
    "    displayformat.text = \"NDF\"\n",
    "    \n",
    "    # Add the labels element with nested label2 element\n",
    "    labels = ET.SubElement(sequence, \"labels\")\n",
    "    label2 = ET.SubElement(labels, \"label2\")\n",
    "    label2.text = \"Forest\"\n",
    "    \n",
    "\n",
    "    # Create the ElementTree object with the root element\n",
    "    tree = ET.ElementTree(root)\n",
    "    \n",
    "    # Generate a random Idd\n",
    "    idd = str(random.randint(1, 1000))\n",
    "    \n",
    "    # Save the XML to a file\n",
    "    filename = f\"{xml_name}-{idd}.xml\"\n",
    "    tree.write(f\"{filename}\", encoding=\"utf-8\", xml_declaration=True)\n",
    "    print(f\"XML saved to {filename}\")\n",
    "\n",
    "    return filename \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> try to refeactor these away</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_method = 'project_timecode'  # video_timecode or project_timecode \n",
    "\n",
    "id_mapping = {}\n",
    "# global sequence_start\n",
    "# global sequence_end\n",
    "subtitle_counter=1\n",
    "sequence_start=0\n",
    "sequence_end=0\n",
    "audio_sequence_start=0\n",
    "audio_sequence_end=0\n",
    "xml_file_assigned=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Helper functions for XML generation </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converts Time to Frames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78624"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_time_to_frames(time, rate):\n",
    "    # print('Time', time, 'Rate', rate)\n",
    "    parts = time.split(\":\")\n",
    "    \n",
    "    hours=0    #If they aren't defined, they are assumed to be 0\n",
    "    frames=0\n",
    "    \n",
    "    if len(parts)==4:\n",
    "        hours = int(parts[0])\n",
    "        minutes = int(parts[1])\n",
    "        seconds = int(parts[2])\n",
    "        frames = int(parts[3])\n",
    "\n",
    "    elif len(parts)==3:\n",
    "        hours = int(parts[0])\n",
    "        minutes = int(parts[1])\n",
    "        seconds = int(parts[2])\n",
    "        \n",
    "    elif len(parts)==2:\n",
    "        minutes = int(parts[0])\n",
    "        seconds = int(parts[1])\n",
    "        \n",
    "        # Calculate the total duration in frames\n",
    "    total_frames = (hours * 3600 * rate +  minutes * 60 * rate + seconds * rate)\n",
    "    \n",
    "    return total_frames\n",
    "\n",
    "convert_time_to_frames('00:54:36:38', 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1440"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_time_to_frames(\"1:00\",24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_to_ticks(frame_number, frame_rate):\n",
    "    total_ticks_in_a_second = 254016000000\n",
    "    tick_value = int((frame_number * total_ticks_in_a_second) / frame_rate)\n",
    "    return tick_value\n",
    "\n",
    "# frame_to_ticks(24, 24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> XML processing functions </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate New ids for the each Clip item in seperate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'clipitem-28319c896aa9462191015b4ea82b9306'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_unique_id():\n",
    "    unique_id = f\"clipitem-{uuid.uuid4().hex}\"\n",
    "    return unique_id\n",
    "\n",
    "generate_unique_id()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the id of clips in specific XML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_xml_ids(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    print('Assigning unique IDs to clipitem elements...')\n",
    "\n",
    "    # Generate unique IDs for clipitem elements\n",
    "      # Store the mapping of old IDs to new unique IDs\n",
    "    for clip_item in root.findall('.//clipitem'):  # Adjust the XPath expression based on the actual location of clipitem elements\n",
    "        current_id = clip_item.attrib['id']\n",
    "        unique_id = generate_unique_id()\n",
    "        id_mapping[current_id] = unique_id\n",
    "        clip_item.attrib['id'] = unique_id\n",
    "\n",
    "    \n",
    "        # Update the references in the links section\n",
    "    for link in root.findall('.//link'):\n",
    "        linkclipref = link.find('linkclipref')\n",
    "        if linkclipref is not None and linkclipref.text in id_mapping:\n",
    "            linkclipref.text = id_mapping[linkclipref.text]\n",
    "    #print(id_mapping)\n",
    "\n",
    "    # Save the modified XML file\n",
    "    tree.write(xml_file, encoding=\"utf-8\")\n",
    "\n",
    "# update_xml_ids(xml_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract time in  start and end time format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('00:00:00:00', '00:23:00:00')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_timecode(timecode_range):\n",
    "    start_time, end_time = timecode_range.split(\" - \")\n",
    "    start_time = start_time.strip().replace(\" \", \"\")\n",
    "    end_time = end_time.strip().replace(\" \", \"\")\n",
    "    # print('Start Time',start_time,'End Time', end_time)\n",
    "    return start_time, end_time\n",
    "\n",
    "extract_timecode(\"00:00:00:00 - 00:23:00:00\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Extract sequences </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract sequence info through xml file and extract the clips that match with the start and end time using frame comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "###this isn't being used at the moment, but it looks like this could be a good function to integrate into the createXml if needed (although the sequence settings are so standardized this doesn't seem needed)\n",
    "\n",
    "def extract_sequence_info(xml_file, start_time, end_time):\n",
    "    global sequence_start, sequence_end\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Extract sequence information\n",
    "    sequence = root.find(\"sequence\")\n",
    "    sequence_info = {\n",
    "        \"duration\": int(sequence.find(\"duration\").text),\n",
    "        \"rate\": {\n",
    "            \"timebase\": int(sequence.find(\"rate/timebase\").text),\n",
    "            \"ntsc\": sequence.find(\"rate/ntsc\").text == \"TRUE\",\n",
    "        },\n",
    "    }\n",
    "    sequence_rate = sequence_info[\"rate\"][\"timebase\"]\n",
    "\n",
    "    # Convert start and end times to frames\n",
    "    start_frame = convert_time_to_frames(start_time, 24)\n",
    "    end_frame = convert_time_to_frames(end_time, 24)\n",
    "    proTickIn = frame_to_ticks(start_frame, 24)\n",
    "    proTickOut = frame_to_ticks(end_frame, 24)\n",
    "\n",
    "    total_clip_frames = end_frame - start_frame\n",
    "    total_clip_proticks = proTickOut - proTickIn\n",
    "\n",
    "    # print('Start and End Frame',start_frame ,end_frame)\n",
    "    # print(sequence_rate,'sequence_rate')\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ###check if this was refactored into extract_video_sequence function\n",
    "\n",
    "#     # Extract video clip information\n",
    "#     video_clips = []\n",
    "#     for track_index, track in enumerate(root.findall(\".//video/track\")):  # Iterate over all tracks within the <video> tag\n",
    "#         # track_idx = 0\n",
    "#         track_targeted = track.attrib[\"MZ.TrackTargeted\"]\n",
    "#         for clip_item in track.findall(\"clipitem\"):  # Only consider clip items within the <video> tag\n",
    "            \n",
    "#             video_start_cut_diff=abs(start_frame - int(clip_item.find(\"start\").text))\n",
    "#             video_end_cut_diff=abs(end_frame - int(clip_item.find(\"end\").text))\n",
    "#             extracted_clip_duration=end_time-start_time\n",
    "#             actual_clip_duration=int(clip_item.find(\"duration\").text)\n",
    "\n",
    "\n",
    "#             links = clip_item.findall(\"link\")\n",
    "#             track_idx = [\n",
    "#                 int(link.find(\"trackindex\").text)\n",
    "#                 for link in clip_item.findall(\"link\")\n",
    "#                 if link.find(\"mediatype\").text == \"video\"\n",
    "#             ]\n",
    "#             print(\"Track Index\", track_idx)\n",
    "#             print(\"Clip ID\", clip_item.attrib[\"id\"])\n",
    "\n",
    "#             clip_info = {\n",
    "#                 \"id\": clip_item.attrib[\"id\"],  # Get the clip ID\n",
    "#                 \"name\": clip_item.find(\"name\").text,\n",
    "#                 \"duration\": int(clip_item.find(\"duration\").text),\n",
    "#                 \"rate\": {\n",
    "#                     \"timebase\": int(clip_item.find(\"rate/timebase\").text),\n",
    "#                     \"ntsc\": clip_item.find(\"rate/ntsc\").text == \"TRUE\",\n",
    "#                 },\n",
    "#                 \"in\": int(clip_item.find(\"in\").text),\n",
    "#                 \"out\": int(clip_item.find(\"out\").text),\n",
    "#                 \"start\": int(clip_item.find(\"start\").text),\n",
    "#                 \"end\": int(clip_item.find(\"end\").text),\n",
    "#                 \"track_index\": track_index+1,\n",
    "#                 \"MZ_TrackTargeted\": track_targeted,\n",
    "#                 \"links\": [],  # Initialize an empty list to store links,\n",
    "#                 \"video_clip_element\": None,  # Store the clip item element for later use\n",
    "#                 \"linked_audio_clip_elements_list\": [],  # Initialize an empty list to store linked clip items\n",
    "#             }\n",
    "\n",
    "#             if extract_method == \"video_timecode\":\n",
    "#                 clip_comparison = (\n",
    "#                     clip_info[\"in\"] <= start_frame <= clip_info[\"out\"]\n",
    "#                 ) or (clip_info[\"in\"] <= end_frame <= clip_info[\"out\"])\n",
    "#             else:\n",
    "#                 clip_comparison = (\n",
    "#                     clip_info[\"start\"] <= start_frame <= clip_info[\"end\"]\n",
    "#                 ) or (clip_info[\"start\"] <= end_frame <= clip_info[\"end\"])\n",
    "\n",
    "            \n",
    "\n",
    "#             for link in links:\n",
    "#                 link_info = {\n",
    "#                     \"linkclipref\": link.find(\"linkclipref\").text,\n",
    "#                     \"mediatype\": link.find(\"mediatype\").text,\n",
    "#                     \"trackindex\": int(link.find(\"trackindex\").text),\n",
    "#                     \"clipindex\": int(link.find(\"clipindex\").text),\n",
    "#                 }\n",
    "#                 if link.find(\"groupindex\") is not None:\n",
    "#                     link_info[\"groupindex\"] = int(link.find(\"groupindex\").text)\n",
    "#                 clip_info[\"links\"].append(link_info)\n",
    "#                 if link.find(\"mediatype\").text == \"audio\":\n",
    "#                     audio_clip_items = root.findall(\".//audio//clipitem\")\n",
    "#                     for audio_clip_item in audio_clip_items:\n",
    "#                         if (\n",
    "#                             audio_clip_item.attrib[\"id\"]\n",
    "#                             == link.find(\"linkclipref\").text\n",
    "#                         ):\n",
    "#                             audio_clip_item.find(\"in\").text = str(start_frame)\n",
    "#                             audio_clip_item.find(\"out\").text = str(end_frame)\n",
    "                              \n",
    "#                             audio_clip_item.find(\"start\").text = str(sequence_start)\n",
    "#                             audio_clip_item.find(\"end\").text = str(sequence_end)\n",
    "#                             audio_clip_item.find(\"pproTicksIn\").text = str(proTickIn)\n",
    "#                             audio_clip_item.find(\"pproTicksOut\").text = str(proTickOut)\n",
    "                                \n",
    "                            \n",
    "#                             clip_info[\"linked_audio_clip_elements_list\"].append(\n",
    "#                                 {\n",
    "#                                     \"audio_clip_item\": audio_clip_item,\n",
    "#                                     \"trackindex\": int(link.find(\"trackindex\").text),\n",
    "#                                     \"sourceindex\": int(\n",
    "#                                         audio_clip_item.find(\n",
    "#                                             \".//sourcetrack/trackindex\"\n",
    "#                                         ).text\n",
    "#                                     ),\n",
    "#                                 }\n",
    "#                             )\n",
    "\n",
    "#             # Check if the clip's in or out frame falls within the given start and end frames\n",
    "#             # print('Clip Frame Inside file Found: ',clip_info['in'] <= start_frame <= clip_info['out'])\n",
    "#             print(\n",
    "#                 \"Clip Frame Inside file Found: \",\n",
    "#                 clip_info[\"start\"] <= start_frame <= clip_info[\"end\"]\n",
    "#                 or clip_info[\"start\"] <= end_frame <= clip_info[\"end\"],\n",
    "#             )\n",
    "#             print(\"clip_comparison\", clip_comparison)\n",
    "#             print(\"In - Matching - Out\")\n",
    "#             # print(clip_info['in'],start_frame,clip_info['out'])\n",
    "#             print(clip_info[\"start\"], start_frame, clip_info[\"end\"])\n",
    "#             print(clip_info[\"start\"], end_frame, clip_info[\"end\"])\n",
    "#             if clip_comparison:\n",
    "#                 clip_item.find(\"in\").text = str(start_frame)\n",
    "#                 clip_item.find(\"out\").text = (\n",
    "#                     str(end_frame)\n",
    "#                     if extract_method == \"video_timecode\"\n",
    "#                     else str(start_frame + total_clip_frames)\n",
    "#                 )\n",
    "#                 clip_item.find(\"start\").text = str(sequence_start)\n",
    "#                 clip_item.find(\"end\").text = str(sequence_end)\n",
    "#                 clip_item.find(\"pproTicksIn\").text = str(proTickIn)\n",
    "#                 clip_item.find(\"pproTicksOut\").text = (\n",
    "#                     str(proTickOut)\n",
    "#                     if extract_method == \"video_timecode\"\n",
    "#                     else str(proTickIn + total_clip_proticks)\n",
    "#                 )\n",
    "#                 clip_info[\"video_clip_element\"] = clip_item\n",
    "#                 video_clips.append(clip_info)\n",
    "#                 print(\"Next Sequence Start\", sequence_start)\n",
    "#                 print(\"Next Sequence End\", sequence_end)\n",
    "\n",
    "#     # print(clip_info, start_frame, end_frame)\n",
    "\n",
    "#     # Create result dictionary\n",
    "#     result = { \"video_clips\": video_clips}\n",
    "#     # print('Result',result)\n",
    "\n",
    "#     if not video_clips:  # Check if video_clips list is empty\n",
    "#         return None\n",
    "\n",
    "    \n",
    "#      return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overlap Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract Video sequences from the xml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_video_sequence(xml_file,row,offset_time):\n",
    "    print(row)\n",
    "    #these start and end times are from the transcripts\n",
    "    start_time=row[\"Start Time\"]\n",
    "    end_time=row[\"End Time\"]\n",
    "    \n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Convert start and end times to frames\n",
    "    start_frame = convert_time_to_frames(start_time, 24)\n",
    "    end_frame = convert_time_to_frames(end_time, 24)\n",
    "\n",
    "\n",
    "    # Extract video clip information\n",
    "    video_clips = []\n",
    "    \n",
    "    for track_index, track in enumerate(root.findall(\".//video/track\")):  # Iterate over all tracks within the <video> tag\n",
    "        track_targeted = track.attrib[\"MZ.TrackTargeted\"]\n",
    "        for clip_item in track.findall(\"clipitem\"):  # Only consider clip items within the <video> \n",
    "\n",
    "            clip_info = {\n",
    "                \"id\": clip_item.attrib[\"id\"],  # Get the clip ID\n",
    "                \"new_id\": generate_unique_id(),  # Generate a new unique ID for the clip item\",\n",
    "                \"name\": clip_item.find(\"name\").text,\n",
    "                \"duration\": int(clip_item.find(\"duration\").text),\n",
    "                \"rate\": {\n",
    "                    \"timebase\": int(clip_item.find(\"rate/timebase\").text),\n",
    "                    \"ntsc\": clip_item.find(\"rate/ntsc\").text == \"TRUE\",\n",
    "                },\n",
    "                \"in\": int(clip_item.find(\"in\").text),\n",
    "                \"out\": int(clip_item.find(\"out\").text),\n",
    "                \"start\": int(clip_item.find(\"start\").text),\n",
    "                \"end\": int(clip_item.find(\"end\").text),\n",
    "                \"track_index\": track_index+1,\n",
    "                \"MZ_TrackTargeted\": track_targeted,\n",
    "                \"video_clip_element\": None,  # Store the clip item element for later use,\n",
    "                \"type\":\"video\",\n",
    "                \"text\":row[\"Transcript\"],\n",
    "                \"interview\":row[\"Interview\"],\n",
    "                \"speaker\":row[\"Speaker\"],\n",
    "                \"duration\":row[\"Duration\"]\n",
    "            }\n",
    "\n",
    "            # Check if the clip's in or out frame falls within the given start and end frames\n",
    "            if (\n",
    "                clip_info[\"start\"] <= start_frame <= clip_info[\"end\"]\n",
    "                or clip_info[\"start\"] <= end_frame <= clip_info[\"end\"]\n",
    "            ):\n",
    "                new_cutoff_left= start_frame - clip_info[\"start\"]                 \n",
    "                if new_cutoff_left<0:\n",
    "                    new_cutoff_left=0\n",
    "                \n",
    "                new_cutoff_right= clip_info[\"end\"]-end_frame\n",
    "                if new_cutoff_right<0:\n",
    "                    new_cutoff_right=0\n",
    "\n",
    "                new_in = clip_info[\"in\"] + new_cutoff_left\n",
    "                new_out = clip_info[\"out\"] - new_cutoff_right\n",
    "                new_start = int(clip_info[\"start\"]-start_frame)\n",
    "                if new_start<0:\n",
    "                    new_start=0\n",
    "                new_start+=offset_time\n",
    "                new_end = new_start+(new_out-new_in)\n",
    "                \n",
    "                \n",
    "                #print(offset_time,new_in,new_out,new_start,new_end,row[\"Transcript\"])\n",
    "                \n",
    "                # Update the clip's in, out, start, and end in the XML tree based on the overlapped segment\n",
    "                clip_item.find(\"in\").text = str(new_in) #+ round(ratio_start * (clip_info[\"out\"] - clip_info[\"in\"])))\n",
    "                clip_item.find(\"out\").text = str(new_out) #+ round(ratio_end * (clip_info[\"out\"] - clip_info[\"in\"])))\n",
    "                clip_item.find(\"start\").text = str(new_start)\n",
    "                clip_item.find(\"end\").text = str(new_end)\n",
    "                \n",
    "                #these aren't used, just for the csv\n",
    "                # Update the clip's in, out, start, and end in the XML tree based on the overlapped segment\n",
    "                clip_info[\"in\"] = str(new_in) #+ round(ratio_start * (clip_info[\"out\"] - clip_info[\"in\"])))\n",
    "                clip_info[\"out\"] = str(new_out) #+ round(ratio_end * (clip_info[\"out\"] - clip_info[\"in\"])))\n",
    "                clip_info[\"start\"] = str(new_start)\n",
    "                clip_info[\"end\"] = str(new_end)\n",
    "                \n",
    "\n",
    "                clip_info[\"video_clip_element\"] = clip_item\n",
    "                #print(clip_info)\n",
    "\n",
    "                video_clips.append(clip_info)\n",
    "                \n",
    "    return video_clips\n",
    "\n",
    "# Test the function with the given XML file and start/end times\n",
    "# extract_video_sequence('ben - synced.xml', '00:00:00:00', '00:00:10:00')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract Audio sequences from the xml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio_sequence(xml_file, row,offset_time):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    start_time=row[\"Start Time\"]\n",
    "    end_time=row[\"End Time\"]\n",
    "\n",
    "    global audio_sequence_start ,audio_sequence_end\n",
    "\n",
    "    # Convert start and end times to frames\n",
    "    start_frame = convert_time_to_frames(start_time, 24)\n",
    "    end_frame = convert_time_to_frames(end_time, 24)\n",
    "\n",
    "    # Extract audio clip information\n",
    "    audio_clips = []\n",
    "    for track_index, track in enumerate(root.findall(\".//audio/track\")):  # Iterate over all tracks within the <video> tag\n",
    "        track_targeted = track.attrib[\"MZ.TrackTargeted\"]\n",
    "        currentExplodedTrackIndex = track.attrib[\"currentExplodedTrackIndex\"]\n",
    "        for clip_item in track.findall(\"clipitem\"):  # Only consider clip items within the <video> tag\n",
    "            clip_info = {\n",
    "                \"id\": clip_item.attrib[\"id\"],  # Get the clip ID\n",
    "                \"name\": clip_item.find(\"name\").text,\n",
    "                \"duration\": int(clip_item.find(\"duration\").text),\n",
    "                \"rate\": {\n",
    "                    \"timebase\": int(clip_item.find(\"rate/timebase\").text),\n",
    "                    \"ntsc\": clip_item.find(\"rate/ntsc\").text == \"TRUE\",\n",
    "                },\n",
    "                \"in\": int(clip_item.find(\"in\").text),\n",
    "                \"out\": int(clip_item.find(\"out\").text),\n",
    "                \"start\": int(clip_item.find(\"start\").text),\n",
    "                \"end\": int(clip_item.find(\"end\").text),\n",
    "                \"track_index\": track_index+1,\n",
    "                \"MZ_TrackTargeted\": track_targeted,\n",
    "                \"currentExplodedTrackIndex\": currentExplodedTrackIndex,\n",
    "                #\"audio_clip_element\": None,  # Store the clip item element for later use\n",
    "                \"sourceindex\": int(clip_item.find(\".//sourcetrack/trackindex\").text),\n",
    "                \"type\":\"audio\",\n",
    "                \"text\":row[\"Transcript\"],\n",
    "                \"interview\":row[\"Interview\"],\n",
    "                \"speaker\":row[\"Speaker\"],\n",
    "            }\n",
    "            \n",
    "\n",
    "            # Check if the clip's in or out frame falls within the given start and end frames\n",
    "            if (\n",
    "                clip_info[\"start\"] <= start_frame <= clip_info[\"end\"]\n",
    "                or clip_info[\"start\"] <= end_frame <= clip_info[\"end\"]\n",
    "            ):\n",
    "               \n",
    "                new_cutoff_left= start_frame - clip_info[\"start\"]\n",
    "                if new_cutoff_left<0:\n",
    "                    new_cutoff_left=0\n",
    "                \n",
    "                new_cutoff_right= clip_info[\"end\"]-end_frame\n",
    "                if new_cutoff_right<0:\n",
    "                    new_cutoff_right=0\n",
    "\n",
    "                new_in = clip_info[\"in\"] + new_cutoff_left\n",
    "                new_out = clip_info[\"out\"] - new_cutoff_right\n",
    "                new_start = int(clip_info[\"start\"]-start_frame)\n",
    "                if new_start<0:\n",
    "                    new_start=0\n",
    "                new_start+=offset_time\n",
    "                new_end = new_start+(new_out-new_in)\n",
    "                \n",
    "                                \n",
    "                # Update the clip's in, out, start, and end in the XML tree based on the overlapped segment\n",
    "                clip_item.find(\"in\").text = str(new_in) #+ round(ratio_start * (clip_info[\"out\"] - clip_info[\"in\"])))\n",
    "                clip_item.find(\"out\").text = str(new_out) #+ round(ratio_end * (clip_info[\"out\"] - clip_info[\"in\"])))\n",
    "                clip_item.find(\"start\").text = str(new_start)\n",
    "                clip_item.find(\"end\").text = str(new_end)\n",
    "                \n",
    "                #these aren't used, just for the csv\n",
    "                # Update the clip's in, out, start, and end in the XML tree based on the overlapped segment\n",
    "                clip_info[\"in\"] = str(new_in) #+ round(ratio_start * (clip_info[\"out\"] - clip_info[\"in\"])))\n",
    "                clip_info[\"out\"] = str(new_out) #+ round(ratio_end * (clip_info[\"out\"] - clip_info[\"in\"])))\n",
    "                clip_info[\"start\"] = str(new_start)\n",
    "                clip_info[\"end\"] = str(new_end)\n",
    "\n",
    "\n",
    "                clip_item.find(\"pproTicksIn\").text = str(frame_to_ticks(new_in, 24))\n",
    "                clip_item.find(\"pproTicksOut\").text = str(frame_to_ticks(new_out, 24))\n",
    "\n",
    "                clip_info[\"audio_clip_element\"] = clip_item\n",
    "                audio_clips.append(clip_info)\n",
    "\n",
    "    # Create result dictionary\n",
    "    return audio_clips\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions go through all the xml files and call the  extract clips function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_csv_file(csv_file,project_name):\n",
    "\n",
    "    video_clips=[]\n",
    "    audio_clips=[]\n",
    "    \n",
    "    dfList=[]\n",
    "    \n",
    "    offset_time=0\n",
    "    for index, row in csv_file.iterrows():\n",
    "\n",
    "        xml_file = os.path.join( \"../03_Interview XML/\"+project_name, row[\"Interview\"]+\" - final.xml\")\n",
    "\n",
    "        #the call here to extract_video/audio_sequences is where the magic happens\n",
    "        new_video_clips=extract_video_sequence(xml_file, row,offset_time)\n",
    "        new_audio_clips=extract_audio_sequence(xml_file, row,offset_time)\n",
    "        dfList+=new_audio_clips\n",
    "        dfList+=new_video_clips\n",
    "        offset_time+=row[\"Duration\"]\n",
    "    \n",
    "    df=pd.DataFrame.from_records(dfList)\n",
    "    #print(\"result\",result)\n",
    "    return df\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append Video to XML File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_video_to_xml(file_name, xml_data):\n",
    "    print(f\"Adding Video Tracks to {file_name}\")\n",
    "    # print(xml_json_data)\n",
    "    # Parse the XML data\n",
    "    tree = ET.parse(file_name)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Find the media element\n",
    "    media = root.find('.//media')\n",
    "\n",
    "    # Append the provided code inside the media element\n",
    "    video = ET.SubElement(media, \"video\")\n",
    "\n",
    "    # Add the format element with nested samplecharacteristics element\n",
    "    format_ = ET.SubElement(video, \"format\")\n",
    "    samplecharacteristics = ET.SubElement(format_, \"samplecharacteristics\")\n",
    "    \n",
    "    # Add the rate element with nested timebase and ntsc elements inside samplecharacteristics\n",
    "    rate = ET.SubElement(samplecharacteristics, \"rate\")\n",
    "    timebase = ET.SubElement(rate, \"timebase\")\n",
    "    timebase.text = \"24\"\n",
    "    ntsc = ET.SubElement(rate, \"ntsc\")\n",
    "    ntsc.text = \"TRUE\"\n",
    "    \n",
    "    # Add the codec element with nested name and appspecificdata elements\n",
    "    codec = ET.SubElement(samplecharacteristics, \"codec\")\n",
    "    name = ET.SubElement(codec, \"name\")\n",
    "    name.text = \"Apple ProRes 422\"\n",
    "    appspecificdata = ET.SubElement(codec, \"appspecificdata\")\n",
    "    \n",
    "    # Add the appname, appmanufacturer, and appversion elements inside appspecificdata\n",
    "    appname = ET.SubElement(appspecificdata, \"appname\")\n",
    "    appname.text = \"Final Cut Pro\"\n",
    "    appmanufacturer = ET.SubElement(appspecificdata, \"appmanufacturer\")\n",
    "    appmanufacturer.text = \"Apple Inc.\"\n",
    "    appversion = ET.SubElement(appspecificdata, \"appversion\")\n",
    "    appversion.text = \"7.0\"\n",
    "    \n",
    "    # Add the data element with nested qtcodec element inside appspecificdata\n",
    "    data = ET.SubElement(appspecificdata, \"data\")\n",
    "    qtcodec = ET.SubElement(data, \"qtcodec\")\n",
    "    codecname = ET.SubElement(qtcodec, \"codecname\")\n",
    "    codecname.text = \"Apple ProRes 422\"\n",
    "    codectypename = ET.SubElement(qtcodec, \"codectypename\")\n",
    "    codectypename.text = \"Apple ProRes 422\"\n",
    "    codectypecode = ET.SubElement(qtcodec, \"codectypecode\")\n",
    "    codectypecode.text = \"apcn\"\n",
    "    codecvendorcode = ET.SubElement(qtcodec, \"codecvendorcode\")\n",
    "    codecvendorcode.text = \"appl\"\n",
    "    spatialquality = ET.SubElement(qtcodec, \"spatialquality\")\n",
    "    spatialquality.text = \"1024\"\n",
    "    temporalquality = ET.SubElement(qtcodec, \"temporalquality\")\n",
    "    temporalquality.text = \"0\"\n",
    "    keyframerate = ET.SubElement(qtcodec, \"keyframerate\")\n",
    "    keyframerate.text = \"0\"\n",
    "    datarate = ET.SubElement(qtcodec, \"datarate\")\n",
    "    datarate.text = \"0\"\n",
    "    \n",
    "    # Add the width, height, anamorphic, pixelaspectratio, fielddominance, and colordepth elements inside samplecharacteristics\n",
    "    width = ET.SubElement(samplecharacteristics, \"width\")\n",
    "    width.text = \"1920\"\n",
    "    height = ET.SubElement(samplecharacteristics, \"height\")\n",
    "    height.text = \"1080\"\n",
    "    anamorphic = ET.SubElement(samplecharacteristics, \"anamorphic\")\n",
    "    anamorphic.text = \"FALSE\"\n",
    "    pixelaspectratio = ET.SubElement(samplecharacteristics, \"pixelaspectratio\")\n",
    "    pixelaspectratio.text = \"square\"\n",
    "    fielddominance = ET.SubElement(samplecharacteristics, \"fielddominance\")\n",
    "    fielddominance.text = \"none\"\n",
    "    colordepth = ET.SubElement(samplecharacteristics, \"colordepth\")\n",
    "    colordepth.text = \"24\"\n",
    "    \n",
    "    video_tracks = []   \n",
    "    for index,clip in xml_data.iterrows():\n",
    "        video_tracks.append({'MZ_TrackTargeted':clip[\"MZ_TrackTargeted\"],'track_index':clip[\"track_index\"]})\n",
    "    #print(\"preDict\",video_tracks)\n",
    "\n",
    "    # Make video_tracks unique based on track_index\n",
    "    video_tracks = [dict(t) for t in {tuple(d.items()) for d in video_tracks}]\n",
    "    #print(video_tracks)\n",
    "\n",
    "    # Create video track elements and append video clips\n",
    "    for track in video_tracks:\n",
    "        video_track = ET.SubElement(video, \"track\", TL_SQTrackShy=\"0\", TL_SQTrackExpandedHeight=\"25\",\n",
    "                                    TL_SQTrackExpanded=\"0\", MZ_TrackTargeted=f\"{track['MZ_TrackTargeted']}\")\n",
    "        track_data=xml_data[xml_data[\"track_index\"]==track['track_index']]\n",
    "        for index,row in track_data.iterrows():\n",
    "            video_track.append(copy.deepcopy(row[\"video_clip_element\"]))\n",
    "\n",
    "    # Save the modified XML to a new file\n",
    "    modified_tree = ET.ElementTree(root)\n",
    "    modified_tree.write(file_name)    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append Audio to XML File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def append_audio_to_xml(file_name, xml_data):\n",
    "    print(f\"Adding Audio Tracks to {file_name}\")\n",
    "    # Parse the XML data\n",
    "    audio_tracks = []\n",
    "    track_index = []\n",
    "    source_index = []\n",
    "    for index,audio_clip in xml_data.iterrows():\n",
    "        if audio_clip['currentExplodedTrackIndex'] not in track_index:\n",
    "            track_index.append(audio_clip['currentExplodedTrackIndex'])\n",
    "            source_index.append(audio_clip['sourceindex'])\n",
    "            audio_tracks.append({'source_index': audio_clip['sourceindex'],\n",
    "                                 'MZ_TrackTargeted': audio_clip['MZ_TrackTargeted'],\n",
    "                                 'currentExplodedTrackIndex':audio_clip['currentExplodedTrackIndex']})\n",
    "\n",
    "    audio_track_count = len(set(source_index))\n",
    "\n",
    "    # print('audio_tracks',audio_tracks)\n",
    "    # print('track_index',track_index)\n",
    "    # print('source_index',source_index)\n",
    "    # print('audio_track_count',audio_track_count)\n",
    "    \n",
    "    tree = ET.parse(file_name)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Find the media element\n",
    "    media = root.find('.//media')\n",
    "\n",
    "    # Add the audio element inside media\n",
    "    audio = ET.SubElement(media, \"audio\")\n",
    "\n",
    "    # constant stuff\n",
    "\n",
    "    # Create subelements and append them to the audio element\n",
    "    num_output_channels = ET.SubElement(audio, 'numOutputChannels')\n",
    "    num_output_channels.text = '2'\n",
    "\n",
    "    format_element = ET.SubElement(audio, 'format')\n",
    "    sample_characteristics = ET.SubElement(format_element, 'samplecharacteristics')\n",
    "    depth = ET.SubElement(sample_characteristics, 'depth')\n",
    "    depth.text = '16'\n",
    "    sample_rate = ET.SubElement(sample_characteristics, 'samplerate')\n",
    "    sample_rate.text = '48000'\n",
    "\n",
    "    outputs = ET.SubElement(audio, 'outputs')\n",
    "\n",
    "    group_1 = ET.SubElement(outputs, 'group')\n",
    "    index_1 = ET.SubElement(group_1, 'index')\n",
    "    index_1.text = '1'\n",
    "    num_channels_1 = ET.SubElement(group_1, 'numchannels')\n",
    "    num_channels_1.text = '1'\n",
    "    downmix_1 = ET.SubElement(group_1, 'downmix')\n",
    "    downmix_1.text = '0'\n",
    "    channel_1 = ET.SubElement(group_1, 'channel')\n",
    "    channel_index_1 = ET.SubElement(channel_1, 'index')\n",
    "    channel_index_1.text = '1'\n",
    "\n",
    "    group_2 = ET.SubElement(outputs, 'group')\n",
    "    index_2 = ET.SubElement(group_2, 'index')\n",
    "    index_2.text = '2'\n",
    "    num_channels_2 = ET.SubElement(group_2, 'numchannels')\n",
    "    num_channels_2.text = '1'\n",
    "    downmix_2 = ET.SubElement(group_2, 'downmix')\n",
    "    downmix_2.text = '0'\n",
    "    channel_2 = ET.SubElement(group_2, 'channel')\n",
    "    channel_index_2 = ET.SubElement(channel_2, 'index')\n",
    "    channel_index_2.text = '2'\n",
    "\n",
    "    \n",
    "     # Create audio track elements and append audio clips\n",
    "    for audio_track_index in audio_tracks:\n",
    "        #print(audio_track_index)\n",
    "        audio_track = ET.SubElement(audio, \"track\", TL_SQTrackAudioKeyframeStyle=\"0\", TL_SQTrackShy=\"0\",\n",
    "                                    TL_SQTrackExpandedHeight=\"25\", TL_SQTrackExpanded=\"0\",\n",
    "                                    MZ_TrackTargeted=f\"{audio_track_index['MZ_TrackTargeted']}\", PannerCurrentValue=\"0.5\", PannerIsInverted=\"true\",\n",
    "                                    PannerStartKeyframe=\"-91445760000000000,0.5,0,0,0,0,0,0\", PannerName=\"Balance\",\n",
    "                                    currentExplodedTrackIndex=f\"{audio_track_index['currentExplodedTrackIndex']}\", totalExplodedTrackCount=f\"{audio_track_count}\",\n",
    "                                    premiereTrackType=\"Stereo\")\n",
    "\n",
    "        for index,audio_clip in xml_data.iterrows():\n",
    "            if int(audio_track_index['currentExplodedTrackIndex']) == int(audio_clip[\"currentExplodedTrackIndex\"]):\n",
    "                audio_track.append(copy.deepcopy(audio_clip[\"audio_clip_element\"]))\n",
    "                   # Save the modified XML to a new file\n",
    "    modified_tree = ET.ElementTree(root)\n",
    "    modified_tree.write(file_name)\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Run the processing for a script </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Speaker Interview Start Time End Time  Duration (Seconds)  \\\n",
      "0   Magalys   wolunka      01:00    01:21            4.380952   \n",
      "5   Magalys   wolunka      00:24    00:42            3.802817   \n",
      "10  Magalys   wolunka      00:01    00:19            3.701923   \n",
      "15  Magalys   wolunka      00:44    00:58            4.000000   \n",
      "\n",
      "                                           Transcript  Duration  \n",
      "0   I am glad to know the place where Wolunka was....       504  \n",
      "5   TRUE. In fact, in our culture it is necessary ...       432  \n",
      "10  Well Neko, you are entering the Macuira mounta...       432  \n",
      "15  That's why I'm here in your territory Magalys....       336  \n",
      "Speaker                                                         Magalys\n",
      "Interview                                                       wolunka\n",
      "Start Time                                                        01:00\n",
      "End Time                                                          01:21\n",
      "Duration (Seconds)                                             4.380952\n",
      "Transcript            I am glad to know the place where Wolunka was....\n",
      "Duration                                                            504\n",
      "Name: 0, dtype: object\n",
      "Speaker                                                         Magalys\n",
      "Interview                                                       wolunka\n",
      "Start Time                                                        00:24\n",
      "End Time                                                          00:42\n",
      "Duration (Seconds)                                             3.802817\n",
      "Transcript            TRUE. In fact, in our culture it is necessary ...\n",
      "Duration                                                            432\n",
      "Name: 5, dtype: object\n",
      "Speaker                                                         Magalys\n",
      "Interview                                                       wolunka\n",
      "Start Time                                                        00:01\n",
      "End Time                                                          00:19\n",
      "Duration (Seconds)                                             3.701923\n",
      "Transcript            Well Neko, you are entering the Macuira mounta...\n",
      "Duration                                                            432\n",
      "Name: 10, dtype: object\n",
      "Speaker                                                         Magalys\n",
      "Interview                                                       wolunka\n",
      "Start Time                                                        00:44\n",
      "End Time                                                          00:58\n",
      "Duration (Seconds)                                                  4.0\n",
      "Transcript            That's why I'm here in your territory Magalys....\n",
      "Duration                                                            336\n",
      "Name: 15, dtype: object\n",
      "XML saved to ../06_Export XMLs/Test/Archive/wolunka-test-967.xml\n",
      "Adding Video Tracks to ../06_Export XMLs/Test/Archive/wolunka-test-967.xml\n",
      "Adding Audio Tracks to ../06_Export XMLs/Test/Archive/wolunka-test-967.xml\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# the run_extraction() function serves as the main entry point for running the extraction process. \n",
    "# It calls functions to process a CSV file, filter the resulting list of clips, \n",
    "# and creates an XML file with the audio and video from the filtered clips\n",
    "\n",
    "def run_extraction(project_id,script_name): \n",
    "    \n",
    "    ###open csv and preprocess, merging consecutive rows\n",
    "    script_csv=pd.read_csv(\"../01_Scripts/\"+project_id+\"/CSV/\"+script_name+\".csv\")\n",
    "    script_df = merge_consecutive_rows(script_csv) ##note this is generated by running the Docx > CSV > SRT Pipeline. should it be brought here?\n",
    "    print(script_df)\n",
    "    \n",
    "    #iterate through csv, ## extract audio and video sequence info, ## add audio, video, and subtitle info to xml\n",
    "    xml_pieces=process_csv_file(script_df,project_id)##note this also goes into the xml files as well. Could consider refactor here to have an intermediate product\n",
    "    xml_pieces.to_csv(\"../09_Temp/xml_pieces_test.csv\")##temp output\n",
    "    #print(\"xml_pieces\",xml_pieces)\n",
    "    \n",
    "    export_xml_path=\"../06_Export XMLs/\"+project_id+\"/Archive/\"+script_name\n",
    "    filename = create_xml(export_xml_path)##note that the xml template is generated here, and the filename is returned\n",
    "    append_video_to_xml(filename, xml_pieces[xml_pieces[\"type\"]==\"video\"])\n",
    "    append_audio_to_xml(filename, xml_pieces[xml_pieces[\"type\"]==\"audio\"])\n",
    "    shutil.copyfile(filename, \"../06_Export XMLs/\"+project_id+\"/\"+script_name+\".xml\")\n",
    "\n",
    "    \n",
    "project_id=\"Test\"\n",
    "script_name=\"wolunka-test\"\n",
    "    \n",
    "run_extraction(project_id,script_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ### Update these to run this pipeline over a project and script\n",
    "# project_id = \"Wayuu\"\n",
    "# script_name=\"magalys test\"\n",
    "\n",
    "# run_extraction(project_id,script_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
