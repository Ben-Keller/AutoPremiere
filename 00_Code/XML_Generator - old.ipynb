{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Imports </h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Globals?</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "csv_folder_path = \"../Interview CSV\"\n",
    "\n",
    "script_path = \"../Script/test script.txt\"\n",
    "script_csv_output_path = \"../Script/script_export.csv\"\n",
    "\n",
    "final_subtitle_file = \"../Script/script.srt\"\n",
    "docx_file_path = \"../Interview TXT/\"\n",
    "\n",
    "xml_folder = \"../Interview XML/\"\n",
    "exported_xml_project_name= 'testy'\n",
    "extract_method = 'project_timecode'  # video_timecode or project_timecode \n",
    "\n",
    "video_clip_list = []\n",
    "audio_clip_list = []\n",
    "id_mapping = {}\n",
    "# global sequence_start\n",
    "# global sequence_end\n",
    "\n",
    "subtitle_counter=1\n",
    "sequence_start=0\n",
    "sequence_end=0\n",
    "audio_sequence_start=0\n",
    "audio_sequence_end=0\n",
    "xml_file_assigned=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Generate XML </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converts Time to Frames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78662"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_time_to_frames(time, rate):\n",
    "    # print('Time', time, 'Rate', rate)\n",
    "    parts = time.split(\":\")\n",
    "    hours = int(parts[0])\n",
    "    minutes = int(parts[1])\n",
    "    seconds = int(parts[2])\n",
    "    frames = int(parts[3])\n",
    "    \n",
    "    # Calculate the total duration in frames\n",
    "    total_frames = (\n",
    "        hours * 3600 * rate +  # Convert hours to frames\n",
    "        minutes * 60 * rate +  # Convert minutes to frames\n",
    "        seconds * rate +  # Convert seconds to frames\n",
    "        frames\n",
    "    )\n",
    "    \n",
    "    return total_frames\n",
    "\n",
    "convert_time_to_frames('00:54:36:38', 24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate New ids for the each Clip item in seperate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'clipitem-1a8c77182ced477da9b92929bc322677'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_unique_id():\n",
    "    unique_id = f\"clipitem-{uuid.uuid4().hex}\"\n",
    "    return unique_id\n",
    "\n",
    "generate_unique_id()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the id of clips in specific XML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_xml_ids(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    print('Assigning unique IDs to clipitem elements...')\n",
    "\n",
    "    # Generate unique IDs for clipitem elements\n",
    "      # Store the mapping of old IDs to new unique IDs\n",
    "    for clip_item in root.findall('.//clipitem'):  # Adjust the XPath expression based on the actual location of clipitem elements\n",
    "        current_id = clip_item.attrib['id']\n",
    "        unique_id = generate_unique_id()\n",
    "        id_mapping[current_id] = unique_id\n",
    "        clip_item.attrib['id'] = unique_id\n",
    "\n",
    "    \n",
    "        # Update the references in the links section\n",
    "    for link in root.findall('.//link'):\n",
    "        linkclipref = link.find('linkclipref')\n",
    "        if linkclipref is not None and linkclipref.text in id_mapping:\n",
    "            linkclipref.text = id_mapping[linkclipref.text]\n",
    "    print(id_mapping)\n",
    "\n",
    "    # Save the modified XML file\n",
    "    tree.write(xml_file, encoding=\"utf-8\")\n",
    "\n",
    "# update_xml_ids(xml_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract time in  start and end time format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('00:00:00:00', '00:23:00:00')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_timecode(timecode_range):\n",
    "    start_time, end_time = timecode_range.split(\" - \")\n",
    "    start_time = start_time.strip().replace(\" \", \"\")\n",
    "    end_time = end_time.strip().replace(\" \", \"\")\n",
    "    # print('Start Time',start_time,'End Time', end_time)\n",
    "    return start_time, end_time\n",
    "\n",
    "extract_timecode(\"00:00:00:00 - 00:23:00:00\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert frame to tick number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_to_ticks(frame_number, frame_rate):\n",
    "    total_ticks_in_a_second = 254016000000\n",
    "    tick_value = int((frame_number * total_ticks_in_a_second) / frame_rate)\n",
    "    return tick_value\n",
    "\n",
    "# frame_to_ticks(24, 24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract sequences through xml file and extract the clips that match with the start and end time using frame comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sequence_info(\n",
    "    xml_file, start_time, end_time, extract_method=\"project_timecode\"\n",
    "):\n",
    "    global sequence_start, sequence_end\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Extract sequence information\n",
    "    sequence = root.find(\"sequence\")\n",
    "    sequence_info = {\n",
    "        \"duration\": int(sequence.find(\"duration\").text),\n",
    "        \"rate\": {\n",
    "            \"timebase\": int(sequence.find(\"rate/timebase\").text),\n",
    "            \"ntsc\": sequence.find(\"rate/ntsc\").text == \"TRUE\",\n",
    "        },\n",
    "    }\n",
    "    sequence_rate = sequence_info[\"rate\"][\"timebase\"]\n",
    "\n",
    "    # Convert start and end times to frames\n",
    "    start_frame = convert_time_to_frames(start_time, 24)\n",
    "    end_frame = convert_time_to_frames(end_time, 24)\n",
    "    proTickIn = frame_to_ticks(start_frame, 24)\n",
    "    proTickOut = frame_to_ticks(end_frame, 24)\n",
    "\n",
    "    total_clip_frames = end_frame - start_frame\n",
    "    total_clip_proticks = proTickOut - proTickIn\n",
    "\n",
    "    # print('Start and End Frame',start_frame ,end_frame)\n",
    "    # print(sequence_rate,'sequence_rate')\n",
    "\n",
    "    # Extract video clip information\n",
    "    video_clips = []\n",
    "    for track_index, track in enumerate(root.findall(\".//video/track\")):  # Iterate over all tracks within the <video> tag\n",
    "        # track_idx = 0\n",
    "        track_targeted = track.attrib[\"MZ.TrackTargeted\"]\n",
    "        for clip_item in track.findall(\"clipitem\"):  # Only consider clip items within the <video> tag\n",
    "            \n",
    "            video_start_cut_diff=abs(start_frame - int(clip_item.find(\"start\").text))\n",
    "            video_end_cut_diff=abs(end_frame - int(clip_item.find(\"end\").text))\n",
    "            extracted_clip_duration=end_time-start_time\n",
    "            actual_clip_duration=int(clip_item.find(\"duration\").text)\n",
    "\n",
    "\n",
    "            links = clip_item.findall(\"link\")\n",
    "            track_idx = [\n",
    "                int(link.find(\"trackindex\").text)\n",
    "                for link in clip_item.findall(\"link\")\n",
    "                if link.find(\"mediatype\").text == \"video\"\n",
    "            ]\n",
    "            print(\"Track Index\", track_idx)\n",
    "            print(\"Clip ID\", clip_item.attrib[\"id\"])\n",
    "\n",
    "            clip_info = {\n",
    "                \"id\": clip_item.attrib[\"id\"],  # Get the clip ID\n",
    "                \"name\": clip_item.find(\"name\").text,\n",
    "                \"duration\": int(clip_item.find(\"duration\").text),\n",
    "                \"rate\": {\n",
    "                    \"timebase\": int(clip_item.find(\"rate/timebase\").text),\n",
    "                    \"ntsc\": clip_item.find(\"rate/ntsc\").text == \"TRUE\",\n",
    "                },\n",
    "                \"in\": int(clip_item.find(\"in\").text),\n",
    "                \"out\": int(clip_item.find(\"out\").text),\n",
    "                \"start\": int(clip_item.find(\"start\").text),\n",
    "                \"end\": int(clip_item.find(\"end\").text),\n",
    "                \"track_index\": track_index+1,\n",
    "                \"MZ_TrackTargeted\": track_targeted,\n",
    "                \"links\": [],  # Initialize an empty list to store links,\n",
    "                \"video_clip_element\": None,  # Store the clip item element for later use\n",
    "                \"linked_audio_clip_elements_list\": [],  # Initialize an empty list to store linked clip items\n",
    "            }\n",
    "\n",
    "            if extract_method == \"video_timecode\":\n",
    "                clip_comparison = (\n",
    "                    clip_info[\"in\"] <= start_frame <= clip_info[\"out\"]\n",
    "                ) or (clip_info[\"in\"] <= end_frame <= clip_info[\"out\"])\n",
    "            else:\n",
    "                clip_comparison = (\n",
    "                    clip_info[\"start\"] <= start_frame <= clip_info[\"end\"]\n",
    "                ) or (clip_info[\"start\"] <= end_frame <= clip_info[\"end\"])\n",
    "\n",
    "            \n",
    "\n",
    "            for link in links:\n",
    "                link_info = {\n",
    "                    \"linkclipref\": link.find(\"linkclipref\").text,\n",
    "                    \"mediatype\": link.find(\"mediatype\").text,\n",
    "                    \"trackindex\": int(link.find(\"trackindex\").text),\n",
    "                    \"clipindex\": int(link.find(\"clipindex\").text),\n",
    "                }\n",
    "                if link.find(\"groupindex\") is not None:\n",
    "                    link_info[\"groupindex\"] = int(link.find(\"groupindex\").text)\n",
    "                clip_info[\"links\"].append(link_info)\n",
    "                if link.find(\"mediatype\").text == \"audio\":\n",
    "                    audio_clip_items = root.findall(\".//audio//clipitem\")\n",
    "                    for audio_clip_item in audio_clip_items:\n",
    "                        if (\n",
    "                            audio_clip_item.attrib[\"id\"]\n",
    "                            == link.find(\"linkclipref\").text\n",
    "                        ):\n",
    "                            audio_clip_item.find(\"in\").text = str(start_frame)\n",
    "                            audio_clip_item.find(\"out\").text = str(end_frame)\n",
    "                              \n",
    "                            audio_clip_item.find(\"start\").text = str(sequence_start)\n",
    "                            audio_clip_item.find(\"end\").text = str(sequence_end)\n",
    "                            audio_clip_item.find(\"pproTicksIn\").text = str(proTickIn)\n",
    "                            audio_clip_item.find(\"pproTicksOut\").text = str(proTickOut)\n",
    "                                \n",
    "                            \n",
    "                            clip_info[\"linked_audio_clip_elements_list\"].append(\n",
    "                                {\n",
    "                                    \"audio_clip_item\": audio_clip_item,\n",
    "                                    \"trackindex\": int(link.find(\"trackindex\").text),\n",
    "                                    \"sourceindex\": int(\n",
    "                                        audio_clip_item.find(\n",
    "                                            \".//sourcetrack/trackindex\"\n",
    "                                        ).text\n",
    "                                    ),\n",
    "                                }\n",
    "                            )\n",
    "\n",
    "            # Check if the clip's in or out frame falls within the given start and end frames\n",
    "            # print('Clip Frame Inside file Found: ',clip_info['in'] <= start_frame <= clip_info['out'])\n",
    "            print(\n",
    "                \"Clip Frame Inside file Found: \",\n",
    "                clip_info[\"start\"] <= start_frame <= clip_info[\"end\"]\n",
    "                or clip_info[\"start\"] <= end_frame <= clip_info[\"end\"],\n",
    "            )\n",
    "            print(\"clip_comparison\", clip_comparison)\n",
    "            print(\"In - Matching - Out\")\n",
    "            # print(clip_info['in'],start_frame,clip_info['out'])\n",
    "            print(clip_info[\"start\"], start_frame, clip_info[\"end\"])\n",
    "            print(clip_info[\"start\"], end_frame, clip_info[\"end\"])\n",
    "            if clip_comparison:\n",
    "                clip_item.find(\"in\").text = str(start_frame)\n",
    "                clip_item.find(\"out\").text = (\n",
    "                    str(end_frame)\n",
    "                    if extract_method == \"video_timecode\"\n",
    "                    else str(start_frame + total_clip_frames)\n",
    "                )\n",
    "                clip_item.find(\"start\").text = str(sequence_start)\n",
    "                clip_item.find(\"end\").text = str(sequence_end)\n",
    "                clip_item.find(\"pproTicksIn\").text = str(proTickIn)\n",
    "                clip_item.find(\"pproTicksOut\").text = (\n",
    "                    str(proTickOut)\n",
    "                    if extract_method == \"video_timecode\"\n",
    "                    else str(proTickIn + total_clip_proticks)\n",
    "                )\n",
    "                clip_info[\"video_clip_element\"] = clip_item\n",
    "                video_clips.append(clip_info)\n",
    "                print(\"Next Sequence Start\", sequence_start)\n",
    "                print(\"Next Sequence End\", sequence_end)\n",
    "\n",
    "    # print(clip_info, start_frame, end_frame)\n",
    "\n",
    "    # Create result dictionary\n",
    "    result = { \"video_clips\": video_clips}\n",
    "    # print('Result',result)\n",
    "\n",
    "    if not video_clips:  # Check if video_clips list is empty\n",
    "        return None\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overlap Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap(segment1, segment2):\n",
    "    \"\"\"Check if two segments overlap and return the overlapped segment if they do\"\"\"\n",
    "    start1, end1 = segment1\n",
    "    start2, end2 = segment2\n",
    "    if start1 > end2 or start2 > end1:\n",
    "        # Segments do not overlap\n",
    "        return None\n",
    "    else:\n",
    "        # Segments overlap, return the overlapped segment\n",
    "        return max(start1, start2), min(end1, end2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract Video sequences from the xml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_video_sequence(xml_file, start_time, end_time):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    global sequence_start, sequence_end\n",
    "\n",
    "    # Convert start and end times to frames\n",
    "    start_frame = convert_time_to_frames(start_time, 24)\n",
    "    end_frame = convert_time_to_frames(end_time, 24)\n",
    "\n",
    "\n",
    "    # Extract video clip information\n",
    "    video_clips = []\n",
    "    for track_index, track in enumerate(root.findall(\".//video/track\")):  # Iterate over all tracks within the <video> tag\n",
    "        track_targeted = track.attrib[\"MZ.TrackTargeted\"]\n",
    "        for clip_item in track.findall(\"clipitem\"):  # Only consider clip items within the <video> tag\n",
    "\n",
    "            \n",
    "\n",
    "            clip_info = {\n",
    "                \"id\": clip_item.attrib[\"id\"],  # Get the clip ID\n",
    "                \"new_id\": generate_unique_id(),  # Generate a new unique ID for the clip item\",\n",
    "                \"name\": clip_item.find(\"name\").text,\n",
    "                \"duration\": int(clip_item.find(\"duration\").text),\n",
    "                \"rate\": {\n",
    "                    \"timebase\": int(clip_item.find(\"rate/timebase\").text),\n",
    "                    \"ntsc\": clip_item.find(\"rate/ntsc\").text == \"TRUE\",\n",
    "                },\n",
    "                \"in\": int(clip_item.find(\"in\").text),\n",
    "                \"out\": int(clip_item.find(\"out\").text),\n",
    "                \"start\": int(clip_item.find(\"start\").text),\n",
    "                \"end\": int(clip_item.find(\"end\").text),\n",
    "                \"track_index\": track_index+1,\n",
    "                \"MZ_TrackTargeted\": track_targeted,\n",
    "                \"video_clip_element\": None,  # Store the clip item element for later use\n",
    "            }\n",
    "\n",
    "            # Check if the clip's in or out frame falls within the given start and end frames\n",
    "            if (\n",
    "                clip_info[\"start\"] <= start_frame <= clip_info[\"end\"]\n",
    "                or clip_info[\"start\"] <= end_frame <= clip_info[\"end\"]\n",
    "            ):\n",
    "                \n",
    "                # Calculate the overlapped segment and the corresponding sequence segment\n",
    "                overlapped_segment = overlap((clip_info[\"start\"], clip_info[\"end\"]), (start_frame, end_frame))\n",
    "\n",
    "\n",
    "\n",
    "                if overlapped_segment is not None:\n",
    "                    overlap_start, overlap_end = overlapped_segment\n",
    "                    ratio_start = (overlap_start - clip_info[\"start\"]) / (clip_info[\"end\"] - clip_info[\"start\"])\n",
    "                    ratio_end = (overlap_end - clip_info[\"start\"]) / (clip_info[\"end\"] - clip_info[\"start\"])\n",
    "\n",
    "                    clip_start_time = 0 if sequence_end == 0 else sequence_end \n",
    "                    clip_end_time = clip_start_time + (overlap_end - overlap_start)\n",
    "\n",
    "                    # Update the clip's in, out, start, and end in the XML tree based on the overlapped segment\n",
    "                    clip_item.find(\"in\").text = str(clip_info[\"in\"] + round(ratio_start * (clip_info[\"out\"] - clip_info[\"in\"])))\n",
    "                    clip_item.find(\"out\").text = str(clip_info[\"in\"] + round(ratio_end * (clip_info[\"out\"] - clip_info[\"in\"])))\n",
    "                    clip_item.find(\"start\").text = str(clip_start_time)\n",
    "                    clip_item.find(\"end\").text = str(clip_end_time)\n",
    "\n",
    "                    clip_info[\"video_clip_element\"] = clip_item\n",
    "                    video_clips.append(clip_info)\n",
    "\n",
    "    if not video_clips:  # Check if video_clips list is empty\n",
    "        return None\n",
    "    else:\n",
    "        sequence_start = 0 if sequence_end == 0 else sequence_end \n",
    "        sequence_end = sequence_start + (end_frame - start_frame)\n",
    "\n",
    "    # Create result dictionary\n",
    "    result = {\"video_clips\": video_clips}\n",
    "    return result\n",
    "\n",
    "# Test the function with the given XML file and start/end times\n",
    "# extract_video_sequence('ben - synced.xml', '00:00:00:00', '00:00:10:00')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract Audio sequences from the xml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio_sequence(xml_file, start_time, end_time):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    global audio_sequence_start ,audio_sequence_end\n",
    "\n",
    "    # Convert start and end times to frames\n",
    "    start_frame = convert_time_to_frames(start_time, 24)\n",
    "    end_frame = convert_time_to_frames(end_time, 24)\n",
    "\n",
    "    # Extract video clip information\n",
    "    audio_clips = []\n",
    "    for track_index, track in enumerate(root.findall(\".//audio/track\")):  # Iterate over all tracks within the <video> tag\n",
    "        track_targeted = track.attrib[\"MZ.TrackTargeted\"]\n",
    "        currentExplodedTrackIndex = track.attrib[\"currentExplodedTrackIndex\"]\n",
    "        for clip_item in track.findall(\"clipitem\"):  # Only consider clip items within the <video> tag\n",
    "            clip_info = {\n",
    "                \"id\": clip_item.attrib[\"id\"],  # Get the clip ID\n",
    "                \"name\": clip_item.find(\"name\").text,\n",
    "                \"duration\": int(clip_item.find(\"duration\").text),\n",
    "                \"rate\": {\n",
    "                    \"timebase\": int(clip_item.find(\"rate/timebase\").text),\n",
    "                    \"ntsc\": clip_item.find(\"rate/ntsc\").text == \"TRUE\",\n",
    "                },\n",
    "                \"in\": int(clip_item.find(\"in\").text),\n",
    "                \"out\": int(clip_item.find(\"out\").text),\n",
    "                \"start\": int(clip_item.find(\"start\").text),\n",
    "                \"end\": int(clip_item.find(\"end\").text),\n",
    "                \"track_index\": track_index+1,\n",
    "                \"MZ_TrackTargeted\": track_targeted,\n",
    "                \"currentExplodedTrackIndex\": currentExplodedTrackIndex,\n",
    "                \"audio_clip_element\": None,  # Store the clip item element for later use\n",
    "                \"sourceindex\": int(clip_item.find(\".//sourcetrack/trackindex\").text),\n",
    "            }\n",
    "            \n",
    "\n",
    "            # Check if the clip's in or out frame falls within the given start and end frames\n",
    "            if (\n",
    "                clip_info[\"start\"] <= start_frame <= clip_info[\"end\"]\n",
    "                or clip_info[\"start\"] <= end_frame <= clip_info[\"end\"]\n",
    "            ):\n",
    "                # Calculate the overlapped segment and the corresponding sequence segment\n",
    "                overlapped_segment = overlap((clip_info[\"start\"], clip_info[\"end\"]), (start_frame, end_frame))\n",
    "                if overlapped_segment is not None:\n",
    "                    overlap_start, overlap_end = overlapped_segment\n",
    "                    ratio_start = (overlap_start - clip_info[\"start\"]) / (clip_info[\"end\"] - clip_info[\"start\"])\n",
    "                    ratio_end = (overlap_end - clip_info[\"start\"]) / (clip_info[\"end\"] - clip_info[\"start\"])\n",
    "\n",
    "                    clip_start_time = 0 if audio_sequence_end == 0 else audio_sequence_end \n",
    "                    clip_end_time = clip_start_time + (overlap_end - overlap_start)\n",
    "\n",
    "                    # Update the clip's in, out, start, and end in the XML tree based on the overlapped segment\n",
    "                    clip_item.find(\"in\").text = str(clip_info[\"in\"] + round(ratio_start * (clip_info[\"out\"] - clip_info[\"in\"])))\n",
    "                    clip_item.find(\"out\").text = str(clip_info[\"in\"] + round(ratio_end * (clip_info[\"out\"] - clip_info[\"in\"])))\n",
    "                    clip_item.find(\"start\").text = str(clip_start_time)\n",
    "                    clip_item.find(\"end\").text = str(clip_end_time)\n",
    "\n",
    "\n",
    "                    clip_item.find(\"pproTicksIn\").text = str(frame_to_ticks(overlap_start, 24))\n",
    "                    clip_item.find(\"pproTicksOut\").text = str(frame_to_ticks(overlap_end, 24))\n",
    "\n",
    "\n",
    "                    clip_info[\"audio_clip_element\"] = clip_item\n",
    "                    audio_clips.append(clip_info)\n",
    "\n",
    "    if not audio_clips:  # Check if audio_clips list is empty\n",
    "        return None\n",
    "    else:\n",
    "        audio_sequence_start = 0 if audio_sequence_end == 0 else audio_sequence_end \n",
    "        audio_sequence_end = audio_sequence_start + (end_frame - start_frame)\n",
    "\n",
    "    # Create result dictionary\n",
    "    result = {\"audio_clips\": audio_clips}\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code Merges the rows which can be merged based on time and narrator name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_consecutive_rows(csv_file_path):\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "\n",
    "    # Drop the \"Unnamed: 0\" column if it exists\n",
    "    if 'Unnamed: 0' in df.columns:\n",
    "        df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "    # Convert time format 'hours:minutes:seconds:frames' to seconds\n",
    "    def time_to_seconds(time_str):\n",
    "        hours, minutes, seconds, frames = map(int, time_str.split(':'))\n",
    "        return hours * 3600 + minutes * 60 + seconds + frames / 30.0\n",
    "\n",
    "    # Add columns for start and end times in seconds\n",
    "    df['Start Time (s)'] = df['Timecode Range'].str.split(' - ').str[0].apply(time_to_seconds)\n",
    "    df['End Time (s)'] = df['Timecode Range'].str.split(' - ').str[1].apply(time_to_seconds)\n",
    "\n",
    "    # Initialize new columns for merged data\n",
    "    df['Merged Text'] = df['Text']\n",
    "\n",
    "    # Iterate through rows and merge consecutive rows\n",
    "    rows_to_drop = set()\n",
    "    i = 0\n",
    "    while i < len(df) - 1:\n",
    "        merged_text = df.at[i, 'Text']\n",
    "        merged_timecodes = [df.at[i, 'Timecode Range']]\n",
    "        start_time = df.at[i, 'Timecode Range'].split(' - ')[0]\n",
    "        end_time = df.at[i, 'Timecode Range'].split(' - ')[1]\n",
    "        j = i\n",
    "        while j < len(df) - 1 and (df.at[j, 'Narrator'] == df.at[j+1, 'Narrator']) and (df.at[j+1, 'Start Time (s)'] - df.at[j, 'End Time (s)'] <= 2):\n",
    "            merged_text += ' (-) ' + df.at[j+1, 'Text']\n",
    "            merged_timecodes.append(df.at[j+1, 'Timecode Range'])\n",
    "            end_time = df.at[j+1, 'Timecode Range'].split(' - ')[1]\n",
    "            j += 1\n",
    "\n",
    "        # If any rows were merged\n",
    "        if j > i:\n",
    "            df.at[i, 'Merged Text'] = merged_text\n",
    "            df.at[i, 'Merged Timecode Range'] = ' (-) '.join(merged_timecodes)\n",
    "            df.at[i, 'Timecode Range'] = start_time + ' - ' + end_time\n",
    "            for k in range(i+1, j+1):\n",
    "                rows_to_drop.add(k)\n",
    "            i = j\n",
    "        i += 1\n",
    "\n",
    "    # Drop merged rows\n",
    "    df.drop(list(rows_to_drop), inplace=True)\n",
    "\n",
    "    # Reset index\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Add Merge Status column\n",
    "    df['Merge Status'] = False\n",
    "    df.loc[df['Text'] != df['Merged Text'], 'Merge Status'] = True\n",
    "\n",
    "    # Drop helper columns\n",
    "    df.drop(['Start Time (s)', 'End Time (s)'], axis=1, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Return the updated function for use\n",
    "# merge_consecutive_rows_final_corrected\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions go through all the xml files and call the  extract clips function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_xml_files(xml_folder, start_time, end_time, narrator_name):\n",
    "    global xml_file_assigned,video_clip_list,audio_clip_list, sequence_start, sequence_end, audio_sequence_start, audio_sequence_end\n",
    "    for filename in os.listdir(xml_folder):\n",
    "        if filename.endswith(\".xml\") and narrator_name.lower() in filename.lower():\n",
    "            # print(filename,narrator_name)\n",
    "            xml_file = os.path.join(xml_folder, filename)\n",
    "            if xml_file not in xml_file_assigned:\n",
    "                update_xml_ids(xml_file)\n",
    "                xml_file_assigned.append(xml_file)\n",
    "            video_clips = extract_video_sequence(xml_file, start_time, end_time)\n",
    "            audio_clips = extract_audio_sequence(xml_file, start_time, end_time)\n",
    "            video_clip_list.append(video_clips)\n",
    "            audio_clip_list.append(audio_clips)\n",
    "\n",
    "\n",
    "\n",
    "def process_csv_file(csv_file):\n",
    "    \n",
    "    xml_folder = \"../Interview XML/\"\n",
    "    with open(csv_file, \"r\") as file:\n",
    "        csv_reader = csv.DictReader(file)\n",
    "        for row in csv_reader:\n",
    "            timecode_range = row[\"Timecode Range\"]\n",
    "            if timecode_range:\n",
    "                narrator_name = row[\"Narrator\"]\n",
    "                line = row[\"Text\"]\n",
    "                original_start_time, original_end_time = extract_timecode(timecode_range)\n",
    "                process_xml_files(xml_folder, original_start_time, original_end_time, narrator_name)\n",
    "                subtitle_frame_start=sequence_start\n",
    "                \n",
    "                if row[\"Merge Status\"]=='True':\n",
    "                    row_time=row[\"Merged Timecode Range\"].split('(-)')\n",
    "                    row_text=row[\"Merged Text\"].split('(-)')\n",
    "\n",
    "                    \n",
    "                    for time, line in zip(row_time,row_text):\n",
    "\n",
    "                        s_time, e_time = extract_timecode(time)\n",
    "                        s_time = timecode_to_frames(s_time)\n",
    "                        e_time = timecode_to_frames(e_time)\n",
    "                        # Convert frame sequences to timecodes for subtitles\n",
    "                        start_time = frames_to_timecode(subtitle_frame_start)\n",
    "                        end_time = frames_to_timecode(subtitle_frame_start+(e_time-s_time))\n",
    "                        generate_subtitles(start_time, end_time, line)\n",
    "                        subtitle_frame_start=subtitle_frame_start+(e_time-s_time)\n",
    "                        \n",
    "                else:\n",
    "                    # Convert frame sequences to timecodes for subtitles\n",
    "                    start_time = frames_to_timecode(sequence_start)\n",
    "                    end_time = frames_to_timecode(sequence_end)\n",
    "\n",
    "                    generate_subtitles(start_time, end_time, line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Create Basic XML Structure </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_xml(xml_name):\n",
    "    \n",
    "    # Create the root element\n",
    "    root = ET.Element(\"xmeml\", version=\"4\")\n",
    "    \n",
    "    # Create the sequence element with attributes\n",
    "    sequence = ET.SubElement(root, \"sequence\", id=\"sequence-2\", TL_SQAudioVisibleBase=\"0\", TL_SQVideoVisibleBase=\"0\",\n",
    "                             TL_SQVisibleBaseTime=\"0\", TL_SQAVDividerPosition=\"0.5\", TL_SQHideShyTracks=\"0\",\n",
    "                             TL_SQHeaderWidth=\"236\", TL_SQDataTrackViewControlState=\"0\",\n",
    "                             Monitor_ProgramZoomOut=\"340011984312000\", Monitor_ProgramZoomIn=\"0\",\n",
    "                             TL_SQTimePerPixel=\"1.6034289012958367\", MZ_EditLine=\"333083126376000\",\n",
    "                             MZ_Sequence_PreviewFrameSizeHeight=\"1080\", MZ_Sequence_PreviewFrameSizeWidth=\"1920\",\n",
    "                             MZ_Sequence_AudioTimeDisplayFormat=\"200\", MZ_Sequence_PreviewUseMaxRenderQuality=\"false\",\n",
    "                             MZ_Sequence_PreviewUseMaxBitDepth=\"false\", MZ_Sequence_VideoTimeDisplayFormat=\"110\",\n",
    "                             MZ_WorkOutPoint=\"15235011792000\", MZ_WorkInPoint=\"0\", MZ_ZeroPoint=\"0\", explodedTracks=\"true\")\n",
    "    \n",
    "    # Add the uuid element\n",
    "    uuid = ET.SubElement(sequence, \"uuid\")\n",
    "    uuid.text = \"50e61931-251f-4069-8193-a3fbad7f93ff\"\n",
    "    \n",
    "    # Add the duration element\n",
    "    duration = ET.SubElement(sequence, \"duration\")\n",
    "    duration.text = \"31533\"\n",
    "    \n",
    "    # Add the rate element with nested timebase and ntsc elements\n",
    "    rate = ET.SubElement(sequence, \"rate\")\n",
    "    timebase = ET.SubElement(rate, \"timebase\")\n",
    "    timebase.text = \"24\"\n",
    "    ntsc = ET.SubElement(rate, \"ntsc\")\n",
    "    ntsc.text = \"TRUE\"\n",
    "    \n",
    "    # Add the name element\n",
    "    name_element = ET.SubElement(sequence, \"name\")\n",
    "    name_element.text = xml_name\n",
    "    \n",
    "    # Add the media element with nested video and audio elements\n",
    "    media = ET.SubElement(sequence, \"media\")\n",
    "\n",
    "    \n",
    " \n",
    "    \n",
    "    # Add the timecode element with nested rate, string, frame, and displayformat elements\n",
    "    timecode = ET.SubElement(sequence, \"timecode\")\n",
    "    rate = ET.SubElement(timecode, \"rate\")\n",
    "    timebase = ET.SubElement(rate, \"timebase\")\n",
    "    timebase.text = \"24\"\n",
    "    ntsc = ET.SubElement(rate, \"ntsc\")\n",
    "    ntsc.text = \"TRUE\"\n",
    "    string = ET.SubElement(timecode, \"string\")\n",
    "    string.text = \"00:00:00:00\"\n",
    "    frame = ET.SubElement(timecode, \"frame\")\n",
    "    frame.text = \"0\"\n",
    "    displayformat = ET.SubElement(timecode, \"displayformat\")\n",
    "    displayformat.text = \"NDF\"\n",
    "    \n",
    "    # Add the labels element with nested label2 element\n",
    "    labels = ET.SubElement(sequence, \"labels\")\n",
    "    label2 = ET.SubElement(labels, \"label2\")\n",
    "    label2.text = \"Forest\"\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    # Create the ElementTree object with the root element\n",
    "    tree = ET.ElementTree(root)\n",
    "    \n",
    "    # Generate a random Idd\n",
    "    idd = str(random.randint(1, 1000))\n",
    "    \n",
    "    # Save the XML to a file\n",
    "    filename = f\"{xml_name.replace(' ', '_')}-{idd}.xml\"\n",
    "    tree.write(f\"../xml exports/{filename}\", encoding=\"utf-8\", xml_declaration=True)\n",
    "    print(f\"XML saved to {filename}\")\n",
    "\n",
    "    return filename \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append Video to XML File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_video_to_xml(file_name, xml_json_data):\n",
    "    print(f\"Adding Video Tracks to {file_name}\")\n",
    "    # print(xml_json_data)\n",
    "    # Parse the XML data\n",
    "    tree = ET.parse(file_name)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Find the media element\n",
    "    media = root.find('.//media')\n",
    "\n",
    "    # Append the provided code inside the media element\n",
    "    video = ET.SubElement(media, \"video\")\n",
    "\n",
    "    # Add the format element with nested samplecharacteristics element\n",
    "    format_ = ET.SubElement(video, \"format\")\n",
    "    samplecharacteristics = ET.SubElement(format_, \"samplecharacteristics\")\n",
    "    \n",
    "    # Add the rate element with nested timebase and ntsc elements inside samplecharacteristics\n",
    "    rate = ET.SubElement(samplecharacteristics, \"rate\")\n",
    "    timebase = ET.SubElement(rate, \"timebase\")\n",
    "    timebase.text = \"24\"\n",
    "    ntsc = ET.SubElement(rate, \"ntsc\")\n",
    "    ntsc.text = \"TRUE\"\n",
    "    \n",
    "    # Add the codec element with nested name and appspecificdata elements\n",
    "    codec = ET.SubElement(samplecharacteristics, \"codec\")\n",
    "    name = ET.SubElement(codec, \"name\")\n",
    "    name.text = \"Apple ProRes 422\"\n",
    "    appspecificdata = ET.SubElement(codec, \"appspecificdata\")\n",
    "    \n",
    "    # Add the appname, appmanufacturer, and appversion elements inside appspecificdata\n",
    "    appname = ET.SubElement(appspecificdata, \"appname\")\n",
    "    appname.text = \"Final Cut Pro\"\n",
    "    appmanufacturer = ET.SubElement(appspecificdata, \"appmanufacturer\")\n",
    "    appmanufacturer.text = \"Apple Inc.\"\n",
    "    appversion = ET.SubElement(appspecificdata, \"appversion\")\n",
    "    appversion.text = \"7.0\"\n",
    "    \n",
    "    # Add the data element with nested qtcodec element inside appspecificdata\n",
    "    data = ET.SubElement(appspecificdata, \"data\")\n",
    "    qtcodec = ET.SubElement(data, \"qtcodec\")\n",
    "    codecname = ET.SubElement(qtcodec, \"codecname\")\n",
    "    codecname.text = \"Apple ProRes 422\"\n",
    "    codectypename = ET.SubElement(qtcodec, \"codectypename\")\n",
    "    codectypename.text = \"Apple ProRes 422\"\n",
    "    codectypecode = ET.SubElement(qtcodec, \"codectypecode\")\n",
    "    codectypecode.text = \"apcn\"\n",
    "    codecvendorcode = ET.SubElement(qtcodec, \"codecvendorcode\")\n",
    "    codecvendorcode.text = \"appl\"\n",
    "    spatialquality = ET.SubElement(qtcodec, \"spatialquality\")\n",
    "    spatialquality.text = \"1024\"\n",
    "    temporalquality = ET.SubElement(qtcodec, \"temporalquality\")\n",
    "    temporalquality.text = \"0\"\n",
    "    keyframerate = ET.SubElement(qtcodec, \"keyframerate\")\n",
    "    keyframerate.text = \"0\"\n",
    "    datarate = ET.SubElement(qtcodec, \"datarate\")\n",
    "    datarate.text = \"0\"\n",
    "    \n",
    "    # Add the width, height, anamorphic, pixelaspectratio, fielddominance, and colordepth elements inside samplecharacteristics\n",
    "    width = ET.SubElement(samplecharacteristics, \"width\")\n",
    "    width.text = \"1920\"\n",
    "    height = ET.SubElement(samplecharacteristics, \"height\")\n",
    "    height.text = \"1080\"\n",
    "    anamorphic = ET.SubElement(samplecharacteristics, \"anamorphic\")\n",
    "    anamorphic.text = \"FALSE\"\n",
    "    pixelaspectratio = ET.SubElement(samplecharacteristics, \"pixelaspectratio\")\n",
    "    pixelaspectratio.text = \"square\"\n",
    "    fielddominance = ET.SubElement(samplecharacteristics, \"fielddominance\")\n",
    "    fielddominance.text = \"none\"\n",
    "    colordepth = ET.SubElement(samplecharacteristics, \"colordepth\")\n",
    "    colordepth.text = \"24\"\n",
    "    video_tracks = []\n",
    "    # Get the track elements\n",
    "    for clip in xml_json_data:\n",
    "        for video_clip in clip[\"video_clips\"]:\n",
    "            if video_clip[\"track_index\"] not in video_tracks:\n",
    "                video_tracks.append({'MZ_TrackTargeted':video_clip[\"MZ_TrackTargeted\"],'track_index':video_clip[\"track_index\"]})\n",
    "\n",
    "    \n",
    "    # print(video_tracks,\"total video tracks\")\n",
    "    appended_video_clip=[]\n",
    "    \n",
    "    # Make video_tracks unique based on track_index\n",
    "    video_tracks = [dict(t) for t in {tuple(d.items()) for d in video_tracks}]\n",
    "    \n",
    "\n",
    "\n",
    "    # Create video track elements and append video clips\n",
    "    print(video_tracks,\"total video tracks\")\n",
    "    for track in video_tracks:\n",
    "        video_track = ET.SubElement(video, \"track\", TL_SQTrackShy=\"0\", TL_SQTrackExpandedHeight=\"25\",\n",
    "                                    TL_SQTrackExpanded=\"0\", MZ_TrackTargeted=f\"{track['MZ_TrackTargeted']}\")\n",
    "        for clip in xml_json_data:\n",
    "            for video_clip in clip[\"video_clips\"]:\n",
    "                if int(track['track_index']) == int(video_clip[\"track_index\"]) and video_clip[\"new_id\"] not in appended_video_clip:\n",
    "                    video_track.append(copy.deepcopy(video_clip[\"video_clip_element\"]))\n",
    "                    appended_video_clip.append(video_clip[\"new_id\"])\n",
    "\n",
    "\n",
    "    # Save the modified XML to a new file\n",
    "    modified_tree = ET.ElementTree(root)\n",
    "    modified_tree.write(file_name)    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append Audio to XML File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def append_audio_to_xml(file_name, xml_json_data):\n",
    "    print(f\"Adding Audio Tracks to {file_name}\")\n",
    "    # Parse the XML data\n",
    "    audio_tracks = []\n",
    "    track_index = []\n",
    "    source_index = []\n",
    "    for clip in xml_json_data:\n",
    "        for audio_clip in clip[\"audio_clips\"]:\n",
    "            if audio_clip['currentExplodedTrackIndex'] not in track_index:\n",
    "                track_index.append(audio_clip['currentExplodedTrackIndex'])\n",
    "                source_index.append(audio_clip['sourceindex'])\n",
    "                audio_tracks.append({'source_index': audio_clip['sourceindex'],\n",
    "                                     'MZ_TrackTargeted': audio_clip['MZ_TrackTargeted'],\n",
    "                                     'currentExplodedTrackIndex':audio_clip['currentExplodedTrackIndex']})\n",
    "\n",
    "    audio_track_count = len(set(source_index))\n",
    "\n",
    "    # print('audio_tracks',audio_tracks)\n",
    "    # print('track_index',track_index)\n",
    "    # print('source_index',source_index)\n",
    "    # print('audio_track_count',audio_track_count)\n",
    "    \n",
    "    tree = ET.parse(file_name)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Find the media element\n",
    "    media = root.find('.//media')\n",
    "\n",
    "    # Add the audio element inside media\n",
    "    audio = ET.SubElement(media, \"audio\")\n",
    "\n",
    "    # constant stuff\n",
    "\n",
    "    # Create subelements and append them to the audio element\n",
    "    num_output_channels = ET.SubElement(audio, 'numOutputChannels')\n",
    "    num_output_channels.text = '2'\n",
    "\n",
    "    format_element = ET.SubElement(audio, 'format')\n",
    "    sample_characteristics = ET.SubElement(format_element, 'samplecharacteristics')\n",
    "    depth = ET.SubElement(sample_characteristics, 'depth')\n",
    "    depth.text = '16'\n",
    "    sample_rate = ET.SubElement(sample_characteristics, 'samplerate')\n",
    "    sample_rate.text = '48000'\n",
    "\n",
    "    outputs = ET.SubElement(audio, 'outputs')\n",
    "\n",
    "    group_1 = ET.SubElement(outputs, 'group')\n",
    "    index_1 = ET.SubElement(group_1, 'index')\n",
    "    index_1.text = '1'\n",
    "    num_channels_1 = ET.SubElement(group_1, 'numchannels')\n",
    "    num_channels_1.text = '1'\n",
    "    downmix_1 = ET.SubElement(group_1, 'downmix')\n",
    "    downmix_1.text = '0'\n",
    "    channel_1 = ET.SubElement(group_1, 'channel')\n",
    "    channel_index_1 = ET.SubElement(channel_1, 'index')\n",
    "    channel_index_1.text = '1'\n",
    "\n",
    "    group_2 = ET.SubElement(outputs, 'group')\n",
    "    index_2 = ET.SubElement(group_2, 'index')\n",
    "    index_2.text = '2'\n",
    "    num_channels_2 = ET.SubElement(group_2, 'numchannels')\n",
    "    num_channels_2.text = '1'\n",
    "    downmix_2 = ET.SubElement(group_2, 'downmix')\n",
    "    downmix_2.text = '0'\n",
    "    channel_2 = ET.SubElement(group_2, 'channel')\n",
    "    channel_index_2 = ET.SubElement(channel_2, 'index')\n",
    "    channel_index_2.text = '2'\n",
    "\n",
    "    appended_video_clip=[]\n",
    "\n",
    "     # Create audio track elements and append audio clips\n",
    "    for audio_track_index in audio_tracks:\n",
    "        audio_track = ET.SubElement(audio, \"track\", TL_SQTrackAudioKeyframeStyle=\"0\", TL_SQTrackShy=\"0\",\n",
    "                                    TL_SQTrackExpandedHeight=\"25\", TL_SQTrackExpanded=\"0\",\n",
    "                                    MZ_TrackTargeted=f\"{audio_track_index['MZ_TrackTargeted']}\", PannerCurrentValue=\"0.5\", PannerIsInverted=\"true\",\n",
    "                                    PannerStartKeyframe=\"-91445760000000000,0.5,0,0,0,0,0,0\", PannerName=\"Balance\",\n",
    "                                    currentExplodedTrackIndex=f\"{audio_track_index['currentExplodedTrackIndex']}\", totalExplodedTrackCount=f\"{audio_track_count}\",\n",
    "                                    premiereTrackType=\"Stereo\")\n",
    "\n",
    "        for clip in xml_json_data:\n",
    "            for audio_clip in clip[\"audio_clips\"]:\n",
    "                if int(audio_track_index['currentExplodedTrackIndex']) == int(audio_clip[\"currentExplodedTrackIndex\"]):\n",
    "                    audio_track.append(copy.deepcopy(audio_clip[\"audio_clip_element\"]))\n",
    "                    appended_video_clip.append(audio_clip[\"id\"])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Save the modified XML to a new file\n",
    "    modified_tree = ET.ElementTree(root)\n",
    "    modified_tree.write(file_name)\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracts the given clips from the xml files and saves them in a seperate xml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the run_extraction() function serves as the main entry point for running the extraction process. \n",
    "# It calls functions to process a CSV file, filter the resulting list of clips, and create an XML file based on the filtered clips.\n",
    "\n",
    "def run_extraction(script_csv_file,exported_xml_project_name):\n",
    "    global video_clip_list,audio_clip_list     \n",
    "    \n",
    "    #why not just return the clip lists? remove the global\n",
    "    process_csv_file(script_csv_file)# video_clip_list and audio_clip_list are added to here...\n",
    "    video_clip_list = [item for item in video_clip_list if item is not None]\n",
    "    audio_clip_list = [item for item in audio_clip_list if item is not None]\n",
    "    filename = create_xml(exported_xml_project_name)\n",
    "    append_video_to_xml(f\"../xml exports/{filename}\", video_clip_list)\n",
    "    append_audio_to_xml(f\"../xml exports/{filename}\", audio_clip_list)\n",
    "# print(video_clip_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code Run Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT        This is the first sentence of the video\n",
      "Narrator                       ../Interview TXT/ben\n",
      "TIME                      00:00:08:00 - 00:00:11:00\n",
      "FilePath      ../Interview TXT/ben - transcript.txt\n",
      "NARRATOR                                          -\n",
      "FILEPATH      ../Interview CSV/ben - transcript.csv\n",
      "Name: 0, dtype: object\n",
      "this is the first sentence of the video This is the first sentence of the video\n",
      "192 72 39 0\n",
      "TEXT        This is the second sentence of this video\n",
      "Narrator                         ../Interview TXT/ben\n",
      "TIME                        00:00:16:00 - 00:00:21:00\n",
      "FilePath        ../Interview TXT/ben - transcript.txt\n",
      "NARRATOR                                            -\n",
      "FILEPATH        ../Interview CSV/ben - transcript.csv\n",
      "Name: 2, dtype: object\n",
      "this is the second sentence of this video This is the second sentence of this video\n",
      "384 120 41 0\n",
      "TEXT        And now this will be the third sentence\n",
      "Narrator                       ../Interview TXT/ben\n",
      "TIME                      00:00:22:00 - 00:00:25:00\n",
      "FilePath      ../Interview TXT/ben - transcript.txt\n",
      "NARRATOR                                          -\n",
      "FILEPATH      ../Interview CSV/ben - transcript.csv\n",
      "Name: 3, dtype: object\n",
      "and now this will be the third sentence And now this will be the third sentence\n",
      "528 72 39 0\n",
      "TEXT        used in this video as a third sentence\n",
      "Narrator                      ../Interview TXT/ben\n",
      "TIME                     00:00:25:00 - 00:00:31:00\n",
      "FilePath     ../Interview TXT/ben - transcript.txt\n",
      "NARRATOR                                         -\n",
      "FILEPATH     ../Interview CSV/ben - transcript.csv\n",
      "Name: 4, dtype: object\n",
      "used in this video as a third sentence used in this video as a third sentence\n",
      "600 144 38 0\n",
      "Assigning unique IDs to clipitem elements...\n",
      "{'clipitem-12b4ccf6ed74496db61a2284a03978f8': 'clipitem-6bdfb559c3814adba919c59fd6111309', 'clipitem-a4498b0c23dd4303b0f478ee17405bf6': 'clipitem-20367fb2810044618a056a676a8efebc', 'clipitem-977859a12c8544fd877eb2f32457edd7': 'clipitem-4963b1258f3d450fbcbbbf5d4dfd4b1c', 'clipitem-5ae65204efa24c3aa06e2500c748fe9b': 'clipitem-450029a96aa64979993eb1d6e752508a', 'clipitem-eec3abaf517143f88b2f915d9eef9b39': 'clipitem-dd029e281e2a434782526df87735334c'}\n",
      "XML saved to testy-718.xml\n",
      "Adding Video Tracks to ../xml exports/testy-718.xml\n",
      "[{'MZ_TrackTargeted': '1', 'track_index': 1}, {'MZ_TrackTargeted': '1', 'track_index': 1}, {'MZ_TrackTargeted': '0', 'track_index': 2}, {'MZ_TrackTargeted': '0', 'track_index': 2}] total video tracks\n",
      "Adding Audio Tracks to ../xml exports/testy-718.xml\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
