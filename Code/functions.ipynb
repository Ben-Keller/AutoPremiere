{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def extract_paragraphs(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    regex = r\"\\[(\\d{2}:\\d{2}:\\d{2})\\]\\s+(.*?)(?=\\n\\[|\\Z)\"\n",
    "    matches = re.findall(regex, content, re.DOTALL)\n",
    "\n",
    "    paragraphs = []\n",
    "    for i, match in enumerate(matches):\n",
    "        start_time = match[0]\n",
    "        paragraph = match[1].strip().replace('\\n', ' ')  # Remove leading/trailing whitespace and replace newlines with spaces\n",
    "        \n",
    "        # Remove line breaks between speaker lines\n",
    "        paragraph = re.sub(r'([A-Za-z]+:)\\s*\\n\\s*', r'\\1 ', paragraph)\n",
    "\n",
    "        if paragraph:\n",
    "            if i < len(matches) - 1:\n",
    "                next_start_time = matches[i + 1][0]\n",
    "                end_time = next_start_time\n",
    "            else:\n",
    "                # Last paragraph, use a default end time\n",
    "                end_time = \"00:00:00\"\n",
    "\n",
    "            paragraphs.append((paragraph, start_time, end_time))\n",
    "\n",
    "    return paragraphs\n",
    "\n",
    "\n",
    "def process_paragraph(paragraph, start_time, end_time):\n",
    "    # Split the paragraph into sentences\n",
    "    sentences = paragraph.split('. ')\n",
    "    \n",
    "    # Calculate the number of sentences\n",
    "    num_sentences = len(sentences)\n",
    "    \n",
    "    # Convert start time and end time to datetime objects\n",
    "    start_datetime = pd.to_datetime(start_time[1:9], format='%H:%M:%S')\n",
    "    end_datetime = pd.to_datetime(end_time[1:9], format='%H:%M:%S')\n",
    "    \n",
    "    # Calculate the total duration of the paragraph in seconds\n",
    "    total_duration = (end_datetime - start_datetime).total_seconds()\n",
    "    \n",
    "    # Calculate the total number of words in the paragraph\n",
    "    total_words = len(paragraph.split())\n",
    "    \n",
    "    # Calculate the time per word\n",
    "    time_per_word = total_duration / total_words\n",
    "    \n",
    "    # Create a list to store the resulting data\n",
    "    data = []\n",
    "    \n",
    "    # Iterate over each sentence and assign time values\n",
    "    current_datetime = start_datetime\n",
    "    for sentence in sentences:\n",
    "        sentence_words = sentence.split()\n",
    "        sentence_duration = len(sentence_words) * time_per_word\n",
    "        \n",
    "        time_str = f\"{current_datetime.time().strftime('%H:%M:%S')} - {(current_datetime + pd.Timedelta(seconds=sentence_duration)).time().strftime('%H:%M:%S')}\"\n",
    "        data.append([time_str, sentence.strip(), \"\"])\n",
    "        current_datetime += pd.Timedelta(seconds=sentence_duration)\n",
    "    \n",
    "    # Create a pandas DataFrame\n",
    "    df = pd.DataFrame(data, columns=['TIME', 'TRANSLATION (ENGLISH)', 'TRANSCRIPTION (SESOTHO)'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def convert_txt_to_csv_xlsx():\n",
    "    # Folder path containing the text files\n",
    "    TXT_folder_path = '../Interview TXT/'\n",
    "\n",
    "    # Output folder path for Excel files\n",
    "    output_folder = '../Interview XLSX/'\n",
    "\n",
    "    # Get a list of all the text files in the folder\n",
    "    txt_files = glob.glob(TXT_folder_path + '*.txt')\n",
    "\n",
    "    for txt_file in txt_files:\n",
    "        # Extract paragraphs from the current text file\n",
    "        paragraphs = extract_paragraphs(txt_file)\n",
    "\n",
    "        df_all = pd.DataFrame(columns=['TIME', 'TRANSLATION (ENGLISH)', 'TRANSCRIPTION (SESOTHO)', 'filepath'])\n",
    "\n",
    "        for paragraph in paragraphs:\n",
    "            df = process_paragraph(paragraph[0], '['+paragraph[1]+']', '['+paragraph[2]+']')\n",
    "\n",
    "            # Add the 'filepath' column with the current text file path\n",
    "            df['filepath'] = txt_file\n",
    "            \n",
    "            df_all = pd.concat([df_all, df], ignore_index=True)\n",
    "\n",
    "        # Generate the Excel file name based on the text file name\n",
    "        excel_file = os.path.join(output_folder, os.path.basename(txt_file).replace('.txt', '.xlsx'))\n",
    "        csv_file = os.path.join(output_folder, os.path.basename(txt_file).replace('.txt', '.csv'))\n",
    "\n",
    "        # Save the DataFrame to the Excel file\n",
    "        df_all.to_excel(excel_file, index=False)\n",
    "        df_all.to_csv(csv_file, index=False)\n",
    "\n",
    "# convert_txt_to_csv_xlsx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "xls_folder_path = \"../Interview XLSX/\"\n",
    "xls_file_extension = \".xlsx\"\n",
    "script_path = \"../Script/test script.txt\"\n",
    "output_matched_csv_file = \"../matched.csv\"\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove special characters from the text\n",
    "    cleaned_text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    return cleaned_text\n",
    "\n",
    "def match_line(line, df):\n",
    "    cleaned_line = clean_text(line.lower())  \n",
    "    matched_rows = []\n",
    "    for _, row in df.iterrows():\n",
    "        transcription = clean_text(str(row['TRANSCRIPTION (SESOTHO)']).lower())\n",
    "        translation = clean_text(str(row['TRANSLATION (ENGLISH)']).lower())\n",
    "        if cleaned_line in transcription or cleaned_line in translation:\n",
    "            matched_rows.append(row) \n",
    "    matched_rows_df = pd.concat(matched_rows, axis=1).transpose() if matched_rows else pd.DataFrame()\n",
    "    return matched_rows_df\n",
    "\n",
    "def get_word_indices(full_string, substring):\n",
    "    full_list = full_string.split()\n",
    "    sub_list = substring.split()\n",
    "    length = len(sub_list)\n",
    "    \n",
    "    for i in range(len(full_list)):\n",
    "        if full_list[i:i+length] == sub_list:\n",
    "            return i, i+length\n",
    "    return None, None\n",
    "\n",
    "\n",
    "\n",
    "def match_script_to_csv():\n",
    "\n",
    "\n",
    "    combined_df = pd.DataFrame()\n",
    "\n",
    "    for filename in os.listdir(xls_folder_path):\n",
    "        if filename.endswith(xls_file_extension):\n",
    "            file_path = os.path.join(xls_folder_path, filename)\n",
    "            df = pd.read_excel(file_path)\n",
    "            df['filepath'] = file_path\n",
    "            combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "\n",
    "    matched_rows = []\n",
    "\n",
    "    with open(script_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    narrator = None\n",
    "    language = None\n",
    "    for line in lines:\n",
    "        line = line.strip().lower()\n",
    "        if line.startswith('***'):\n",
    "            narrator = line[3:].strip().lower()\n",
    "            language = 'SESOTHO'\n",
    "        elif line.startswith('###'):\n",
    "            narrator = line[3:].strip().lower()\n",
    "            language = 'ENGLISH'\n",
    "        elif line and narrator and language:\n",
    "            matched_rows_df = match_line(line, combined_df)\n",
    "            cleaned_line = clean_text(line)\n",
    "            if not matched_rows_df.empty:\n",
    "                for _, row in matched_rows_df.iterrows():\n",
    "                    time_range = row['TIME'].split(\" - \")\n",
    "                    start_time = datetime.strptime(time_range[0], '%H:%M:%S')\n",
    "                    end_time = datetime.strptime(time_range[1], '%H:%M:%S')\n",
    "                    total_duration = (end_time - start_time).total_seconds()\n",
    "\n",
    "                    transcription = clean_text(str(row['TRANSCRIPTION (SESOTHO)']).lower())\n",
    "                    translation = clean_text(str(row['TRANSLATION (ENGLISH)']).lower())\n",
    "                    original_text = transcription if cleaned_line in transcription else translation\n",
    "                    if cleaned_line == original_text:\n",
    "                        new_row = {\n",
    "                            'Text': line,\n",
    "                            'Narrator': narrator,\n",
    "                            'Language': language,\n",
    "                            'Timecode Range': row['TIME'],\n",
    "                            'FilePath': row['filepath']\n",
    "                        }\n",
    "                    else:\n",
    "                        start_index, end_index = get_word_indices(original_text, cleaned_line)\n",
    "                        total_words = len(original_text.split())\n",
    "                        start_time = start_time + timedelta(seconds=total_duration*start_index/total_words)\n",
    "                        end_time = start_time + timedelta(seconds=total_duration*(end_index-start_index)/total_words)\n",
    "                        new_row = {\n",
    "                            'Text': line,\n",
    "                            'Narrator': narrator,\n",
    "                            'Language': language,\n",
    "                            'Timecode Range': f'{start_time.time()} - {end_time.time()}',\n",
    "                            'FilePath': row['filepath']\n",
    "                        }\n",
    "                    matched_rows.append(new_row)\n",
    "            else:  \n",
    "                new_row = {\n",
    "                    'Text': line,\n",
    "                    'Narrator': narrator,\n",
    "                    'Language': language,\n",
    "                    'Timecode Range': None,\n",
    "                    'FilePath': None\n",
    "                }\n",
    "                matched_rows.append(new_row)\n",
    "\n",
    "    matched_df = pd.DataFrame(matched_rows)\n",
    "    matched_df.to_csv(output_matched_csv_file, index=False)\n",
    "\n",
    "\n",
    "# match_script_to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import re\n",
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "final_subtitle_file = \"../final_subtitle.srt\"\n",
    "intermediate_csv_file = '../intermediate.csv'\n",
    "\n",
    "def time_to_srt_format(time):\n",
    "    return str(datetime.timedelta(seconds=time)).split('.')[0]\n",
    "\n",
    "def time_difference(time_str):\n",
    "    start, end = time_str.split(' - ')\n",
    "    try:\n",
    "        FMT = \"%H:%M:%S.%f\"\n",
    "        tdelta = datetime.datetime.strptime(end, FMT) - datetime.datetime.strptime(start, FMT)\n",
    "    except ValueError:\n",
    "        try:\n",
    "            FMT = \"%H:%M:%S\"\n",
    "            tdelta = datetime.datetime.strptime(end, FMT) - datetime.datetime.strptime(start, FMT)\n",
    "        except ValueError:\n",
    "            return 0\n",
    "    return tdelta.total_seconds()\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove special characters from the text\n",
    "    cleaned_text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    return cleaned_text\n",
    "\n",
    "def generate_subtitles():\n",
    "\n",
    "\n",
    "    with open(intermediate_csv_file, 'r') as csv_file, open(final_subtitle_file, 'w') as srt_file:\n",
    "        csv_reader = csv.reader(csv_file)\n",
    "        next(csv_reader)  # Skip header\n",
    "        counter = 1\n",
    "        last_time = 0\n",
    "        for row in csv_reader:\n",
    "            srt_file.write(str(counter) + '\\n')\n",
    "            if row[3]:  # If Timecode Range is not empty\n",
    "                start_time, end_time = row[3].split(' - ')\n",
    "                time_diff = time_difference(row[3])\n",
    "                start_seconds = last_time\n",
    "                end_seconds = last_time + time_diff\n",
    "                last_time = end_seconds\n",
    "                start_time = time_to_srt_format(start_seconds)\n",
    "                end_time = time_to_srt_format(end_seconds)\n",
    "                srt_file.write(start_time + ',000 --> ' + end_time + ',000\\n')\n",
    "            else:\n",
    "                start_time = time_to_srt_format(last_time)  # Start time based on last saved end time\n",
    "                last_time += 5  # Add 5 seconds to the last known time\n",
    "                end_time = time_to_srt_format(last_time)\n",
    "                srt_file.write(start_time + ',000 --> ' + end_time + ',000\\n')\n",
    "            srt_file.write(clean_text(row[0]) + '\\n\\n')  # Cleaned text\n",
    "            counter += 1\n",
    "\n",
    "# generate_subtitles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../intermediate_test.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 431\u001b[0m\n\u001b[0;32m    428\u001b[0m     create_xml(exported_xml_project_name,final_clip_list)\n\u001b[0;32m    429\u001b[0m \u001b[39m# print(final_clip_list)\u001b[39;00m\n\u001b[1;32m--> 431\u001b[0m run_extraction()\n",
      "Cell \u001b[1;32mIn[2], line 425\u001b[0m, in \u001b[0;36mrun_extraction\u001b[1;34m()\u001b[0m\n\u001b[0;32m    420\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_extraction\u001b[39m():\n\u001b[0;32m    421\u001b[0m         \n\u001b[0;32m    422\u001b[0m     \u001b[39m# Example usage\u001b[39;00m\n\u001b[1;32m--> 425\u001b[0m     process_csv_file(intermediate_csv_file, xml_folder)\n\u001b[0;32m    426\u001b[0m     final_clip_list \u001b[39m=\u001b[39m [item \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m final_clip_list \u001b[39mif\u001b[39;00m item \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m]\n\u001b[0;32m    427\u001b[0m     \u001b[39m# print(final_clip_list)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[2], line 276\u001b[0m, in \u001b[0;36mprocess_csv_file\u001b[1;34m(csv_file, xml_folder)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess_csv_file\u001b[39m(csv_file, xml_folder):\n\u001b[1;32m--> 276\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(csv_file, \u001b[39m\"\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m file:\n\u001b[0;32m    277\u001b[0m         csv_reader \u001b[39m=\u001b[39m csv\u001b[39m.\u001b[39mDictReader(file)\n\u001b[0;32m    278\u001b[0m         \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m csv_reader:\n",
      "File \u001b[1;32mc:\\Programming\\upwork\\xml_job\\AutoPremiere\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[0;32m    278\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    279\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[1;32m--> 284\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../intermediate_test.csv'"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from datetime import datetime, timedelta\n",
    "import copy\n",
    "import random\n",
    "import uuid\n",
    "\n",
    "\n",
    "final_clip_list = []\n",
    "id_mapping = {}\n",
    "# global sequence_start\n",
    "# global sequence_end\n",
    "\n",
    "sequence_start=0\n",
    "sequence_end=0\n",
    "xml_file_assigned=[]\n",
    "intermediate_csv_file = \"../intermediate_test.csv\"\n",
    "xml_folder = \"../Interview XML/\"\n",
    "exported_xml_project_name= 'testy'\n",
    "\n",
    "\n",
    "def create_xml(xml_name,xml_json_data):\n",
    "    \n",
    "    # Create the root element\n",
    "    root = ET.Element(\"xmeml\", version=\"4\")\n",
    "    \n",
    "    # Create the sequence element with attributes\n",
    "    sequence = ET.SubElement(root, \"sequence\", id=\"sequence-2\", TL_SQAudioVisibleBase=\"0\", TL_SQVideoVisibleBase=\"0\",\n",
    "                             TL_SQVisibleBaseTime=\"0\", TL_SQAVDividerPosition=\"0.5\", TL_SQHideShyTracks=\"0\",\n",
    "                             TL_SQHeaderWidth=\"236\", TL_SQDataTrackViewControlState=\"0\",\n",
    "                             Monitor_ProgramZoomOut=\"340011984312000\", Monitor_ProgramZoomIn=\"0\",\n",
    "                             TL_SQTimePerPixel=\"1.6034289012958367\", MZ_EditLine=\"333083126376000\",\n",
    "                             MZ_Sequence_PreviewFrameSizeHeight=\"1080\", MZ_Sequence_PreviewFrameSizeWidth=\"1920\",\n",
    "                             MZ_Sequence_AudioTimeDisplayFormat=\"200\", MZ_Sequence_PreviewUseMaxRenderQuality=\"false\",\n",
    "                             MZ_Sequence_PreviewUseMaxBitDepth=\"false\", MZ_Sequence_VideoTimeDisplayFormat=\"110\",\n",
    "                             MZ_WorkOutPoint=\"15235011792000\", MZ_WorkInPoint=\"0\", MZ_ZeroPoint=\"0\", explodedTracks=\"true\")\n",
    "    \n",
    "    # Add the uuid element\n",
    "    uuid = ET.SubElement(sequence, \"uuid\")\n",
    "    uuid.text = \"50e61931-251f-4069-8193-a3fbad7f93ff\"\n",
    "    \n",
    "    # Add the duration element\n",
    "    duration = ET.SubElement(sequence, \"duration\")\n",
    "    duration.text = \"31533\"\n",
    "    \n",
    "    # Add the rate element with nested timebase and ntsc elements\n",
    "    rate = ET.SubElement(sequence, \"rate\")\n",
    "    timebase = ET.SubElement(rate, \"timebase\")\n",
    "    timebase.text = \"24\"\n",
    "    ntsc = ET.SubElement(rate, \"ntsc\")\n",
    "    ntsc.text = \"TRUE\"\n",
    "    \n",
    "    # Add the name element\n",
    "    name_element = ET.SubElement(sequence, \"name\")\n",
    "    name_element.text = xml_name\n",
    "    \n",
    "    # Add the media element with nested video and audio elements\n",
    "    media = ET.SubElement(sequence, \"media\")\n",
    "    video = ET.SubElement(media, \"video\")\n",
    "\n",
    "    # Add the format element with nested samplecharacteristics element\n",
    "    format_ = ET.SubElement(video, \"format\")\n",
    "    samplecharacteristics = ET.SubElement(format_, \"samplecharacteristics\")\n",
    "    \n",
    "    # Add the rate element with nested timebase and ntsc elements inside samplecharacteristics\n",
    "    rate = ET.SubElement(samplecharacteristics, \"rate\")\n",
    "    timebase = ET.SubElement(rate, \"timebase\")\n",
    "    timebase.text = \"24\"\n",
    "    ntsc = ET.SubElement(rate, \"ntsc\")\n",
    "    ntsc.text = \"TRUE\"\n",
    "    \n",
    "    # Add the codec element with nested name and appspecificdata elements\n",
    "    codec = ET.SubElement(samplecharacteristics, \"codec\")\n",
    "    name = ET.SubElement(codec, \"name\")\n",
    "    name.text = \"Apple ProRes 422\"\n",
    "    appspecificdata = ET.SubElement(codec, \"appspecificdata\")\n",
    "    \n",
    "    # Add the appname, appmanufacturer, and appversion elements inside appspecificdata\n",
    "    appname = ET.SubElement(appspecificdata, \"appname\")\n",
    "    appname.text = \"Final Cut Pro\"\n",
    "    appmanufacturer = ET.SubElement(appspecificdata, \"appmanufacturer\")\n",
    "    appmanufacturer.text = \"Apple Inc.\"\n",
    "    appversion = ET.SubElement(appspecificdata, \"appversion\")\n",
    "    appversion.text = \"7.0\"\n",
    "    \n",
    "    # Add the data element with nested qtcodec element inside appspecificdata\n",
    "    data = ET.SubElement(appspecificdata, \"data\")\n",
    "    qtcodec = ET.SubElement(data, \"qtcodec\")\n",
    "    codecname = ET.SubElement(qtcodec, \"codecname\")\n",
    "    codecname.text = \"Apple ProRes 422\"\n",
    "    codectypename = ET.SubElement(qtcodec, \"codectypename\")\n",
    "    codectypename.text = \"Apple ProRes 422\"\n",
    "    codectypecode = ET.SubElement(qtcodec, \"codectypecode\")\n",
    "    codectypecode.text = \"apcn\"\n",
    "    codecvendorcode = ET.SubElement(qtcodec, \"codecvendorcode\")\n",
    "    codecvendorcode.text = \"appl\"\n",
    "    spatialquality = ET.SubElement(qtcodec, \"spatialquality\")\n",
    "    spatialquality.text = \"1024\"\n",
    "    temporalquality = ET.SubElement(qtcodec, \"temporalquality\")\n",
    "    temporalquality.text = \"0\"\n",
    "    keyframerate = ET.SubElement(qtcodec, \"keyframerate\")\n",
    "    keyframerate.text = \"0\"\n",
    "    datarate = ET.SubElement(qtcodec, \"datarate\")\n",
    "    datarate.text = \"0\"\n",
    "    \n",
    "    # Add the width, height, anamorphic, pixelaspectratio, fielddominance, and colordepth elements inside samplecharacteristics\n",
    "    width = ET.SubElement(samplecharacteristics, \"width\")\n",
    "    width.text = \"1920\"\n",
    "    height = ET.SubElement(samplecharacteristics, \"height\")\n",
    "    height.text = \"1080\"\n",
    "    anamorphic = ET.SubElement(samplecharacteristics, \"anamorphic\")\n",
    "    anamorphic.text = \"FALSE\"\n",
    "    pixelaspectratio = ET.SubElement(samplecharacteristics, \"pixelaspectratio\")\n",
    "    pixelaspectratio.text = \"square\"\n",
    "    fielddominance = ET.SubElement(samplecharacteristics, \"fielddominance\")\n",
    "    fielddominance.text = \"none\"\n",
    "    colordepth = ET.SubElement(samplecharacteristics, \"colordepth\")\n",
    "    colordepth.text = \"24\"\n",
    "\n",
    "    # Get the track elements\n",
    "    video_tracks = [1]\n",
    "    audio_tracks = []\n",
    "    for clip in xml_json_data:\n",
    "\n",
    "        audio_track_indexes = [link[\"trackindex\"] for link in clip[\"video_clips\"][0][\"links\"] if link[\"mediatype\"] == \"audio\"]\n",
    "        # print(audio_track_indexes)\n",
    "        for audio_track_index in audio_track_indexes:\n",
    "            if audio_track_index not in audio_tracks:\n",
    "                audio_tracks.append(audio_track_index)\n",
    "\n",
    "    # Create video track elements and append video clips\n",
    "    for video_track_index in video_tracks:\n",
    "        video_track = ET.SubElement(video, \"track\", TL_SQTrackShy=\"0\", TL_SQTrackExpandedHeight=\"25\",\n",
    "                                    TL_SQTrackExpanded=\"0\", MZ_TrackTargeted=\"0\")\n",
    "        # video_track.set(\"trackindex\", str(video_track_index))\n",
    "\n",
    "        for clip in xml_json_data:\n",
    "            video_clip = clip[\"video_clips\"][0][\"video_clip_element\"]\n",
    "            video_track.append(copy.deepcopy(video_clip))\n",
    "\n",
    "   \n",
    "    \n",
    "\n",
    "    \n",
    "    # Add the audio element inside media\n",
    "    audio = ET.SubElement(media, \"audio\")\n",
    "\n",
    "    # constant stuff\n",
    "\n",
    "    # Create subelements and append them to the audio element\n",
    "    num_output_channels = ET.SubElement(audio, 'numOutputChannels')\n",
    "    num_output_channels.text = '2'\n",
    "\n",
    "    format_element = ET.SubElement(audio, 'format')\n",
    "    sample_characteristics = ET.SubElement(format_element, 'samplecharacteristics')\n",
    "    depth = ET.SubElement(sample_characteristics, 'depth')\n",
    "    depth.text = '16'\n",
    "    sample_rate = ET.SubElement(sample_characteristics, 'samplerate')\n",
    "    sample_rate.text = '48000'\n",
    "\n",
    "    outputs = ET.SubElement(audio, 'outputs')\n",
    "\n",
    "    group_1 = ET.SubElement(outputs, 'group')\n",
    "    index_1 = ET.SubElement(group_1, 'index')\n",
    "    index_1.text = '1'\n",
    "    num_channels_1 = ET.SubElement(group_1, 'numchannels')\n",
    "    num_channels_1.text = '1'\n",
    "    downmix_1 = ET.SubElement(group_1, 'downmix')\n",
    "    downmix_1.text = '0'\n",
    "    channel_1 = ET.SubElement(group_1, 'channel')\n",
    "    channel_index_1 = ET.SubElement(channel_1, 'index')\n",
    "    channel_index_1.text = '1'\n",
    "\n",
    "    group_2 = ET.SubElement(outputs, 'group')\n",
    "    index_2 = ET.SubElement(group_2, 'index')\n",
    "    index_2.text = '2'\n",
    "    num_channels_2 = ET.SubElement(group_2, 'numchannels')\n",
    "    num_channels_2.text = '1'\n",
    "    downmix_2 = ET.SubElement(group_2, 'downmix')\n",
    "    downmix_2.text = '0'\n",
    "    channel_2 = ET.SubElement(group_2, 'channel')\n",
    "    channel_index_2 = ET.SubElement(channel_2, 'index')\n",
    "    channel_index_2.text = '2'\n",
    "\n",
    "     # Create audio track elements and append audio clips\n",
    "    for audio_track_index in audio_tracks:\n",
    "        audio_track = ET.SubElement(audio, \"track\", TL_SQTrackAudioKeyframeStyle=\"0\", TL_SQTrackShy=\"0\",\n",
    "                                    TL_SQTrackExpandedHeight=\"25\", TL_SQTrackExpanded=\"0\",\n",
    "                                    MZ_TrackTargeted=\"1\", PannerCurrentValue=\"0.5\", PannerIsInverted=\"true\",\n",
    "                                    PannerStartKeyframe=\"-91445760000000000,0.5,0,0,0,0,0,0\", PannerName=\"Balance\",\n",
    "                                    currentExplodedTrackIndex=f\"{audio_track_index-1}\", totalExplodedTrackCount=\"2\",\n",
    "                                    premiereTrackType=\"Stereo\")\n",
    "        # audio_track.set(\"trackindex\", str(audio_track_index))\n",
    "\n",
    "        for clip in xml_json_data:\n",
    "            audio_clip_elements = clip[\"video_clips\"][0][\"linked_audio_clip_elements_list\"]\n",
    "            \n",
    "            for audio_clip in audio_clip_elements:\n",
    "                if audio_track_index == audio_clip[1]:\n",
    "                    audio_track.append(copy.deepcopy(audio_clip[0]))\n",
    "    \n",
    "    # Add the timecode element with nested rate, string, frame, and displayformat elements\n",
    "    timecode = ET.SubElement(sequence, \"timecode\")\n",
    "    rate = ET.SubElement(timecode, \"rate\")\n",
    "    timebase = ET.SubElement(rate, \"timebase\")\n",
    "    timebase.text = \"24\"\n",
    "    ntsc = ET.SubElement(rate, \"ntsc\")\n",
    "    ntsc.text = \"TRUE\"\n",
    "    string = ET.SubElement(timecode, \"string\")\n",
    "    string.text = \"00:00:00:00\"\n",
    "    frame = ET.SubElement(timecode, \"frame\")\n",
    "    frame.text = \"0\"\n",
    "    displayformat = ET.SubElement(timecode, \"displayformat\")\n",
    "    displayformat.text = \"NDF\"\n",
    "    \n",
    "    # Add the labels element with nested label2 element\n",
    "    labels = ET.SubElement(sequence, \"labels\")\n",
    "    label2 = ET.SubElement(labels, \"label2\")\n",
    "    label2.text = \"Forest\"\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    # Create the ElementTree object with the root element\n",
    "    tree = ET.ElementTree(root)\n",
    "    \n",
    "    # Generate a random Idd\n",
    "    idd = str(random.randint(1, 1000))\n",
    "    \n",
    "    # Save the XML to a file\n",
    "    filename = f\"../xml exports/{xml_name.replace(' ', '_')}-{idd}.xml\"\n",
    "    tree.write(filename, encoding=\"utf-8\", xml_declaration=True)\n",
    "    print(f\"XML saved to {filename}\")\n",
    "\n",
    "\n",
    "def generate_unique_id():\n",
    "    unique_id = f\"clipitem-{uuid.uuid4().hex}\"\n",
    "    return unique_id\n",
    "\n",
    "def update_xml_ids(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    print('Assigning unique IDs to clipitem elements...')\n",
    "\n",
    "    # Generate unique IDs for clipitem elements\n",
    "      # Store the mapping of old IDs to new unique IDs\n",
    "    for clip_item in root.findall('.//clipitem'):  # Adjust the XPath expression based on the actual location of clipitem elements\n",
    "        current_id = clip_item.attrib['id']\n",
    "        unique_id = generate_unique_id()\n",
    "        id_mapping[current_id] = unique_id\n",
    "        clip_item.attrib['id'] = unique_id\n",
    "\n",
    "    \n",
    "        # Update the references in the links section\n",
    "    for link in root.findall('.//link'):\n",
    "        linkclipref = link.find('linkclipref')\n",
    "        if linkclipref is not None and linkclipref.text in id_mapping:\n",
    "            linkclipref.text = id_mapping[linkclipref.text]\n",
    "    print(id_mapping)\n",
    "\n",
    "    # Save the modified XML file\n",
    "    tree.write(xml_file, encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "\n",
    "def extract_timecode(timecode_range):\n",
    "    start_time, end_time = timecode_range.split(\" - \")\n",
    "    start_time = start_time.strip().replace(\" \", \"\")\n",
    "    end_time = end_time.strip().replace(\" \", \"\")\n",
    "    print('Start Time',start_time,'End Time', end_time)\n",
    "    return start_time, end_time\n",
    "\n",
    "\n",
    "def process_csv_file(csv_file, xml_folder):\n",
    "    with open(csv_file, \"r\") as file:\n",
    "        csv_reader = csv.DictReader(file)\n",
    "        for row in csv_reader:\n",
    "            timecode_range = row[\"Timecode Range\"]\n",
    "            if timecode_range:\n",
    "                start_time, end_time = extract_timecode(timecode_range)\n",
    "                narrator_name = row[\"Narrator\"]\n",
    "                print('Narrator Name:' ,narrator_name)\n",
    "                process_xml_files(xml_folder, start_time, end_time, narrator_name)\n",
    "\n",
    "\n",
    "def process_xml_files(xml_folder, start_time, end_time, narrator_name):\n",
    "    global xml_file_assigned,final_clip_list\n",
    "    for filename in os.listdir(xml_folder):\n",
    "        if filename.endswith(\".xml\") and narrator_name in filename:\n",
    "            # print(filename,narrator_name)\n",
    "            xml_file = os.path.join(xml_folder, filename)\n",
    "            if xml_file not in xml_file_assigned:\n",
    "                update_xml_ids(xml_file)\n",
    "                xml_file_assigned.append(xml_file)\n",
    "            matched_clips = extract_sequence_info(xml_file, start_time, end_time)\n",
    "            final_clip_list.append(matched_clips)\n",
    "\n",
    "\n",
    "def convert_time_to_frames(time, rate):\n",
    "    time_format = \"%H:%M:%S\"\n",
    "    if \".\" in time:\n",
    "        time_format += \".%f\"\n",
    "    time_obj = datetime.strptime(time, time_format)\n",
    "    time_delta = time_obj - datetime.strptime(\"00:00:00\", \"%H:%M:%S\")\n",
    "    frame_count = int(time_delta.total_seconds() * rate)\n",
    "    return frame_count\n",
    "\n",
    "\n",
    "def frame_to_ticks(frame_number, frame_rate):\n",
    "    total_ticks_in_a_second = 254016000000\n",
    "    tick_value = int((frame_number * total_ticks_in_a_second) / frame_rate)\n",
    "    return tick_value\n",
    "\n",
    "\n",
    "def extract_sequence_info(xml_file, start_time, end_time):\n",
    "    global sequence_start, sequence_end\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Extract sequence information\n",
    "    sequence = root.find('sequence')\n",
    "    sequence_info = {\n",
    "        'duration': int(sequence.find('duration').text),\n",
    "        'rate': {\n",
    "            'timebase': int(sequence.find('rate/timebase').text),\n",
    "            'ntsc': sequence.find('rate/ntsc').text == 'TRUE'\n",
    "        }\n",
    "    }\n",
    "    sequence_rate = sequence_info['rate']['timebase']\n",
    "\n",
    "    # Convert start and end times to frames\n",
    "    start_frame = convert_time_to_frames(start_time, sequence_rate)\n",
    "    end_frame = convert_time_to_frames(end_time, sequence_rate)\n",
    "    proTickIn=frame_to_ticks(start_frame,sequence_rate)\n",
    "    proTickOut=frame_to_ticks(end_frame,sequence_rate)\n",
    "    \n",
    "    print('Start and End Frame',start_frame ,end_frame)\n",
    "    print(sequence_rate,'sequence_rate')\n",
    "\n",
    "    # Extract video clip information\n",
    "    video_clips = []\n",
    "    for clip_item in root.findall('.//video//clipitem'):  # Only consider clip items within the <video> tag\n",
    "        \n",
    "        clip_info = {\n",
    "            'id': clip_item.attrib['id'],  # Get the clip ID\n",
    "            'name': clip_item.find('name').text,\n",
    "            'duration': int(clip_item.find('duration').text),\n",
    "            'rate': {\n",
    "                'timebase': int(clip_item.find('rate/timebase').text),\n",
    "                'ntsc': clip_item.find('rate/ntsc').text == 'TRUE'\n",
    "            },\n",
    "            'in': int(clip_item.find('in').text),\n",
    "            'out': int(clip_item.find('out').text),\n",
    "            'start': int(clip_item.find('start').text),\n",
    "            'end': int(clip_item.find('end').text),\n",
    "            'links': [],  # Initialize an empty list to store links,\n",
    "            'video_clip_element': None,  # Store the clip item element for later use\n",
    "            'linked_audio_clip_elements_list': []  # Initialize an empty list to store linked clip items\n",
    "        }\n",
    "\n",
    "        if clip_info['in'] <= start_frame <= clip_info['out']:\n",
    "            sequence_start=sequence_end+10\n",
    "            sequence_end=sequence_start+(end_frame-start_frame)\n",
    "\n",
    "        links = clip_item.findall('link')\n",
    "        for link in links:\n",
    "            link_info = {\n",
    "                'linkclipref': link.find('linkclipref').text,\n",
    "                'mediatype': link.find('mediatype').text,\n",
    "                'trackindex': int(link.find('trackindex').text),\n",
    "                'clipindex': int(link.find('clipindex').text)\n",
    "            }\n",
    "            if link.find('groupindex') is not None:\n",
    "                link_info['groupindex'] = int(link.find('groupindex').text)\n",
    "            clip_info['links'].append(link_info)\n",
    "            if link.find('mediatype').text == 'audio':\n",
    "                audio_clip_items = root.findall('.//audio//clipitem')\n",
    "                for audio_clip_item in audio_clip_items:\n",
    "                    if audio_clip_item.attrib['id'] == link.find('linkclipref').text:\n",
    "                        audio_clip_item.find('in').text = str(start_frame)  \n",
    "                        audio_clip_item.find('out').text = str(end_frame)\n",
    "                        audio_clip_item.find('start').text = str(sequence_start)  \n",
    "                        audio_clip_item.find('end').text = str(sequence_end)\n",
    "                        audio_clip_item.find('pproTicksIn').text = str(proTickIn)  \n",
    "                        audio_clip_item.find('pproTicksOut').text = str(proTickOut)\n",
    "                        clip_info['linked_audio_clip_elements_list'].append([audio_clip_item,int(link.find('trackindex').text)])\n",
    "\n",
    "        # Check if the clip's in or out frame falls within the given start and end frames\n",
    "        print('Clip Frame Inside file Found: ',clip_info['in'] <= start_frame <= clip_info['out'])\n",
    "        print('Start - Matching - End')\n",
    "        print(clip_info['in'],start_frame,clip_info['out'])\n",
    "        if clip_info['in'] <= start_frame <= clip_info['out']:\n",
    "            clip_item.find('in').text = str(start_frame)  \n",
    "            clip_item.find('out').text = str(end_frame)\n",
    "            clip_item.find('start').text = str(sequence_start)  \n",
    "            clip_item.find('end').text = str(sequence_end)\n",
    "            clip_info['video_clip_element']=clip_item\n",
    "            video_clips.append(clip_info)\n",
    "            print('Next Sequence Start',sequence_start)\n",
    "            print('Next Sequence End',sequence_end)\n",
    "            \n",
    "        \n",
    "    # print(clip_info, start_frame, end_frame)\n",
    "\n",
    "    # Create result dictionary\n",
    "    result = {\n",
    "        'sequence_info': sequence_info,\n",
    "        'video_clips': video_clips\n",
    "    }\n",
    "    # print('Result',result)\n",
    "\n",
    "    if not video_clips:  # Check if video_clips list is empty\n",
    "        return None\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def run_extraction():\n",
    "        \n",
    "    # Example usage\n",
    "    \n",
    "\n",
    "    process_csv_file(intermediate_csv_file, xml_folder)\n",
    "    final_clip_list = [item for item in final_clip_list if item is not None]\n",
    "    # print(final_clip_list)\n",
    "    create_xml(exported_xml_project_name,final_clip_list)\n",
    "# print(final_clip_list)\n",
    "\n",
    "run_extraction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
