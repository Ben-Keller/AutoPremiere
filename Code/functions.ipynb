{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "import csv\n",
    "import xml.etree.ElementTree as ET\n",
    "import copy\n",
    "import random\n",
    "import uuid\n",
    "\n",
    "csv_folder_path = \"../Interview CSV\"\n",
    "\n",
    "script_path = \"../Script/test script.txt\"\n",
    "script_csv_output_path = \"../Script/script_export.csv\"\n",
    "\n",
    "final_subtitle_file = \"../Script/script.srt\"\n",
    "\n",
    "xml_folder = \"../Interview XML/\"\n",
    "exported_xml_project_name= 'testy'\n",
    "\n",
    "final_clip_list = []\n",
    "id_mapping = {}\n",
    "# global sequence_start\n",
    "# global sequence_end\n",
    "\n",
    "sequence_start=0\n",
    "sequence_end=0\n",
    "xml_file_assigned=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Helper functions </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45194"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def timecode_to_frames(text):\n",
    "    if len(text.split(\":\"))==2:\n",
    "        frames=(int(text.split(\":\")[0])*60+int(text.split(\":\")[1]))*24\n",
    "    elif len(text.split(\":\"))==3:\n",
    "        frames=(int(text.split(\":\")[0])*3600+int(text.split(\":\")[1])*60+int(text.split(\":\")[2]))*24\n",
    "    elif len(text.split(\":\"))==4:\n",
    "        frames=(int(text.split(\":\")[0])*3600+int(text.split(\":\")[1])*60+int(text.split(\":\")[2]))*24+int(text.split(\":\")[3])\n",
    "    else:\n",
    "        print(text+\"timecode parse error\")\n",
    "    return frames\n",
    "\n",
    "timecode_to_frames(\"00:31:23:02\")  #test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def frames_to_timecode(frames):\n",
    "    frames=int(frames)\n",
    "    hours = frames // (3600*24)\n",
    "    remaining_frames = frames % (3600*24)\n",
    "    minutes=remaining_frames // (60*24)\n",
    "    remaining_frames=remaining_frames % (60*24)\n",
    "    seconds=remaining_frames // (24)\n",
    "    remaining_frames =remaining_frames %(24)\n",
    "    frames=remaining_frames\n",
    "\n",
    "\n",
    "\n",
    "    timecode=\"{:02d}\".format(hours)+\":\"+\"{:02d}\".format(minutes)+\":\"+\"{:02d}\".format(seconds)+\":\"+\"{:02d}\".format(frames)\n",
    "\n",
    "    return timecode\n",
    "\n",
    "#frames_to_timecode(45194)   #test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Remove special characters from the text\n",
    "    cleaned_text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    return cleaned_text\n",
    "\n",
    "#clean_text(\"abcd$$\")   #test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_line(line, narrator, df):\n",
    "    cleaned_line = clean_text(line.lower())  \n",
    "    matched_rows = []\n",
    "\n",
    "    #df=df[df[\"NARRATOR\"].str.lower()==narrator]\n",
    "#    print(df)\n",
    "\n",
    "    for index,row in df.iterrows():\n",
    "        text = clean_text(str(row['TEXT']).lower())\n",
    "        if cleaned_line in text:\n",
    "            matched_rows.append(row) \n",
    "    matched_rows_df = pd.concat(matched_rows, axis=1).transpose() if matched_rows else pd.DataFrame()\n",
    "    return matched_rows_df\n",
    "\n",
    "\n",
    "##add test here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 7)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_character_indices(full_string, substring):\n",
    "    full_list = list(full_string.lower())\n",
    "    sub_list = list(substring.lower())\n",
    "    length = len(sub_list)\n",
    "    \n",
    "    for i in range(len(full_list)):\n",
    "        if full_list[i:i+length] == sub_list:\n",
    "            return i, i+length\n",
    "    return None, None\n",
    "\n",
    "get_character_indices(\"abc def iopoi\",\"def\")   #test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Convert Script to coded CSV </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The match_script_to_csv() function performs a matching operation between a script file and a\n",
    "#  folder containing data from multiple CSV files\n",
    "# in order to generate a csv version of the script with links to files and timecodes\n",
    "\n",
    "def match_script_to_csv(script_path):\n",
    "\n",
    "    combined_df = pd.DataFrame()\n",
    "\n",
    "    for filename in os.listdir(csv_folder_path):\n",
    "        if filename.endswith(\"csv\"):\n",
    "            file_path = os.path.join(csv_folder_path, filename)\n",
    "            df = pd.read_csv(file_path)\n",
    "            df[\"NARRATOR\"]=(filename.split(\" \")[1])\n",
    "            df['FILEPATH'] = file_path\n",
    "            combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "\n",
    "    matched_rows = []\n",
    "\n",
    "    with open(script_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    narrator = None\n",
    "    for line in lines:\n",
    "        line=line.strip()\n",
    "        if line==\"\":\n",
    "            pass\n",
    "        elif line[:3]==\"###\":\n",
    "            narrator=line.strip()[3:]\n",
    "        else:\n",
    "            matched_rows_df = match_line(line, narrator, combined_df)\n",
    "            cleaned_line = clean_text(line)\n",
    "            if not matched_rows_df.empty:\n",
    "                for index,row in matched_rows_df.iterrows():\n",
    "                    print(row)\n",
    "                    time_range = [s.strip() for s in row['TIME'].split(\"-\")]\n",
    "                    start_time = timecode_to_frames(time_range[0])\n",
    "                    end_time = timecode_to_frames(time_range[1])\n",
    "                    total_duration = end_time - start_time\n",
    "\n",
    "                    text = clean_text(str(row['TEXT']).lower())\n",
    "\n",
    "                    ##if the row matches completely, the new and original start/end times should match\n",
    "\n",
    "                    print(text,cleaned_line)\n",
    "\n",
    "                    start_index, end_index = get_character_indices(text, cleaned_line)\n",
    "                    total_characters = len(list(text))\n",
    "\n",
    "                    print(start_time,total_duration,total_characters,start_index)\n",
    "\n",
    "                    new_start_time = start_time + total_duration/total_characters*start_index\n",
    "                    new_end_time = start_time + total_duration/total_characters*end_index\n",
    "\n",
    "                    new_row = {\n",
    "                        'Text': line,\n",
    "                        'Narrator': narrator,\n",
    "                        'Timecode Range': frames_to_timecode(new_start_time) +\" - \" + frames_to_timecode(new_end_time),\n",
    "                        'FilePath': row['FILEPATH']\n",
    "                        }\n",
    "            else:\n",
    "                ##if no match is found, the line is added anyway but with no timecode or filepath\n",
    "                new_row = {\n",
    "                        'Text': line,\n",
    "                        'Narrator': narrator,\n",
    "                        'Timecode Range': None,\n",
    "                        'FilePath': None\n",
    "                    }\n",
    "            matched_rows.append(new_row)\n",
    "\n",
    "    matched_df = pd.DataFrame.from_records(matched_rows)\n",
    "    return matched_df\n",
    "\n",
    "# match_script_to_csv(script_path).to_csv(script_csv_output_path) #test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Generate subtitles from coded script csv </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertTimecodeToSubFormat(timecode):\n",
    "    timecodeSplit=timecode.split(\":\")\n",
    "    timecodeSplit[3]=str(int(int(timecodeSplit[3])/24*1000))\n",
    "    timecodeNew = \":\".join(timecodeSplit[:3])+\",\"+timecodeSplit[3]\n",
    "    return timecodeNew\n",
    "\n",
    "#convertTimecodeToSubFormat(\"01:02:03:04\")   #test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "\n",
    "# the generate_subtitles() function reads a script CSV file, performs time calculations\n",
    "# and formatting, and writes the generated subtitles to a final subtitle file in the SRT format. if no time is found\n",
    "# it adds 5 seconds to the last time.\n",
    "\n",
    "def generate_subtitles(script_csv_file,final_subtitle_file):\n",
    "\n",
    "    with open(final_subtitle_file, 'w') as srt_file:\n",
    "        script_csv=pd.read_csv(script_csv_file)\n",
    "        counter = 1\n",
    "        last_time = 0\n",
    "        for index,row in script_csv.iterrows():\n",
    "            srt_file.write(str(counter) + '\\n')\n",
    "            \n",
    "            new_start_frames=last_time\n",
    "\n",
    "            if not pd.isna(row[\"Timecode Range\"]):  # If Timecode Range is not empty\n",
    "\n",
    "                start_time, end_time = [s.strip() for s in row[\"Timecode Range\"].split('-')]\n",
    "                start_frames=timecode_to_frames(start_time)\n",
    "                end_frames=timecode_to_frames(end_time)\n",
    "\n",
    "                new_end_frames= last_time+ end_frames - start_frames\n",
    "                last_time=new_end_frames\n",
    "\n",
    "            else:\n",
    "                new_end_frames = new_start_frames+120\n",
    "                last_time=new_end_frames\n",
    "\n",
    "            srt_file.write(convertTimecodeToSubFormat(frames_to_timecode(new_start_frames)) +' --> ' + convertTimecodeToSubFormat(frames_to_timecode(new_end_frames)) + '\\n')\n",
    "            \n",
    "            srt_file.write(clean_text(row[\"Text\"]) + '\\n\\n')  # Cleaned text\n",
    "            counter += 1\n",
    "\n",
    "generate_subtitles(script_csv_output_path,final_subtitle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converts Time to Frames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78662"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_time_to_frames(time, rate):\n",
    "    # print('Time', time, 'Rate', rate)\n",
    "    parts = time.split(\":\")\n",
    "    hours = int(parts[0])\n",
    "    minutes = int(parts[1])\n",
    "    seconds = int(parts[2])\n",
    "    frames = int(parts[3])\n",
    "    \n",
    "    # Calculate the total duration in frames\n",
    "    total_frames = (\n",
    "        hours * 3600 * rate +  # Convert hours to frames\n",
    "        minutes * 60 * rate +  # Convert minutes to frames\n",
    "        seconds * rate +  # Convert seconds to frames\n",
    "        frames\n",
    "    )\n",
    "    \n",
    "    return total_frames\n",
    "\n",
    "convert_time_to_frames('00:54:36:38', 24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate New ids for the each Clip item in seperate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'clipitem-35d8fe86ca684bc6a25d91ee69f90b04'"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_unique_id():\n",
    "    unique_id = f\"clipitem-{uuid.uuid4().hex}\"\n",
    "    return unique_id\n",
    "\n",
    "generate_unique_id()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the id of clips in specific XML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_xml_ids(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    print('Assigning unique IDs to clipitem elements...')\n",
    "\n",
    "    # Generate unique IDs for clipitem elements\n",
    "      # Store the mapping of old IDs to new unique IDs\n",
    "    for clip_item in root.findall('.//clipitem'):  # Adjust the XPath expression based on the actual location of clipitem elements\n",
    "        current_id = clip_item.attrib['id']\n",
    "        unique_id = generate_unique_id()\n",
    "        id_mapping[current_id] = unique_id\n",
    "        clip_item.attrib['id'] = unique_id\n",
    "\n",
    "    \n",
    "        # Update the references in the links section\n",
    "    for link in root.findall('.//link'):\n",
    "        linkclipref = link.find('linkclipref')\n",
    "        if linkclipref is not None and linkclipref.text in id_mapping:\n",
    "            linkclipref.text = id_mapping[linkclipref.text]\n",
    "    print(id_mapping)\n",
    "\n",
    "    # Save the modified XML file\n",
    "    tree.write(xml_file, encoding=\"utf-8\")\n",
    "\n",
    "# update_xml_ids(xml_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract time in  start and end time format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Time 00:00:00:00 End Time 00:23:00:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('00:00:00:00', '00:23:00:00')"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_timecode(timecode_range):\n",
    "    start_time, end_time = timecode_range.split(\" - \")\n",
    "    start_time = start_time.strip().replace(\" \", \"\")\n",
    "    end_time = end_time.strip().replace(\" \", \"\")\n",
    "    print('Start Time',start_time,'End Time', end_time)\n",
    "    return start_time, end_time\n",
    "\n",
    "extract_timecode(\"00:00:00:00 - 00:23:00:00\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert frame to tick number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_to_ticks(frame_number, frame_rate):\n",
    "    total_ticks_in_a_second = 254016000000\n",
    "    tick_value = int((frame_number * total_ticks_in_a_second) / frame_rate)\n",
    "    return tick_value\n",
    "\n",
    "# frame_to_ticks(24, 24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract sequences through xml file and extract the clips that match with the start and end time using frame comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_sequence_info(xml_file, start_time, end_time):\n",
    "    global sequence_start, sequence_end\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Extract sequence information\n",
    "    sequence = root.find('sequence')\n",
    "    sequence_info = {\n",
    "        'duration': int(sequence.find('duration').text),\n",
    "        'rate': {\n",
    "            'timebase': int(sequence.find('rate/timebase').text),\n",
    "            'ntsc': sequence.find('rate/ntsc').text == 'TRUE'\n",
    "        }\n",
    "    }\n",
    "    sequence_rate = sequence_info['rate']['timebase']\n",
    "\n",
    "    # Convert start and end times to frames\n",
    "    start_frame = convert_time_to_frames(start_time, 24)\n",
    "    end_frame = convert_time_to_frames(end_time, 24)\n",
    "    proTickIn=frame_to_ticks(start_frame,24)\n",
    "    proTickOut=frame_to_ticks(end_frame,24)\n",
    "    \n",
    "    # print('Start and End Frame',start_frame ,end_frame)\n",
    "    # print(sequence_rate,'sequence_rate')\n",
    "\n",
    "    # Extract video clip information\n",
    "    video_clips = []\n",
    "    for track_index, track in enumerate(root.findall('.//video/track')):  # Iterate over all tracks within the <video> tag\n",
    "        # track_idx = 0\n",
    "        for clip_item in track.findall('clipitem'):  # Only consider clip items within the <video> tag\n",
    "\n",
    "            links = clip_item.findall('link')\n",
    "            track_idx = [int(link.find('trackindex').text) for link in clip_item.findall('link') if link.find('mediatype').text == 'video']\n",
    "            print('Track Index',track_idx)\n",
    "            \n",
    "            clip_info = {\n",
    "                'id': clip_item.attrib['id'],  # Get the clip ID\n",
    "                'name': clip_item.find('name').text,\n",
    "                'duration': int(clip_item.find('duration').text),\n",
    "                'rate': {\n",
    "                    'timebase': int(clip_item.find('rate/timebase').text),\n",
    "                    'ntsc': clip_item.find('rate/ntsc').text == 'TRUE'\n",
    "                },\n",
    "                'in': int(clip_item.find('in').text),\n",
    "                'out': int(clip_item.find('out').text),\n",
    "                'start': int(clip_item.find('start').text),\n",
    "                'end': int(clip_item.find('end').text),\n",
    "                'track_index': track_idx[0],  \n",
    "                'links': [],  # Initialize an empty list to store links,\n",
    "                'video_clip_element': None,  # Store the clip item element for later use\n",
    "                'linked_audio_clip_elements_list': []  # Initialize an empty list to store linked clip items\n",
    "            }\n",
    "\n",
    "            if clip_info['in'] <= start_frame <= clip_info['out'] or clip_info['in'] <= end_frame <= clip_info['out']:\n",
    "                sequence_start=sequence_end+120\n",
    "                sequence_end=sequence_start+(end_frame-start_frame)\n",
    "\n",
    "            \n",
    "            for link in links:\n",
    "                link_info = {\n",
    "                    'linkclipref': link.find('linkclipref').text,\n",
    "                    'mediatype': link.find('mediatype').text,\n",
    "                    'trackindex': int(link.find('trackindex').text),\n",
    "                    'clipindex': int(link.find('clipindex').text)\n",
    "                }\n",
    "                if link.find('groupindex') is not None:\n",
    "                    link_info['groupindex'] = int(link.find('groupindex').text)\n",
    "                clip_info['links'].append(link_info)\n",
    "                if link.find('mediatype').text == 'audio':\n",
    "                    audio_clip_items = root.findall('.//audio//clipitem')\n",
    "                    for audio_clip_item in audio_clip_items:\n",
    "                        if audio_clip_item.attrib['id'] == link.find('linkclipref').text:\n",
    "                            audio_clip_item.find('in').text = str(start_frame)  \n",
    "                            audio_clip_item.find('out').text = str(end_frame)\n",
    "                            audio_clip_item.find('start').text = str(sequence_start)  \n",
    "                            audio_clip_item.find('end').text = str(sequence_end)\n",
    "                            audio_clip_item.find('pproTicksIn').text = str(proTickIn)  \n",
    "                            audio_clip_item.find('pproTicksOut').text = str(proTickOut)\n",
    "                            clip_info['linked_audio_clip_elements_list'].append(\n",
    "\n",
    "                                {\n",
    "            'audio_clip_item': audio_clip_item,\n",
    "            'trackindex': int(link.find('trackindex').text),\n",
    "            'sourceindex': int(audio_clip_item.find('.//sourcetrack/trackindex').text)\n",
    "        }\n",
    "                                )\n",
    "\n",
    "            # Check if the clip's in or out frame falls within the given start and end frames\n",
    "            print('Clip Frame Inside file Found: ',clip_info['in'] <= start_frame <= clip_info['out'])\n",
    "            print('In - Matching - Out')\n",
    "            print(clip_info['in'],start_frame,clip_info['out'])\n",
    "            if clip_info['in'] <= start_frame <= clip_info['out'] or clip_info['in'] <= end_frame <= clip_info['out']:\n",
    "                clip_item.find('in').text = str(start_frame)  \n",
    "                clip_item.find('out').text = str(end_frame)\n",
    "                clip_item.find('start').text = str(sequence_start)  \n",
    "                clip_item.find('end').text = str(sequence_end)\n",
    "                clip_item.find('pproTicksIn').text = str(proTickIn)  \n",
    "                clip_item.find('pproTicksOut').text = str(proTickOut)\n",
    "                clip_info['video_clip_element']=clip_item\n",
    "                video_clips.append(clip_info)\n",
    "                print('Next Sequence Start',sequence_start)\n",
    "                print('Next Sequence End',sequence_end)\n",
    "            \n",
    "        \n",
    "    # print(clip_info, start_frame, end_frame)\n",
    "\n",
    "    # Create result dictionary\n",
    "    result = {\n",
    "        'sequence_info': sequence_info,\n",
    "        'video_clips': video_clips\n",
    "    }\n",
    "    # print('Result',result)\n",
    "\n",
    "    if not video_clips:  # Check if video_clips list is empty\n",
    "        return None\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions go through all the xml files and call the  extract clips function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_xml_files(xml_folder, start_time, end_time, narrator_name):\n",
    "    global xml_file_assigned,final_clip_list\n",
    "    for filename in os.listdir(xml_folder):\n",
    "        if filename.endswith(\".xml\") and narrator_name.lower() in filename.lower():\n",
    "            # print(filename,narrator_name)\n",
    "            xml_file = os.path.join(xml_folder, filename)\n",
    "            if xml_file not in xml_file_assigned:\n",
    "                update_xml_ids(xml_file)\n",
    "                xml_file_assigned.append(xml_file)\n",
    "            matched_clips = extract_sequence_info(xml_file, start_time, end_time)\n",
    "            final_clip_list.append(matched_clips)\n",
    "\n",
    "\n",
    "\n",
    "def process_csv_file(csv_file):\n",
    "    xml_folder = \"../Interview XML/\"\n",
    "    with open(csv_file, \"r\") as file:\n",
    "        csv_reader = csv.DictReader(file)\n",
    "        for row in csv_reader:\n",
    "            timecode_range = row[\"Timecode Range\"]\n",
    "            if timecode_range:\n",
    "                start_time, end_time = extract_timecode(timecode_range)\n",
    "                narrator_name = row[\"Narrator\"]\n",
    "                print('Narrator Name:' ,narrator_name)\n",
    "                process_xml_files(xml_folder, start_time, end_time, narrator_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Create Basic XML Structure </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_xml(xml_name):\n",
    "    \n",
    "    # Create the root element\n",
    "    root = ET.Element(\"xmeml\", version=\"4\")\n",
    "    \n",
    "    # Create the sequence element with attributes\n",
    "    sequence = ET.SubElement(root, \"sequence\", id=\"sequence-2\", TL_SQAudioVisibleBase=\"0\", TL_SQVideoVisibleBase=\"0\",\n",
    "                             TL_SQVisibleBaseTime=\"0\", TL_SQAVDividerPosition=\"0.5\", TL_SQHideShyTracks=\"0\",\n",
    "                             TL_SQHeaderWidth=\"236\", TL_SQDataTrackViewControlState=\"0\",\n",
    "                             Monitor_ProgramZoomOut=\"340011984312000\", Monitor_ProgramZoomIn=\"0\",\n",
    "                             TL_SQTimePerPixel=\"1.6034289012958367\", MZ_EditLine=\"333083126376000\",\n",
    "                             MZ_Sequence_PreviewFrameSizeHeight=\"1080\", MZ_Sequence_PreviewFrameSizeWidth=\"1920\",\n",
    "                             MZ_Sequence_AudioTimeDisplayFormat=\"200\", MZ_Sequence_PreviewUseMaxRenderQuality=\"false\",\n",
    "                             MZ_Sequence_PreviewUseMaxBitDepth=\"false\", MZ_Sequence_VideoTimeDisplayFormat=\"110\",\n",
    "                             MZ_WorkOutPoint=\"15235011792000\", MZ_WorkInPoint=\"0\", MZ_ZeroPoint=\"0\", explodedTracks=\"true\")\n",
    "    \n",
    "    # Add the uuid element\n",
    "    uuid = ET.SubElement(sequence, \"uuid\")\n",
    "    uuid.text = \"50e61931-251f-4069-8193-a3fbad7f93ff\"\n",
    "    \n",
    "    # Add the duration element\n",
    "    duration = ET.SubElement(sequence, \"duration\")\n",
    "    duration.text = \"31533\"\n",
    "    \n",
    "    # Add the rate element with nested timebase and ntsc elements\n",
    "    rate = ET.SubElement(sequence, \"rate\")\n",
    "    timebase = ET.SubElement(rate, \"timebase\")\n",
    "    timebase.text = \"24\"\n",
    "    ntsc = ET.SubElement(rate, \"ntsc\")\n",
    "    ntsc.text = \"TRUE\"\n",
    "    \n",
    "    # Add the name element\n",
    "    name_element = ET.SubElement(sequence, \"name\")\n",
    "    name_element.text = xml_name\n",
    "    \n",
    "    # Add the media element with nested video and audio elements\n",
    "    media = ET.SubElement(sequence, \"media\")\n",
    "\n",
    "    \n",
    " \n",
    "    \n",
    "    # Add the timecode element with nested rate, string, frame, and displayformat elements\n",
    "    timecode = ET.SubElement(sequence, \"timecode\")\n",
    "    rate = ET.SubElement(timecode, \"rate\")\n",
    "    timebase = ET.SubElement(rate, \"timebase\")\n",
    "    timebase.text = \"24\"\n",
    "    ntsc = ET.SubElement(rate, \"ntsc\")\n",
    "    ntsc.text = \"TRUE\"\n",
    "    string = ET.SubElement(timecode, \"string\")\n",
    "    string.text = \"00:00:00:00\"\n",
    "    frame = ET.SubElement(timecode, \"frame\")\n",
    "    frame.text = \"0\"\n",
    "    displayformat = ET.SubElement(timecode, \"displayformat\")\n",
    "    displayformat.text = \"NDF\"\n",
    "    \n",
    "    # Add the labels element with nested label2 element\n",
    "    labels = ET.SubElement(sequence, \"labels\")\n",
    "    label2 = ET.SubElement(labels, \"label2\")\n",
    "    label2.text = \"Forest\"\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    # Create the ElementTree object with the root element\n",
    "    tree = ET.ElementTree(root)\n",
    "    \n",
    "    # Generate a random Idd\n",
    "    idd = str(random.randint(1, 1000))\n",
    "    \n",
    "    # Save the XML to a file\n",
    "    filename = f\"{xml_name.replace(' ', '_')}-{idd}.xml\"\n",
    "    tree.write(f\"../xml exports/{filename}\", encoding=\"utf-8\", xml_declaration=True)\n",
    "    print(f\"XML saved to {filename}\")\n",
    "\n",
    "    return filename \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append Video to XML File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_video_to_xml(file_name, xml_json_data):\n",
    "    print(f\"Adding Video Tracks to {file_name}\")\n",
    "    # Parse the XML data\n",
    "    tree = ET.parse(file_name)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Find the media element\n",
    "    media = root.find('.//media')\n",
    "\n",
    "    # Append the provided code inside the media element\n",
    "    video = ET.SubElement(media, \"video\")\n",
    "\n",
    "    # Add the format element with nested samplecharacteristics element\n",
    "    format_ = ET.SubElement(video, \"format\")\n",
    "    samplecharacteristics = ET.SubElement(format_, \"samplecharacteristics\")\n",
    "    \n",
    "    # Add the rate element with nested timebase and ntsc elements inside samplecharacteristics\n",
    "    rate = ET.SubElement(samplecharacteristics, \"rate\")\n",
    "    timebase = ET.SubElement(rate, \"timebase\")\n",
    "    timebase.text = \"24\"\n",
    "    ntsc = ET.SubElement(rate, \"ntsc\")\n",
    "    ntsc.text = \"TRUE\"\n",
    "    \n",
    "    # Add the codec element with nested name and appspecificdata elements\n",
    "    codec = ET.SubElement(samplecharacteristics, \"codec\")\n",
    "    name = ET.SubElement(codec, \"name\")\n",
    "    name.text = \"Apple ProRes 422\"\n",
    "    appspecificdata = ET.SubElement(codec, \"appspecificdata\")\n",
    "    \n",
    "    # Add the appname, appmanufacturer, and appversion elements inside appspecificdata\n",
    "    appname = ET.SubElement(appspecificdata, \"appname\")\n",
    "    appname.text = \"Final Cut Pro\"\n",
    "    appmanufacturer = ET.SubElement(appspecificdata, \"appmanufacturer\")\n",
    "    appmanufacturer.text = \"Apple Inc.\"\n",
    "    appversion = ET.SubElement(appspecificdata, \"appversion\")\n",
    "    appversion.text = \"7.0\"\n",
    "    \n",
    "    # Add the data element with nested qtcodec element inside appspecificdata\n",
    "    data = ET.SubElement(appspecificdata, \"data\")\n",
    "    qtcodec = ET.SubElement(data, \"qtcodec\")\n",
    "    codecname = ET.SubElement(qtcodec, \"codecname\")\n",
    "    codecname.text = \"Apple ProRes 422\"\n",
    "    codectypename = ET.SubElement(qtcodec, \"codectypename\")\n",
    "    codectypename.text = \"Apple ProRes 422\"\n",
    "    codectypecode = ET.SubElement(qtcodec, \"codectypecode\")\n",
    "    codectypecode.text = \"apcn\"\n",
    "    codecvendorcode = ET.SubElement(qtcodec, \"codecvendorcode\")\n",
    "    codecvendorcode.text = \"appl\"\n",
    "    spatialquality = ET.SubElement(qtcodec, \"spatialquality\")\n",
    "    spatialquality.text = \"1024\"\n",
    "    temporalquality = ET.SubElement(qtcodec, \"temporalquality\")\n",
    "    temporalquality.text = \"0\"\n",
    "    keyframerate = ET.SubElement(qtcodec, \"keyframerate\")\n",
    "    keyframerate.text = \"0\"\n",
    "    datarate = ET.SubElement(qtcodec, \"datarate\")\n",
    "    datarate.text = \"0\"\n",
    "    \n",
    "    # Add the width, height, anamorphic, pixelaspectratio, fielddominance, and colordepth elements inside samplecharacteristics\n",
    "    width = ET.SubElement(samplecharacteristics, \"width\")\n",
    "    width.text = \"1920\"\n",
    "    height = ET.SubElement(samplecharacteristics, \"height\")\n",
    "    height.text = \"1080\"\n",
    "    anamorphic = ET.SubElement(samplecharacteristics, \"anamorphic\")\n",
    "    anamorphic.text = \"FALSE\"\n",
    "    pixelaspectratio = ET.SubElement(samplecharacteristics, \"pixelaspectratio\")\n",
    "    pixelaspectratio.text = \"square\"\n",
    "    fielddominance = ET.SubElement(samplecharacteristics, \"fielddominance\")\n",
    "    fielddominance.text = \"none\"\n",
    "    colordepth = ET.SubElement(samplecharacteristics, \"colordepth\")\n",
    "    colordepth.text = \"24\"\n",
    "    video_tracks = set()\n",
    "    # Get the track elements\n",
    "    for clip in xml_json_data:\n",
    "        track = clip[\"video_clips\"][0][\"track_index\"]\n",
    "        video_tracks.add(track)\n",
    "        print(track,\"track index\")\n",
    "    \n",
    "    # print(video_tracks)\n",
    "\n",
    "    # Create video track elements and append video clips\n",
    "    for video_track_index in video_tracks:\n",
    "        video_track = ET.SubElement(video, \"track\", TL_SQTrackShy=\"0\", TL_SQTrackExpandedHeight=\"25\",\n",
    "                                    TL_SQTrackExpanded=\"0\", MZ_TrackTargeted=f\"{video_track_index}\")\n",
    "        # video_track.set(\"trackindex\", str(video_track_index))\n",
    "\n",
    "        for clip in xml_json_data:\n",
    "            video_clip = clip[\"video_clips\"][0][\"video_clip_element\"]\n",
    "            if video_track_index == clip[\"video_clips\"][0][\"track_index\"]:\n",
    "                video_track.append(copy.deepcopy(video_clip))\n",
    "\n",
    "    final_track = ET.SubElement(video, \"track\", TL_SQTrackShy=\"0\", TL_SQTrackExpandedHeight=\"25\",\n",
    "                                TL_SQTrackExpanded=\"0\", MZ_TrackTargeted=\"0\")\n",
    "\n",
    "    # Add the enabled and locked elements\n",
    "    enabled = ET.SubElement(final_track, \"enabled\")\n",
    "    enabled.text = \"TRUE\"\n",
    "    locked = ET.SubElement(final_track, \"locked\")\n",
    "    locked.text = \"FALSE\"\n",
    "\n",
    "    # Save the modified XML to a new file\n",
    "    modified_tree = ET.ElementTree(root)\n",
    "    modified_tree.write(file_name)    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append Audio to XML File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def append_audio_to_xml(file_name, xml_json_data):\n",
    "    print(f\"Adding Audio Tracks to {file_name}\")\n",
    "    # Parse the XML data\n",
    "    audio_tracks = []\n",
    "    track_index=[]\n",
    "    source_index=[]\n",
    "    for clip in xml_json_data:\n",
    "\n",
    "        audio_track_indexes = [idx for idx in clip[\"video_clips\"][0][\"linked_audio_clip_elements_list\"]]\n",
    "        for audio_track_index in audio_track_indexes:\n",
    "            if audio_track_index['trackindex'] not in track_index:\n",
    "                track_index.append(audio_track_index['trackindex'])\n",
    "                source_index.append(audio_track_index['sourceindex'])\n",
    "                audio_tracks.append({'track_index':audio_track_index['trackindex'],'source_index':audio_track_index['sourceindex']})\n",
    "\n",
    "    audio_track_count=len(set(source_index))\n",
    "    # print('audio_tracks',audio_tracks)\n",
    "    # print('track_index',track_index)\n",
    "    # print('source_index',source_index)\n",
    "    # print('audio_track_count',audio_track_count)\n",
    "    \n",
    "    tree = ET.parse(file_name)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Find the media element\n",
    "    media = root.find('.//media')\n",
    "\n",
    "    # Add the audio element inside media\n",
    "    audio = ET.SubElement(media, \"audio\")\n",
    "\n",
    "    # constant stuff\n",
    "\n",
    "    # Create subelements and append them to the audio element\n",
    "    num_output_channels = ET.SubElement(audio, 'numOutputChannels')\n",
    "    num_output_channels.text = '2'\n",
    "\n",
    "    format_element = ET.SubElement(audio, 'format')\n",
    "    sample_characteristics = ET.SubElement(format_element, 'samplecharacteristics')\n",
    "    depth = ET.SubElement(sample_characteristics, 'depth')\n",
    "    depth.text = '16'\n",
    "    sample_rate = ET.SubElement(sample_characteristics, 'samplerate')\n",
    "    sample_rate.text = '48000'\n",
    "\n",
    "    outputs = ET.SubElement(audio, 'outputs')\n",
    "\n",
    "    group_1 = ET.SubElement(outputs, 'group')\n",
    "    index_1 = ET.SubElement(group_1, 'index')\n",
    "    index_1.text = '1'\n",
    "    num_channels_1 = ET.SubElement(group_1, 'numchannels')\n",
    "    num_channels_1.text = '1'\n",
    "    downmix_1 = ET.SubElement(group_1, 'downmix')\n",
    "    downmix_1.text = '0'\n",
    "    channel_1 = ET.SubElement(group_1, 'channel')\n",
    "    channel_index_1 = ET.SubElement(channel_1, 'index')\n",
    "    channel_index_1.text = '1'\n",
    "\n",
    "    group_2 = ET.SubElement(outputs, 'group')\n",
    "    index_2 = ET.SubElement(group_2, 'index')\n",
    "    index_2.text = '2'\n",
    "    num_channels_2 = ET.SubElement(group_2, 'numchannels')\n",
    "    num_channels_2.text = '1'\n",
    "    downmix_2 = ET.SubElement(group_2, 'downmix')\n",
    "    downmix_2.text = '0'\n",
    "    channel_2 = ET.SubElement(group_2, 'channel')\n",
    "    channel_index_2 = ET.SubElement(channel_2, 'index')\n",
    "    channel_index_2.text = '2'\n",
    "\n",
    "     # Create audio track elements and append audio clips\n",
    "    for audio_track_index in audio_tracks:\n",
    "        audio_track = ET.SubElement(audio, \"track\", TL_SQTrackAudioKeyframeStyle=\"0\", TL_SQTrackShy=\"0\",\n",
    "                                    TL_SQTrackExpandedHeight=\"25\", TL_SQTrackExpanded=\"0\",\n",
    "                                    MZ_TrackTargeted=\"1\", PannerCurrentValue=\"0.5\", PannerIsInverted=\"true\",\n",
    "                                    PannerStartKeyframe=\"-91445760000000000,0.5,0,0,0,0,0,0\", PannerName=\"Balance\",\n",
    "                                    currentExplodedTrackIndex=f\"{audio_track_index['source_index']-1}\", totalExplodedTrackCount=f\"{audio_track_count}\",\n",
    "                                    premiereTrackType=\"Stereo\")\n",
    "        # audio_track.set(\"trackindex\", str(audio_track_index))\n",
    "        for clip in xml_json_data:\n",
    "            audio_clip_elements = clip[\"video_clips\"][0][\"linked_audio_clip_elements_list\"]\n",
    "            \n",
    "            for audio_clip in audio_clip_elements:\n",
    "                # print(audio_clip,\"audio_clip\",audio_track_index['source_index'] == audio_clip['sourceindex'])\n",
    "                if audio_track_index['source_index'] == audio_clip['sourceindex']:\n",
    "                    audio_track.append(copy.deepcopy(audio_clip['audio_clip_item']))\n",
    "\n",
    "\n",
    "\n",
    "    # Save the modified XML to a new file\n",
    "    modified_tree = ET.ElementTree(root)\n",
    "    modified_tree.write(file_name)\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracts the given clips from the xml files and saves them in a seperate xml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the run_extraction() function serves as the main entry point for running the extraction process. \n",
    "# It calls functions to process a CSV file, filter the resulting list of clips, and create an XML file based on the filtered clips.\n",
    "\n",
    "def run_extraction(script_csv_file,exported_xml_project_name):\n",
    "    global final_clip_list    \n",
    "    process_csv_file(script_csv_file)\n",
    "    final_clip_list = [item for item in final_clip_list if item is not None]\n",
    "    print(final_clip_list)\n",
    "    filename = create_xml(exported_xml_project_name)\n",
    "    append_video_to_xml(f\"../xml exports/{filename}\", final_clip_list)\n",
    "    append_audio_to_xml(f\"../xml exports/{filename}\", final_clip_list)\n",
    "# print(final_clip_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code Run Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Time 00:00:00:00 End Time 00:00:30:00\n",
      "Narrator Name: fnite\n",
      "Assigning unique IDs to clipitem elements...\n",
      "{'clipitem-0b9646ea368440ebbbf754bbf2ac3508': 'clipitem-cb4954ac1d8e4b708d11a3ccc698701d', 'clipitem-e3ff0cebe8524534a0903eef49307cd6': 'clipitem-49c2f509c82f4143a59b46a0b6b43349', 'clipitem-65a261cae0934258b1ad0532e1383832': 'clipitem-c7158f39ff164e3785dc4caa2a49cc6a', 'clipitem-142143cd57c54dca9356c30707710345': 'clipitem-811c9377ded846c3813984b21bda156f', 'clipitem-c7087313ca9341e3908586a38f5fe094': 'clipitem-5332fd49fa46485a8a1de8b7fcb47458', 'clipitem-6641cba5cfde4d8ab5a798b2634e8f04': 'clipitem-d4019d43334247e19ac5303e6eeab3c2', 'clipitem-1af298924b0941de9fad26769fa6c5e3': 'clipitem-528b50001188489c851aea0a7042da6e', 'clipitem-6e961f57ef6544379b3e38d5864aaed3': 'clipitem-6bf0e66a07f34ebf80b6d8e94d6303b6', 'clipitem-6c62f25e52c943a780c5e0b55d370794': 'clipitem-323d99fdb8544099bef01d0d3a39a08d'}\n",
      "Track Index [1]\n",
      "Clip Frame Inside file Found:  True\n",
      "In - Matching - Out\n",
      "0 0 724\n",
      "Next Sequence Start 120\n",
      "Next Sequence End 840\n",
      "Track Index [1]\n",
      "Clip Frame Inside file Found:  False\n",
      "In - Matching - Out\n",
      "1448 0 2172\n",
      "Track Index [2]\n",
      "Clip Frame Inside file Found:  False\n",
      "In - Matching - Out\n",
      "724 0 1448\n",
      "Start Time 00:00:31:00 End Time 00:01:00:00\n",
      "Narrator Name: fnite\n",
      "Track Index [1]\n",
      "Clip Frame Inside file Found:  False\n",
      "In - Matching - Out\n",
      "0 744 724\n",
      "Track Index [1]\n",
      "Clip Frame Inside file Found:  False\n",
      "In - Matching - Out\n",
      "1448 744 2172\n",
      "Track Index [2]\n",
      "Clip Frame Inside file Found:  True\n",
      "In - Matching - Out\n",
      "724 744 1448\n",
      "Next Sequence Start 960\n",
      "Next Sequence End 1656\n",
      "Start Time 00:01:1:00 End Time 00:01:20:00\n",
      "Narrator Name: fnite\n",
      "Track Index [1]\n",
      "Clip Frame Inside file Found:  False\n",
      "In - Matching - Out\n",
      "0 1464 724\n",
      "Track Index [1]\n",
      "Clip Frame Inside file Found:  True\n",
      "In - Matching - Out\n",
      "1448 1464 2172\n",
      "Next Sequence Start 1776\n",
      "Next Sequence End 2232\n",
      "Track Index [2]\n",
      "Clip Frame Inside file Found:  False\n",
      "In - Matching - Out\n",
      "724 1464 1448\n",
      "[{'sequence_info': {'duration': 12031, 'rate': {'timebase': 24, 'ntsc': False}}, 'video_clips': [{'id': 'clipitem-cb4954ac1d8e4b708d11a3ccc698701d', 'name': 'Fortnite  NA PlayStation Cup  PlayStation Esports Game 1.mp4', 'duration': 7687, 'rate': {'timebase': 24, 'ntsc': False}, 'in': 0, 'out': 724, 'start': 758, 'end': 1482, 'track_index': 1, 'links': [{'linkclipref': 'clipitem-cb4954ac1d8e4b708d11a3ccc698701d', 'mediatype': 'video', 'trackindex': 1, 'clipindex': 1}, {'linkclipref': 'clipitem-811c9377ded846c3813984b21bda156f', 'mediatype': 'audio', 'trackindex': 1, 'clipindex': 1, 'groupindex': 1}, {'linkclipref': 'clipitem-d4019d43334247e19ac5303e6eeab3c2', 'mediatype': 'audio', 'trackindex': 2, 'clipindex': 1, 'groupindex': 1}], 'video_clip_element': <Element 'clipitem' at 0x00000243E2DE30B0>, 'linked_audio_clip_elements_list': [{'audio_clip_item': <Element 'clipitem' at 0x00000243E2C48770>, 'trackindex': 1, 'sourceindex': 1}, {'audio_clip_item': <Element 'clipitem' at 0x00000243E2DC0CC0>, 'trackindex': 2, 'sourceindex': 2}]}]}, {'sequence_info': {'duration': 12031, 'rate': {'timebase': 24, 'ntsc': False}}, 'video_clips': [{'id': 'clipitem-c7158f39ff164e3785dc4caa2a49cc6a', 'name': 'Fortnite  NA PlayStation Cup  PlayStation Esports Game 1.mp4', 'duration': 7687, 'rate': {'timebase': 24, 'ntsc': False}, 'in': 724, 'out': 1448, 'start': 5860, 'end': 6584, 'track_index': 2, 'links': [{'linkclipref': 'clipitem-c7158f39ff164e3785dc4caa2a49cc6a', 'mediatype': 'video', 'trackindex': 2, 'clipindex': 1}, {'linkclipref': 'clipitem-6bf0e66a07f34ebf80b6d8e94d6303b6', 'mediatype': 'audio', 'trackindex': 3, 'clipindex': 1, 'groupindex': 1}, {'linkclipref': 'clipitem-323d99fdb8544099bef01d0d3a39a08d', 'mediatype': 'audio', 'trackindex': 4, 'clipindex': 1, 'groupindex': 1}], 'video_clip_element': <Element 'clipitem' at 0x00000243E2DC01D0>, 'linked_audio_clip_elements_list': [{'audio_clip_item': <Element 'clipitem' at 0x00000243E2C214E0>, 'trackindex': 3, 'sourceindex': 1}, {'audio_clip_item': <Element 'clipitem' at 0x00000243E2C21760>, 'trackindex': 4, 'sourceindex': 2}]}]}, {'sequence_info': {'duration': 12031, 'rate': {'timebase': 24, 'ntsc': False}}, 'video_clips': [{'id': 'clipitem-49c2f509c82f4143a59b46a0b6b43349', 'name': 'Fortnite  NA PlayStation Cup  PlayStation Esports Game 1.mp4', 'duration': 7687, 'rate': {'timebase': 24, 'ntsc': False}, 'in': 1448, 'out': 2172, 'start': 11307, 'end': 12031, 'track_index': 1, 'links': [{'linkclipref': 'clipitem-49c2f509c82f4143a59b46a0b6b43349', 'mediatype': 'video', 'trackindex': 1, 'clipindex': 2}, {'linkclipref': 'clipitem-5332fd49fa46485a8a1de8b7fcb47458', 'mediatype': 'audio', 'trackindex': 1, 'clipindex': 2, 'groupindex': 1}, {'linkclipref': 'clipitem-528b50001188489c851aea0a7042da6e', 'mediatype': 'audio', 'trackindex': 2, 'clipindex': 2, 'groupindex': 1}], 'video_clip_element': <Element 'clipitem' at 0x00000243E2CBDA80>, 'linked_audio_clip_elements_list': [{'audio_clip_item': <Element 'clipitem' at 0x00000243E2CC60C0>, 'trackindex': 1, 'sourceindex': 1}, {'audio_clip_item': <Element 'clipitem' at 0x00000243E2D6DE90>, 'trackindex': 2, 'sourceindex': 2}]}]}]\n",
      "XML saved to testy-594.xml\n",
      "Adding Video Tracks to ../xml exports/testy-594.xml\n",
      "1 track index\n",
      "2 track index\n",
      "1 track index\n",
      "Adding Audio Tracks to ../xml exports/testy-594.xml\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "csv_folder_path = \"../Interview CSV\"\n",
    "\n",
    "script_path = \"../Script/test script.txt\"\n",
    "script_csv_output_path = \"../Script/test.csv\"\n",
    "\n",
    "final_subtitle_file = \"../Script/script.srt\"\n",
    "\n",
    "exported_xml_project_name= 'testy'\n",
    "\n",
    "\n",
    "#convert_txt_to_csv()\n",
    "\n",
    "# match_script_to_csv(script_path)\n",
    "\n",
    "# generate_subtitles(script_csv_output_path,final_subtitle_file)\n",
    "\n",
    "run_extraction(script_csv_output_path,exported_xml_project_name)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
