{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "import csv\n",
    "import xml.etree.ElementTree as ET\n",
    "import copy\n",
    "import random\n",
    "import uuid\n",
    "\n",
    "csv_folder_path = \"../Interview CSV\"\n",
    "\n",
    "script_path = \"../Script/test script.txt\"\n",
    "script_csv_output_path = \"../Script/script_export.csv\"\n",
    "\n",
    "final_subtitle_file = \"../Script/script.srt\"\n",
    "\n",
    "xml_folder = \"../Interview XML/\"\n",
    "exported_xml_project_name= 'testy'\n",
    "extract_method = 'project_timecode'  # video_timecode or project_timecode \n",
    "\n",
    "video_clip_list = []\n",
    "audio_clip_list = []\n",
    "id_mapping = {}\n",
    "# global sequence_start\n",
    "# global sequence_end\n",
    "\n",
    "sequence_start=0\n",
    "sequence_end=0\n",
    "audio_sequence_start=0\n",
    "audio_sequence_end=0\n",
    "xml_file_assigned=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Helper functions </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45194"
      ]
     },
     "execution_count": 601,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def timecode_to_frames(text):\n",
    "    if len(text.split(\":\"))==2:\n",
    "        frames=(int(text.split(\":\")[0])*60+int(text.split(\":\")[1]))*24\n",
    "    elif len(text.split(\":\"))==3:\n",
    "        frames=(int(text.split(\":\")[0])*3600+int(text.split(\":\")[1])*60+int(text.split(\":\")[2]))*24\n",
    "    elif len(text.split(\":\"))==4:\n",
    "        frames=(int(text.split(\":\")[0])*3600+int(text.split(\":\")[1])*60+int(text.split(\":\")[2]))*24+int(text.split(\":\")[3])\n",
    "    else:\n",
    "        print(text+\"timecode parse error\")\n",
    "    return frames\n",
    "\n",
    "timecode_to_frames(\"00:31:23:02\")  #test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def frames_to_timecode(frames):\n",
    "    frames=int(frames)\n",
    "    hours = frames // (3600*24)\n",
    "    remaining_frames = frames % (3600*24)\n",
    "    minutes=remaining_frames // (60*24)\n",
    "    remaining_frames=remaining_frames % (60*24)\n",
    "    seconds=remaining_frames // (24)\n",
    "    remaining_frames =remaining_frames %(24)\n",
    "    frames=remaining_frames\n",
    "\n",
    "\n",
    "\n",
    "    timecode=\"{:02d}\".format(hours)+\":\"+\"{:02d}\".format(minutes)+\":\"+\"{:02d}\".format(seconds)+\":\"+\"{:02d}\".format(frames)\n",
    "\n",
    "    return timecode\n",
    "\n",
    "#frames_to_timecode(45194)   #test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Remove special characters from the text\n",
    "    cleaned_text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    return cleaned_text\n",
    "\n",
    "#clean_text(\"abcd$$\")   #test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_line(line, narrator, df):\n",
    "    cleaned_line = clean_text(line.lower())  \n",
    "    matched_rows = []\n",
    "\n",
    "    #df=df[df[\"NARRATOR\"].str.lower()==narrator]\n",
    "#    print(df)\n",
    "\n",
    "    for index,row in df.iterrows():\n",
    "        text = clean_text(str(row['TEXT']).lower())\n",
    "        if cleaned_line in text:\n",
    "            matched_rows.append(row) \n",
    "    matched_rows_df = pd.concat(matched_rows, axis=1).transpose() if matched_rows else pd.DataFrame()\n",
    "    return matched_rows_df\n",
    "\n",
    "\n",
    "##add test here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 7)"
      ]
     },
     "execution_count": 605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_character_indices(full_string, substring):\n",
    "    full_list = list(full_string.lower())\n",
    "    sub_list = list(substring.lower())\n",
    "    length = len(sub_list)\n",
    "    \n",
    "    for i in range(len(full_list)):\n",
    "        if full_list[i:i+length] == sub_list:\n",
    "            return i, i+length\n",
    "    return None, None\n",
    "\n",
    "get_character_indices(\"abc def iopoi\",\"def\")   #test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Convert Script to coded CSV </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The match_script_to_csv() function performs a matching operation between a script file and a\n",
    "#  folder containing data from multiple CSV files\n",
    "# in order to generate a csv version of the script with links to files and timecodes\n",
    "\n",
    "def match_script_to_csv(script_path):\n",
    "\n",
    "    combined_df = pd.DataFrame()\n",
    "\n",
    "    for filename in os.listdir(csv_folder_path):\n",
    "        if filename.endswith(\"csv\"):\n",
    "            file_path = os.path.join(csv_folder_path, filename)\n",
    "            df = pd.read_csv(file_path)\n",
    "            df[\"NARRATOR\"]=(filename.split(\" \")[1])\n",
    "            df['FILEPATH'] = file_path\n",
    "            combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "\n",
    "    matched_rows = []\n",
    "\n",
    "    with open(script_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    narrator = None\n",
    "    for line in lines:\n",
    "        line=line.strip()\n",
    "        if line==\"\":\n",
    "            pass\n",
    "        elif line[:3]==\"###\":\n",
    "            narrator=line.strip()[3:]\n",
    "        else:\n",
    "            matched_rows_df = match_line(line, narrator, combined_df)\n",
    "            cleaned_line = clean_text(line)\n",
    "            if not matched_rows_df.empty:\n",
    "                for index,row in matched_rows_df.iterrows():\n",
    "                    print(row)\n",
    "                    time_range = [s.strip() for s in row['TIME'].split(\"-\")]\n",
    "                    start_time = timecode_to_frames(time_range[0])\n",
    "                    end_time = timecode_to_frames(time_range[1])\n",
    "                    total_duration = end_time - start_time\n",
    "\n",
    "                    text = clean_text(str(row['TEXT']).lower())\n",
    "\n",
    "                    ##if the row matches completely, the new and original start/end times should match\n",
    "\n",
    "                    print(text,cleaned_line)\n",
    "\n",
    "                    start_index, end_index = get_character_indices(text, cleaned_line)\n",
    "                    total_characters = len(list(text))\n",
    "\n",
    "                    print(start_time,total_duration,total_characters,start_index)\n",
    "\n",
    "                    new_start_time = start_time + total_duration/total_characters*start_index\n",
    "                    new_end_time = start_time + total_duration/total_characters*end_index\n",
    "\n",
    "                    new_row = {\n",
    "                        'Text': line,\n",
    "                        'Narrator': narrator,\n",
    "                        'Timecode Range': frames_to_timecode(new_start_time) +\" - \" + frames_to_timecode(new_end_time),\n",
    "                        'FilePath': row['FILEPATH']\n",
    "                        }\n",
    "            else:\n",
    "                ##if no match is found, the line is added anyway but with no timecode or filepath\n",
    "                new_row = {\n",
    "                        'Text': line,\n",
    "                        'Narrator': narrator,\n",
    "                        'Timecode Range': None,\n",
    "                        'FilePath': None\n",
    "                    }\n",
    "            matched_rows.append(new_row)\n",
    "\n",
    "    matched_df = pd.DataFrame.from_records(matched_rows)\n",
    "    return matched_df\n",
    "\n",
    "# match_script_to_csv(script_path).to_csv(script_csv_output_path) #test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Generate subtitles from coded script csv </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertTimecodeToSubFormat(timecode):\n",
    "    timecodeSplit=timecode.split(\":\")\n",
    "    timecodeSplit[3]=str(int(int(timecodeSplit[3])/24*1000))\n",
    "    timecodeNew = \":\".join(timecodeSplit[:3])+\",\"+timecodeSplit[3]\n",
    "    return timecodeNew\n",
    "\n",
    "#convertTimecodeToSubFormat(\"01:02:03:04\")   #test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "\n",
    "# the generate_subtitles() function reads a script CSV file, performs time calculations\n",
    "# and formatting, and writes the generated subtitles to a final subtitle file in the SRT format. if no time is found\n",
    "# it adds 5 seconds to the last time.\n",
    "\n",
    "def generate_subtitles(script_csv_file,final_subtitle_file):\n",
    "\n",
    "    with open(final_subtitle_file, 'w') as srt_file:\n",
    "        script_csv=pd.read_csv(script_csv_file)\n",
    "        counter = 1\n",
    "        last_time = 0\n",
    "        for index,row in script_csv.iterrows():\n",
    "            srt_file.write(str(counter) + '\\n')\n",
    "            \n",
    "            new_start_frames=last_time\n",
    "\n",
    "            if not pd.isna(row[\"Timecode Range\"]):  # If Timecode Range is not empty\n",
    "\n",
    "                start_time, end_time = [s.strip() for s in row[\"Timecode Range\"].split('-')]\n",
    "                start_frames=timecode_to_frames(start_time)\n",
    "                end_frames=timecode_to_frames(end_time)\n",
    "\n",
    "                new_end_frames= last_time+ end_frames - start_frames\n",
    "                last_time=new_end_frames\n",
    "\n",
    "            else:\n",
    "                new_end_frames = new_start_frames+120\n",
    "                last_time=new_end_frames\n",
    "\n",
    "            srt_file.write(convertTimecodeToSubFormat(frames_to_timecode(new_start_frames)) +' --> ' + convertTimecodeToSubFormat(frames_to_timecode(new_end_frames)) + '\\n')\n",
    "            \n",
    "            srt_file.write(clean_text(row[\"Text\"]) + '\\n\\n')  # Cleaned text\n",
    "            counter += 1\n",
    "\n",
    "generate_subtitles(script_csv_output_path,final_subtitle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converts Time to Frames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78662"
      ]
     },
     "execution_count": 609,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_time_to_frames(time, rate):\n",
    "    # print('Time', time, 'Rate', rate)\n",
    "    parts = time.split(\":\")\n",
    "    hours = int(parts[0])\n",
    "    minutes = int(parts[1])\n",
    "    seconds = int(parts[2])\n",
    "    frames = int(parts[3])\n",
    "    \n",
    "    # Calculate the total duration in frames\n",
    "    total_frames = (\n",
    "        hours * 3600 * rate +  # Convert hours to frames\n",
    "        minutes * 60 * rate +  # Convert minutes to frames\n",
    "        seconds * rate +  # Convert seconds to frames\n",
    "        frames\n",
    "    )\n",
    "    \n",
    "    return total_frames\n",
    "\n",
    "convert_time_to_frames('00:54:36:38', 24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate New ids for the each Clip item in seperate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'clipitem-82e783cb07e84de5afed92957f6e84b2'"
      ]
     },
     "execution_count": 610,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_unique_id():\n",
    "    unique_id = f\"clipitem-{uuid.uuid4().hex}\"\n",
    "    return unique_id\n",
    "\n",
    "generate_unique_id()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the id of clips in specific XML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_xml_ids(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    print('Assigning unique IDs to clipitem elements...')\n",
    "\n",
    "    # Generate unique IDs for clipitem elements\n",
    "      # Store the mapping of old IDs to new unique IDs\n",
    "    for clip_item in root.findall('.//clipitem'):  # Adjust the XPath expression based on the actual location of clipitem elements\n",
    "        current_id = clip_item.attrib['id']\n",
    "        unique_id = generate_unique_id()\n",
    "        id_mapping[current_id] = unique_id\n",
    "        clip_item.attrib['id'] = unique_id\n",
    "\n",
    "    \n",
    "        # Update the references in the links section\n",
    "    for link in root.findall('.//link'):\n",
    "        linkclipref = link.find('linkclipref')\n",
    "        if linkclipref is not None and linkclipref.text in id_mapping:\n",
    "            linkclipref.text = id_mapping[linkclipref.text]\n",
    "    print(id_mapping)\n",
    "\n",
    "    # Save the modified XML file\n",
    "    tree.write(xml_file, encoding=\"utf-8\")\n",
    "\n",
    "# update_xml_ids(xml_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract time in  start and end time format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Time 00:00:00:00 End Time 00:23:00:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('00:00:00:00', '00:23:00:00')"
      ]
     },
     "execution_count": 612,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_timecode(timecode_range):\n",
    "    start_time, end_time = timecode_range.split(\" - \")\n",
    "    start_time = start_time.strip().replace(\" \", \"\")\n",
    "    end_time = end_time.strip().replace(\" \", \"\")\n",
    "    print('Start Time',start_time,'End Time', end_time)\n",
    "    return start_time, end_time\n",
    "\n",
    "extract_timecode(\"00:00:00:00 - 00:23:00:00\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert frame to tick number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_to_ticks(frame_number, frame_rate):\n",
    "    total_ticks_in_a_second = 254016000000\n",
    "    tick_value = int((frame_number * total_ticks_in_a_second) / frame_rate)\n",
    "    return tick_value\n",
    "\n",
    "# frame_to_ticks(24, 24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract sequences through xml file and extract the clips that match with the start and end time using frame comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sequence_info(\n",
    "    xml_file, start_time, end_time, extract_method=\"project_timecode\"\n",
    "):\n",
    "    global sequence_start, sequence_end\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Extract sequence information\n",
    "    sequence = root.find(\"sequence\")\n",
    "    sequence_info = {\n",
    "        \"duration\": int(sequence.find(\"duration\").text),\n",
    "        \"rate\": {\n",
    "            \"timebase\": int(sequence.find(\"rate/timebase\").text),\n",
    "            \"ntsc\": sequence.find(\"rate/ntsc\").text == \"TRUE\",\n",
    "        },\n",
    "    }\n",
    "    sequence_rate = sequence_info[\"rate\"][\"timebase\"]\n",
    "\n",
    "    # Convert start and end times to frames\n",
    "    start_frame = convert_time_to_frames(start_time, 24)\n",
    "    end_frame = convert_time_to_frames(end_time, 24)\n",
    "    proTickIn = frame_to_ticks(start_frame, 24)\n",
    "    proTickOut = frame_to_ticks(end_frame, 24)\n",
    "\n",
    "    total_clip_frames = end_frame - start_frame\n",
    "    total_clip_proticks = proTickOut - proTickIn\n",
    "\n",
    "    # print('Start and End Frame',start_frame ,end_frame)\n",
    "    # print(sequence_rate,'sequence_rate')\n",
    "\n",
    "    # Extract video clip information\n",
    "    video_clips = []\n",
    "    for track_index, track in enumerate(root.findall(\".//video/track\")):  # Iterate over all tracks within the <video> tag\n",
    "        # track_idx = 0\n",
    "        track_targeted = track.attrib[\"MZ.TrackTargeted\"]\n",
    "        for clip_item in track.findall(\"clipitem\"):  # Only consider clip items within the <video> tag\n",
    "            \n",
    "            video_start_cut_diff=abs(start_frame - int(clip_item.find(\"start\").text))\n",
    "            video_end_cut_diff=abs(end_frame - int(clip_item.find(\"end\").text))\n",
    "            extracted_clip_duration=end_time-start_time\n",
    "            actual_clip_duration=int(clip_item.find(\"duration\").text)\n",
    "\n",
    "\n",
    "            links = clip_item.findall(\"link\")\n",
    "            track_idx = [\n",
    "                int(link.find(\"trackindex\").text)\n",
    "                for link in clip_item.findall(\"link\")\n",
    "                if link.find(\"mediatype\").text == \"video\"\n",
    "            ]\n",
    "            print(\"Track Index\", track_idx)\n",
    "            print(\"Clip ID\", clip_item.attrib[\"id\"])\n",
    "\n",
    "            clip_info = {\n",
    "                \"id\": clip_item.attrib[\"id\"],  # Get the clip ID\n",
    "                \"name\": clip_item.find(\"name\").text,\n",
    "                \"duration\": int(clip_item.find(\"duration\").text),\n",
    "                \"rate\": {\n",
    "                    \"timebase\": int(clip_item.find(\"rate/timebase\").text),\n",
    "                    \"ntsc\": clip_item.find(\"rate/ntsc\").text == \"TRUE\",\n",
    "                },\n",
    "                \"in\": int(clip_item.find(\"in\").text),\n",
    "                \"out\": int(clip_item.find(\"out\").text),\n",
    "                \"start\": int(clip_item.find(\"start\").text),\n",
    "                \"end\": int(clip_item.find(\"end\").text),\n",
    "                \"track_index\": track_index+1,\n",
    "                \"MZ_TrackTargeted\": track_targeted,\n",
    "                \"links\": [],  # Initialize an empty list to store links,\n",
    "                \"video_clip_element\": None,  # Store the clip item element for later use\n",
    "                \"linked_audio_clip_elements_list\": [],  # Initialize an empty list to store linked clip items\n",
    "            }\n",
    "\n",
    "            if extract_method == \"video_timecode\":\n",
    "                clip_comparison = (\n",
    "                    clip_info[\"in\"] <= start_frame <= clip_info[\"out\"]\n",
    "                ) or (clip_info[\"in\"] <= end_frame <= clip_info[\"out\"])\n",
    "            else:\n",
    "                clip_comparison = (\n",
    "                    clip_info[\"start\"] <= start_frame <= clip_info[\"end\"]\n",
    "                ) or (clip_info[\"start\"] <= end_frame <= clip_info[\"end\"])\n",
    "\n",
    "            \n",
    "\n",
    "            for link in links:\n",
    "                link_info = {\n",
    "                    \"linkclipref\": link.find(\"linkclipref\").text,\n",
    "                    \"mediatype\": link.find(\"mediatype\").text,\n",
    "                    \"trackindex\": int(link.find(\"trackindex\").text),\n",
    "                    \"clipindex\": int(link.find(\"clipindex\").text),\n",
    "                }\n",
    "                if link.find(\"groupindex\") is not None:\n",
    "                    link_info[\"groupindex\"] = int(link.find(\"groupindex\").text)\n",
    "                clip_info[\"links\"].append(link_info)\n",
    "                if link.find(\"mediatype\").text == \"audio\":\n",
    "                    audio_clip_items = root.findall(\".//audio//clipitem\")\n",
    "                    for audio_clip_item in audio_clip_items:\n",
    "                        if (\n",
    "                            audio_clip_item.attrib[\"id\"]\n",
    "                            == link.find(\"linkclipref\").text\n",
    "                        ):\n",
    "                            audio_clip_item.find(\"in\").text = str(start_frame)\n",
    "                            audio_clip_item.find(\"out\").text = str(end_frame)\n",
    "                              \n",
    "                            audio_clip_item.find(\"start\").text = str(sequence_start)\n",
    "                            audio_clip_item.find(\"end\").text = str(sequence_end)\n",
    "                            audio_clip_item.find(\"pproTicksIn\").text = str(proTickIn)\n",
    "                            audio_clip_item.find(\"pproTicksOut\").text = str(proTickOut)\n",
    "                                \n",
    "                            \n",
    "                            clip_info[\"linked_audio_clip_elements_list\"].append(\n",
    "                                {\n",
    "                                    \"audio_clip_item\": audio_clip_item,\n",
    "                                    \"trackindex\": int(link.find(\"trackindex\").text),\n",
    "                                    \"sourceindex\": int(\n",
    "                                        audio_clip_item.find(\n",
    "                                            \".//sourcetrack/trackindex\"\n",
    "                                        ).text\n",
    "                                    ),\n",
    "                                }\n",
    "                            )\n",
    "\n",
    "            # Check if the clip's in or out frame falls within the given start and end frames\n",
    "            # print('Clip Frame Inside file Found: ',clip_info['in'] <= start_frame <= clip_info['out'])\n",
    "            print(\n",
    "                \"Clip Frame Inside file Found: \",\n",
    "                clip_info[\"start\"] <= start_frame <= clip_info[\"end\"]\n",
    "                or clip_info[\"start\"] <= end_frame <= clip_info[\"end\"],\n",
    "            )\n",
    "            print(\"clip_comparison\", clip_comparison)\n",
    "            print(\"In - Matching - Out\")\n",
    "            # print(clip_info['in'],start_frame,clip_info['out'])\n",
    "            print(clip_info[\"start\"], start_frame, clip_info[\"end\"])\n",
    "            print(clip_info[\"start\"], end_frame, clip_info[\"end\"])\n",
    "            if clip_comparison:\n",
    "                clip_item.find(\"in\").text = str(start_frame)\n",
    "                clip_item.find(\"out\").text = (\n",
    "                    str(end_frame)\n",
    "                    if extract_method == \"video_timecode\"\n",
    "                    else str(start_frame + total_clip_frames)\n",
    "                )\n",
    "                clip_item.find(\"start\").text = str(sequence_start)\n",
    "                clip_item.find(\"end\").text = str(sequence_end)\n",
    "                clip_item.find(\"pproTicksIn\").text = str(proTickIn)\n",
    "                clip_item.find(\"pproTicksOut\").text = (\n",
    "                    str(proTickOut)\n",
    "                    if extract_method == \"video_timecode\"\n",
    "                    else str(proTickIn + total_clip_proticks)\n",
    "                )\n",
    "                clip_info[\"video_clip_element\"] = clip_item\n",
    "                video_clips.append(clip_info)\n",
    "                print(\"Next Sequence Start\", sequence_start)\n",
    "                print(\"Next Sequence End\", sequence_end)\n",
    "\n",
    "    # print(clip_info, start_frame, end_frame)\n",
    "\n",
    "    # Create result dictionary\n",
    "    result = { \"video_clips\": video_clips}\n",
    "    # print('Result',result)\n",
    "\n",
    "    if not video_clips:  # Check if video_clips list is empty\n",
    "        return None\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overlap Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap(segment1, segment2):\n",
    "    \"\"\"Check if two segments overlap and return the overlapped segment if they do\"\"\"\n",
    "    start1, end1 = segment1\n",
    "    start2, end2 = segment2\n",
    "    if start1 > end2 or start2 > end1:\n",
    "        # Segments do not overlap\n",
    "        return None\n",
    "    else:\n",
    "        # Segments overlap, return the overlapped segment\n",
    "        return max(start1, start2), min(end1, end2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract Video sequences from the xml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_video_sequence(xml_file, start_time, end_time):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    global sequence_start, sequence_end\n",
    "\n",
    "    # Convert start and end times to frames\n",
    "    start_frame = convert_time_to_frames(start_time, 24)\n",
    "    end_frame = convert_time_to_frames(end_time, 24)\n",
    "\n",
    "    # Extract video clip information\n",
    "    video_clips = []\n",
    "    for track_index, track in enumerate(root.findall(\".//video/track\")):  # Iterate over all tracks within the <video> tag\n",
    "        track_targeted = track.attrib[\"MZ.TrackTargeted\"]\n",
    "        for clip_item in track.findall(\"clipitem\"):  # Only consider clip items within the <video> tag\n",
    "            clip_info = {\n",
    "                \"id\": clip_item.attrib[\"id\"],  # Get the clip ID\n",
    "                \"new_id\": generate_unique_id(),  # Generate a new unique ID for the clip item\",\n",
    "                \"name\": clip_item.find(\"name\").text,\n",
    "                \"duration\": int(clip_item.find(\"duration\").text),\n",
    "                \"rate\": {\n",
    "                    \"timebase\": int(clip_item.find(\"rate/timebase\").text),\n",
    "                    \"ntsc\": clip_item.find(\"rate/ntsc\").text == \"TRUE\",\n",
    "                },\n",
    "                \"in\": int(clip_item.find(\"in\").text),\n",
    "                \"out\": int(clip_item.find(\"out\").text),\n",
    "                \"start\": int(clip_item.find(\"start\").text),\n",
    "                \"end\": int(clip_item.find(\"end\").text),\n",
    "                \"track_index\": track_index+1,\n",
    "                \"MZ_TrackTargeted\": track_targeted,\n",
    "                \"video_clip_element\": None,  # Store the clip item element for later use\n",
    "            }\n",
    "\n",
    "            # Check if the clip's in or out frame falls within the given start and end frames\n",
    "            if (\n",
    "                clip_info[\"start\"] <= start_frame <= clip_info[\"end\"]\n",
    "                or clip_info[\"start\"] <= end_frame <= clip_info[\"end\"]\n",
    "            ):\n",
    "                # Calculate the overlapped segment and the corresponding sequence segment\n",
    "                overlapped_segment = overlap((clip_info[\"start\"], clip_info[\"end\"]), (start_frame, end_frame))\n",
    "                if overlapped_segment is not None:\n",
    "                    overlap_start, overlap_end = overlapped_segment\n",
    "                    ratio_start = (overlap_start - clip_info[\"start\"]) / (clip_info[\"end\"] - clip_info[\"start\"])\n",
    "                    ratio_end = (overlap_end - clip_info[\"start\"]) / (clip_info[\"end\"] - clip_info[\"start\"])\n",
    "\n",
    "                    # Update the clip's in, out, start, and end in the XML tree based on the overlapped segment\n",
    "                    clip_item.find(\"in\").text = str(clip_info[\"in\"] + round(ratio_start * (clip_info[\"out\"] - clip_info[\"in\"])))\n",
    "                    clip_item.find(\"out\").text = str(clip_info[\"in\"] + round(ratio_end * (clip_info[\"out\"] - clip_info[\"in\"])))\n",
    "                    clip_item.find(\"start\").text = str(overlap_start)\n",
    "                    clip_item.find(\"end\").text = str(overlap_end)\n",
    "\n",
    "                    clip_info[\"video_clip_element\"] = clip_item\n",
    "                    video_clips.append(clip_info)\n",
    "\n",
    "    if not video_clips:  # Check if video_clips list is empty\n",
    "        return None\n",
    "\n",
    "    # Create result dictionary\n",
    "    result = {\"video_clips\": video_clips}\n",
    "    return result\n",
    "\n",
    "# Test the function with the given XML file and start/end times\n",
    "# extract_video_sequence('ben - synced.xml', '00:00:00:00', '00:00:10:00')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract Audio sequences from the xml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio_sequence(xml_file, start_time, end_time):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Convert start and end times to frames\n",
    "    start_frame = convert_time_to_frames(start_time, 24)\n",
    "    end_frame = convert_time_to_frames(end_time, 24)\n",
    "\n",
    "    # Extract video clip information\n",
    "    audio_clips = []\n",
    "    for track_index, track in enumerate(root.findall(\".//audio/track\")):  # Iterate over all tracks within the <video> tag\n",
    "        track_targeted = track.attrib[\"MZ.TrackTargeted\"]\n",
    "        currentExplodedTrackIndex = track.attrib[\"currentExplodedTrackIndex\"]\n",
    "        for clip_item in track.findall(\"clipitem\"):  # Only consider clip items within the <video> tag\n",
    "            clip_info = {\n",
    "                \"id\": clip_item.attrib[\"id\"],  # Get the clip ID\n",
    "                \"name\": clip_item.find(\"name\").text,\n",
    "                \"duration\": int(clip_item.find(\"duration\").text),\n",
    "                \"rate\": {\n",
    "                    \"timebase\": int(clip_item.find(\"rate/timebase\").text),\n",
    "                    \"ntsc\": clip_item.find(\"rate/ntsc\").text == \"TRUE\",\n",
    "                },\n",
    "                \"in\": int(clip_item.find(\"in\").text),\n",
    "                \"out\": int(clip_item.find(\"out\").text),\n",
    "                \"start\": int(clip_item.find(\"start\").text),\n",
    "                \"end\": int(clip_item.find(\"end\").text),\n",
    "                \"track_index\": track_index+1,\n",
    "                \"MZ_TrackTargeted\": track_targeted,\n",
    "                \"currentExplodedTrackIndex\": currentExplodedTrackIndex,\n",
    "                \"audio_clip_element\": None,  # Store the clip item element for later use\n",
    "                \"sourceindex\": int(clip_item.find(\".//sourcetrack/trackindex\").text),\n",
    "            }\n",
    "            \n",
    "\n",
    "            # Check if the clip's in or out frame falls within the given start and end frames\n",
    "            if (\n",
    "                clip_info[\"start\"] <= start_frame <= clip_info[\"end\"]\n",
    "                or clip_info[\"start\"] <= end_frame <= clip_info[\"end\"]\n",
    "            ):\n",
    "                # Calculate the overlapped segment and the corresponding sequence segment\n",
    "                overlapped_segment = overlap((clip_info[\"start\"], clip_info[\"end\"]), (start_frame, end_frame))\n",
    "                if overlapped_segment is not None:\n",
    "                    overlap_start, overlap_end = overlapped_segment\n",
    "                    ratio_start = (overlap_start - clip_info[\"start\"]) / (clip_info[\"end\"] - clip_info[\"start\"])\n",
    "                    ratio_end = (overlap_end - clip_info[\"start\"]) / (clip_info[\"end\"] - clip_info[\"start\"])\n",
    "\n",
    "                    # Update the clip's in, out, start, and end in the XML tree based on the overlapped segment\n",
    "                    clip_item.find(\"in\").text = str(clip_info[\"in\"] + round(ratio_start * (clip_info[\"out\"] - clip_info[\"in\"])))\n",
    "                    clip_item.find(\"out\").text = str(clip_info[\"in\"] + round(ratio_end * (clip_info[\"out\"] - clip_info[\"in\"])))\n",
    "                    clip_item.find(\"start\").text = str(overlap_start)\n",
    "                    clip_item.find(\"end\").text = str(overlap_end)\n",
    "\n",
    "\n",
    "                    clip_item.find(\"pproTicksIn\").text = str(frame_to_ticks(overlap_start, 24))\n",
    "                    clip_item.find(\"pproTicksOut\").text = str(frame_to_ticks(overlap_end, 24))\n",
    "\n",
    "\n",
    "                    clip_info[\"audio_clip_element\"] = clip_item\n",
    "                    audio_clips.append(clip_info)\n",
    "\n",
    "    if not audio_clips:  # Check if audio_clips list is empty\n",
    "        return None\n",
    "\n",
    "    # Create result dictionary\n",
    "    result = {\"audio_clips\": audio_clips}\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions go through all the xml files and call the  extract clips function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_xml_files(xml_folder, start_time, end_time, narrator_name):\n",
    "    global xml_file_assigned,video_clip_list,audio_clip_list, sequence_start, sequence_end, audio_sequence_start, audio_sequence_end\n",
    "    for filename in os.listdir(xml_folder):\n",
    "        if filename.endswith(\".xml\") and narrator_name.lower() in filename.lower():\n",
    "            # print(filename,narrator_name)\n",
    "            xml_file = os.path.join(xml_folder, filename)\n",
    "            if xml_file not in xml_file_assigned:\n",
    "                update_xml_ids(xml_file)\n",
    "                xml_file_assigned.append(xml_file)\n",
    "            video_clips = extract_video_sequence(xml_file, start_time, end_time)\n",
    "            if video_clips:\n",
    "                start_frame = convert_time_to_frames(start_time, 24)\n",
    "                end_frame = convert_time_to_frames(end_time, 24)\n",
    "                sequence_start = sequence_end + 120\n",
    "                sequence_end = sequence_start + (end_frame - start_frame)\n",
    "            video_clip_list.append(video_clips)\n",
    "            audio_clips = extract_audio_sequence(xml_file, start_time, end_time)\n",
    "            if audio_clips:\n",
    "                start_frame = convert_time_to_frames(start_time, 24)\n",
    "                end_frame = convert_time_to_frames(end_time, 24)\n",
    "                audio_sequence_start = sequence_end + 120\n",
    "                audio_sequence_end = sequence_start + (end_frame - start_frame)\n",
    "            audio_clip_list.append(audio_clips)\n",
    "\n",
    "\n",
    "\n",
    "def process_csv_file(csv_file):\n",
    "    xml_folder = \"../Interview XML/\"\n",
    "    with open(csv_file, \"r\") as file:\n",
    "        csv_reader = csv.DictReader(file)\n",
    "        for row in csv_reader:\n",
    "            timecode_range = row[\"Timecode Range\"]\n",
    "            if timecode_range:\n",
    "                start_time, end_time = extract_timecode(timecode_range)\n",
    "                narrator_name = row[\"Narrator\"]\n",
    "                line = row[\"Text\"]\n",
    "                # print('Narrator Name:' ,narrator_name)\n",
    "                # print('Line:', line)\n",
    "                process_xml_files(xml_folder, start_time, end_time, narrator_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Create Basic XML Structure </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_xml(xml_name):\n",
    "    \n",
    "    # Create the root element\n",
    "    root = ET.Element(\"xmeml\", version=\"4\")\n",
    "    \n",
    "    # Create the sequence element with attributes\n",
    "    sequence = ET.SubElement(root, \"sequence\", id=\"sequence-2\", TL_SQAudioVisibleBase=\"0\", TL_SQVideoVisibleBase=\"0\",\n",
    "                             TL_SQVisibleBaseTime=\"0\", TL_SQAVDividerPosition=\"0.5\", TL_SQHideShyTracks=\"0\",\n",
    "                             TL_SQHeaderWidth=\"236\", TL_SQDataTrackViewControlState=\"0\",\n",
    "                             Monitor_ProgramZoomOut=\"340011984312000\", Monitor_ProgramZoomIn=\"0\",\n",
    "                             TL_SQTimePerPixel=\"1.6034289012958367\", MZ_EditLine=\"333083126376000\",\n",
    "                             MZ_Sequence_PreviewFrameSizeHeight=\"1080\", MZ_Sequence_PreviewFrameSizeWidth=\"1920\",\n",
    "                             MZ_Sequence_AudioTimeDisplayFormat=\"200\", MZ_Sequence_PreviewUseMaxRenderQuality=\"false\",\n",
    "                             MZ_Sequence_PreviewUseMaxBitDepth=\"false\", MZ_Sequence_VideoTimeDisplayFormat=\"110\",\n",
    "                             MZ_WorkOutPoint=\"15235011792000\", MZ_WorkInPoint=\"0\", MZ_ZeroPoint=\"0\", explodedTracks=\"true\")\n",
    "    \n",
    "    # Add the uuid element\n",
    "    uuid = ET.SubElement(sequence, \"uuid\")\n",
    "    uuid.text = \"50e61931-251f-4069-8193-a3fbad7f93ff\"\n",
    "    \n",
    "    # Add the duration element\n",
    "    duration = ET.SubElement(sequence, \"duration\")\n",
    "    duration.text = \"31533\"\n",
    "    \n",
    "    # Add the rate element with nested timebase and ntsc elements\n",
    "    rate = ET.SubElement(sequence, \"rate\")\n",
    "    timebase = ET.SubElement(rate, \"timebase\")\n",
    "    timebase.text = \"24\"\n",
    "    ntsc = ET.SubElement(rate, \"ntsc\")\n",
    "    ntsc.text = \"TRUE\"\n",
    "    \n",
    "    # Add the name element\n",
    "    name_element = ET.SubElement(sequence, \"name\")\n",
    "    name_element.text = xml_name\n",
    "    \n",
    "    # Add the media element with nested video and audio elements\n",
    "    media = ET.SubElement(sequence, \"media\")\n",
    "\n",
    "    \n",
    " \n",
    "    \n",
    "    # Add the timecode element with nested rate, string, frame, and displayformat elements\n",
    "    timecode = ET.SubElement(sequence, \"timecode\")\n",
    "    rate = ET.SubElement(timecode, \"rate\")\n",
    "    timebase = ET.SubElement(rate, \"timebase\")\n",
    "    timebase.text = \"24\"\n",
    "    ntsc = ET.SubElement(rate, \"ntsc\")\n",
    "    ntsc.text = \"TRUE\"\n",
    "    string = ET.SubElement(timecode, \"string\")\n",
    "    string.text = \"00:00:00:00\"\n",
    "    frame = ET.SubElement(timecode, \"frame\")\n",
    "    frame.text = \"0\"\n",
    "    displayformat = ET.SubElement(timecode, \"displayformat\")\n",
    "    displayformat.text = \"NDF\"\n",
    "    \n",
    "    # Add the labels element with nested label2 element\n",
    "    labels = ET.SubElement(sequence, \"labels\")\n",
    "    label2 = ET.SubElement(labels, \"label2\")\n",
    "    label2.text = \"Forest\"\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    # Create the ElementTree object with the root element\n",
    "    tree = ET.ElementTree(root)\n",
    "    \n",
    "    # Generate a random Idd\n",
    "    idd = str(random.randint(1, 1000))\n",
    "    \n",
    "    # Save the XML to a file\n",
    "    filename = f\"{xml_name.replace(' ', '_')}-{idd}.xml\"\n",
    "    tree.write(f\"../xml exports/{filename}\", encoding=\"utf-8\", xml_declaration=True)\n",
    "    print(f\"XML saved to {filename}\")\n",
    "\n",
    "    return filename \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append Video to XML File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_video_to_xml(file_name, xml_json_data):\n",
    "    print(f\"Adding Video Tracks to {file_name}\")\n",
    "    # print(xml_json_data)\n",
    "    # Parse the XML data\n",
    "    tree = ET.parse(file_name)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Find the media element\n",
    "    media = root.find('.//media')\n",
    "\n",
    "    # Append the provided code inside the media element\n",
    "    video = ET.SubElement(media, \"video\")\n",
    "\n",
    "    # Add the format element with nested samplecharacteristics element\n",
    "    format_ = ET.SubElement(video, \"format\")\n",
    "    samplecharacteristics = ET.SubElement(format_, \"samplecharacteristics\")\n",
    "    \n",
    "    # Add the rate element with nested timebase and ntsc elements inside samplecharacteristics\n",
    "    rate = ET.SubElement(samplecharacteristics, \"rate\")\n",
    "    timebase = ET.SubElement(rate, \"timebase\")\n",
    "    timebase.text = \"24\"\n",
    "    ntsc = ET.SubElement(rate, \"ntsc\")\n",
    "    ntsc.text = \"TRUE\"\n",
    "    \n",
    "    # Add the codec element with nested name and appspecificdata elements\n",
    "    codec = ET.SubElement(samplecharacteristics, \"codec\")\n",
    "    name = ET.SubElement(codec, \"name\")\n",
    "    name.text = \"Apple ProRes 422\"\n",
    "    appspecificdata = ET.SubElement(codec, \"appspecificdata\")\n",
    "    \n",
    "    # Add the appname, appmanufacturer, and appversion elements inside appspecificdata\n",
    "    appname = ET.SubElement(appspecificdata, \"appname\")\n",
    "    appname.text = \"Final Cut Pro\"\n",
    "    appmanufacturer = ET.SubElement(appspecificdata, \"appmanufacturer\")\n",
    "    appmanufacturer.text = \"Apple Inc.\"\n",
    "    appversion = ET.SubElement(appspecificdata, \"appversion\")\n",
    "    appversion.text = \"7.0\"\n",
    "    \n",
    "    # Add the data element with nested qtcodec element inside appspecificdata\n",
    "    data = ET.SubElement(appspecificdata, \"data\")\n",
    "    qtcodec = ET.SubElement(data, \"qtcodec\")\n",
    "    codecname = ET.SubElement(qtcodec, \"codecname\")\n",
    "    codecname.text = \"Apple ProRes 422\"\n",
    "    codectypename = ET.SubElement(qtcodec, \"codectypename\")\n",
    "    codectypename.text = \"Apple ProRes 422\"\n",
    "    codectypecode = ET.SubElement(qtcodec, \"codectypecode\")\n",
    "    codectypecode.text = \"apcn\"\n",
    "    codecvendorcode = ET.SubElement(qtcodec, \"codecvendorcode\")\n",
    "    codecvendorcode.text = \"appl\"\n",
    "    spatialquality = ET.SubElement(qtcodec, \"spatialquality\")\n",
    "    spatialquality.text = \"1024\"\n",
    "    temporalquality = ET.SubElement(qtcodec, \"temporalquality\")\n",
    "    temporalquality.text = \"0\"\n",
    "    keyframerate = ET.SubElement(qtcodec, \"keyframerate\")\n",
    "    keyframerate.text = \"0\"\n",
    "    datarate = ET.SubElement(qtcodec, \"datarate\")\n",
    "    datarate.text = \"0\"\n",
    "    \n",
    "    # Add the width, height, anamorphic, pixelaspectratio, fielddominance, and colordepth elements inside samplecharacteristics\n",
    "    width = ET.SubElement(samplecharacteristics, \"width\")\n",
    "    width.text = \"1920\"\n",
    "    height = ET.SubElement(samplecharacteristics, \"height\")\n",
    "    height.text = \"1080\"\n",
    "    anamorphic = ET.SubElement(samplecharacteristics, \"anamorphic\")\n",
    "    anamorphic.text = \"FALSE\"\n",
    "    pixelaspectratio = ET.SubElement(samplecharacteristics, \"pixelaspectratio\")\n",
    "    pixelaspectratio.text = \"square\"\n",
    "    fielddominance = ET.SubElement(samplecharacteristics, \"fielddominance\")\n",
    "    fielddominance.text = \"none\"\n",
    "    colordepth = ET.SubElement(samplecharacteristics, \"colordepth\")\n",
    "    colordepth.text = \"24\"\n",
    "    video_tracks = []\n",
    "    # Get the track elements\n",
    "    for clip in xml_json_data:\n",
    "        for video_clip in clip[\"video_clips\"]:\n",
    "            if video_clip[\"track_index\"] not in video_tracks:\n",
    "                video_tracks.append({'MZ_TrackTargeted':video_clip[\"MZ_TrackTargeted\"],'track_index':video_clip[\"track_index\"]})\n",
    "\n",
    "    \n",
    "    # print(video_tracks,\"total video tracks\")\n",
    "    appended_video_clip=[]\n",
    "    \n",
    "    # Make video_tracks unique based on track_index\n",
    "    # video_tracks = [dict(t) for t in {tuple(d.items()) for d in video_tracks}]\n",
    "    \n",
    "\n",
    "\n",
    "    # Create video track elements and append video clips\n",
    "    print(video_tracks,\"total video tracks\")\n",
    "    for track in video_tracks:\n",
    "        video_track = ET.SubElement(video, \"track\", TL_SQTrackShy=\"0\", TL_SQTrackExpandedHeight=\"25\",\n",
    "                                    TL_SQTrackExpanded=\"0\", MZ_TrackTargeted=f\"{track['MZ_TrackTargeted']}\")\n",
    "        for clip in xml_json_data:\n",
    "            for video_clip in clip[\"video_clips\"]:\n",
    "                if int(track['track_index']) == int(video_clip[\"track_index\"]) and video_clip[\"new_id\"] not in appended_video_clip:\n",
    "                    video_track.append(copy.deepcopy(video_clip[\"video_clip_element\"]))\n",
    "                    appended_video_clip.append(video_clip[\"new_id\"])\n",
    "\n",
    "\n",
    "    # Save the modified XML to a new file\n",
    "    modified_tree = ET.ElementTree(root)\n",
    "    modified_tree.write(file_name)    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append Audio to XML File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def append_audio_to_xml(file_name, xml_json_data):\n",
    "    print(f\"Adding Audio Tracks to {file_name}\")\n",
    "    # Parse the XML data\n",
    "    audio_tracks = []\n",
    "    track_index = []\n",
    "    source_index = []\n",
    "    for clip in xml_json_data:\n",
    "        for audio_clip in clip[\"audio_clips\"]:\n",
    "            if audio_clip['currentExplodedTrackIndex'] not in track_index:\n",
    "                track_index.append(audio_clip['currentExplodedTrackIndex'])\n",
    "                source_index.append(audio_clip['sourceindex'])\n",
    "                audio_tracks.append({'source_index': audio_clip['sourceindex'],\n",
    "                                     'MZ_TrackTargeted': audio_clip['MZ_TrackTargeted'],\n",
    "                                     'currentExplodedTrackIndex':audio_clip['currentExplodedTrackIndex']})\n",
    "\n",
    "    audio_track_count = len(set(source_index))\n",
    "\n",
    "    # print('audio_tracks',audio_tracks)\n",
    "    # print('track_index',track_index)\n",
    "    # print('source_index',source_index)\n",
    "    # print('audio_track_count',audio_track_count)\n",
    "    \n",
    "    tree = ET.parse(file_name)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Find the media element\n",
    "    media = root.find('.//media')\n",
    "\n",
    "    # Add the audio element inside media\n",
    "    audio = ET.SubElement(media, \"audio\")\n",
    "\n",
    "    # constant stuff\n",
    "\n",
    "    # Create subelements and append them to the audio element\n",
    "    num_output_channels = ET.SubElement(audio, 'numOutputChannels')\n",
    "    num_output_channels.text = '2'\n",
    "\n",
    "    format_element = ET.SubElement(audio, 'format')\n",
    "    sample_characteristics = ET.SubElement(format_element, 'samplecharacteristics')\n",
    "    depth = ET.SubElement(sample_characteristics, 'depth')\n",
    "    depth.text = '16'\n",
    "    sample_rate = ET.SubElement(sample_characteristics, 'samplerate')\n",
    "    sample_rate.text = '48000'\n",
    "\n",
    "    outputs = ET.SubElement(audio, 'outputs')\n",
    "\n",
    "    group_1 = ET.SubElement(outputs, 'group')\n",
    "    index_1 = ET.SubElement(group_1, 'index')\n",
    "    index_1.text = '1'\n",
    "    num_channels_1 = ET.SubElement(group_1, 'numchannels')\n",
    "    num_channels_1.text = '1'\n",
    "    downmix_1 = ET.SubElement(group_1, 'downmix')\n",
    "    downmix_1.text = '0'\n",
    "    channel_1 = ET.SubElement(group_1, 'channel')\n",
    "    channel_index_1 = ET.SubElement(channel_1, 'index')\n",
    "    channel_index_1.text = '1'\n",
    "\n",
    "    group_2 = ET.SubElement(outputs, 'group')\n",
    "    index_2 = ET.SubElement(group_2, 'index')\n",
    "    index_2.text = '2'\n",
    "    num_channels_2 = ET.SubElement(group_2, 'numchannels')\n",
    "    num_channels_2.text = '1'\n",
    "    downmix_2 = ET.SubElement(group_2, 'downmix')\n",
    "    downmix_2.text = '0'\n",
    "    channel_2 = ET.SubElement(group_2, 'channel')\n",
    "    channel_index_2 = ET.SubElement(channel_2, 'index')\n",
    "    channel_index_2.text = '2'\n",
    "\n",
    "    appended_video_clip=[]\n",
    "\n",
    "     # Create audio track elements and append audio clips\n",
    "    for audio_track_index in audio_tracks:\n",
    "        audio_track = ET.SubElement(audio, \"track\", TL_SQTrackAudioKeyframeStyle=\"0\", TL_SQTrackShy=\"0\",\n",
    "                                    TL_SQTrackExpandedHeight=\"25\", TL_SQTrackExpanded=\"0\",\n",
    "                                    MZ_TrackTargeted=f\"{audio_track_index['MZ_TrackTargeted']}\", PannerCurrentValue=\"0.5\", PannerIsInverted=\"true\",\n",
    "                                    PannerStartKeyframe=\"-91445760000000000,0.5,0,0,0,0,0,0\", PannerName=\"Balance\",\n",
    "                                    currentExplodedTrackIndex=f\"{audio_track_index['currentExplodedTrackIndex']}\", totalExplodedTrackCount=f\"{audio_track_count}\",\n",
    "                                    premiereTrackType=\"Stereo\")\n",
    "\n",
    "        for clip in xml_json_data:\n",
    "            for audio_clip in clip[\"audio_clips\"]:\n",
    "                if int(audio_track_index['currentExplodedTrackIndex']) == int(audio_clip[\"currentExplodedTrackIndex\"]):\n",
    "                    audio_track.append(copy.deepcopy(audio_clip[\"audio_clip_element\"]))\n",
    "                    appended_video_clip.append(audio_clip[\"id\"])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Save the modified XML to a new file\n",
    "    modified_tree = ET.ElementTree(root)\n",
    "    modified_tree.write(file_name)\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracts the given clips from the xml files and saves them in a seperate xml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the run_extraction() function serves as the main entry point for running the extraction process. \n",
    "# It calls functions to process a CSV file, filter the resulting list of clips, and create an XML file based on the filtered clips.\n",
    "\n",
    "def run_extraction(script_csv_file,exported_xml_project_name):\n",
    "    global video_clip_list,audio_clip_list     \n",
    "    process_csv_file(script_csv_file)\n",
    "    video_clip_list = [item for item in video_clip_list if item is not None]\n",
    "    audio_clip_list = [item for item in audio_clip_list if item is not None]\n",
    "    print(video_clip_list)\n",
    "    filename = create_xml(exported_xml_project_name)\n",
    "    append_video_to_xml(f\"../xml exports/{filename}\", video_clip_list)\n",
    "    append_audio_to_xml(f\"../xml exports/{filename}\", audio_clip_list)\n",
    "# print(video_clip_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code Run Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Time 00:00:11:00 End Time 00:00:18:7\n",
      "Assigning unique IDs to clipitem elements...\n",
      "{'clipitem-55f161fb9de449abad842d4d38ff56ff': 'clipitem-1e0aed9ac0624b95b5272036c4e6082f', 'clipitem-68519c92dde34c34a48f2cddbfde2068': 'clipitem-c7a5e674dbd6473f86e36325bc033ea3', 'clipitem-644b231578f64c7d98fad1dd6180fc4e': 'clipitem-c970a642b2444b019eda0c62949bf7ff', 'clipitem-7966524171af4841816dc0f4a6c5923d': 'clipitem-f746fb4b15554e0aa945a283e994f19a', 'clipitem-7a0ba03c257242c985fda5daeb3a17dd': 'clipitem-5da5d9d5700b40fe8c8f6caa0411e8aa'}\n",
      "Start Time 00:00:25:00 End Time 00:00:32:00\n",
      "[{'video_clips': [{'id': 'clipitem-1e0aed9ac0624b95b5272036c4e6082f', 'new_id': 'clipitem-76bfaf080a7c4febbb8c8cb975e5f484', 'name': 'Camera_Recording_-_Jul_23 (6).mp4', 'duration': 872, 'rate': {'timebase': 24, 'ntsc': False}, 'in': 0, 'out': 872, 'start': 2, 'end': 874, 'track_index': 1, 'MZ_TrackTargeted': '1', 'video_clip_element': <Element 'clipitem' at 0x0000028FCFDD9BC0>}, {'id': 'clipitem-c7a5e674dbd6473f86e36325bc033ea3', 'new_id': 'clipitem-b4f5aa2fa64041d2bcc36ddd25de96ec', 'name': '20230723_123914.mp4', 'duration': 175, 'rate': {'timebase': 24, 'ntsc': False}, 'in': 0, 'out': 175, 'start': 266, 'end': 441, 'track_index': 2, 'MZ_TrackTargeted': '0', 'video_clip_element': <Element 'clipitem' at 0x0000028FCFDD9EE0>}]}, {'video_clips': [{'id': 'clipitem-1e0aed9ac0624b95b5272036c4e6082f', 'new_id': 'clipitem-eb0ee6de72034621a7ce9336770d805c', 'name': 'Camera_Recording_-_Jul_23 (6).mp4', 'duration': 872, 'rate': {'timebase': 24, 'ntsc': False}, 'in': 0, 'out': 872, 'start': 2, 'end': 874, 'track_index': 1, 'MZ_TrackTargeted': '1', 'video_clip_element': <Element 'clipitem' at 0x0000028FCF85CC20>}, {'id': 'clipitem-c970a642b2444b019eda0c62949bf7ff', 'new_id': 'clipitem-f9a10b2ca3c841bfa222dbcb9d986938', 'name': '20230723_123929.mp4', 'duration': 158, 'rate': {'timebase': 24, 'ntsc': False}, 'in': 0, 'out': 158, 'start': 614, 'end': 772, 'track_index': 2, 'MZ_TrackTargeted': '0', 'video_clip_element': <Element 'clipitem' at 0x0000028FB74527F0>}]}]\n",
      "XML saved to testy-323.xml\n",
      "Adding Video Tracks to ../xml exports/testy-323.xml\n",
      "[{'MZ_TrackTargeted': '1', 'track_index': 1}, {'MZ_TrackTargeted': '0', 'track_index': 2}, {'MZ_TrackTargeted': '1', 'track_index': 1}, {'MZ_TrackTargeted': '0', 'track_index': 2}] total video tracks\n",
      "Adding Audio Tracks to ../xml exports/testy-323.xml\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "csv_folder_path = \"../Interview CSV\"\n",
    "\n",
    "script_path = \"../Script/test script.txt\"\n",
    "script_csv_output_path = \"../Script/test.csv\"\n",
    "\n",
    "final_subtitle_file = \"../Script/script.srt\"\n",
    "\n",
    "exported_xml_project_name= 'testy'\n",
    "\n",
    "\n",
    "#convert_txt_to_csv()\n",
    "\n",
    "# match_script_to_csv(script_path)\n",
    "\n",
    "# generate_subtitles(script_csv_output_path,final_subtitle_file)\n",
    "\n",
    "run_extraction(script_csv_output_path,exported_xml_project_name)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
