{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "import csv\n",
    "import xml.etree.ElementTree as ET\n",
    "import copy\n",
    "import random\n",
    "import uuid\n",
    "\n",
    "csv_folder_path = \"../Interview CSV\"\n",
    "\n",
    "script_path = \"../Script/test script.txt\"\n",
    "script_csv_output_path = \"../Script/script_export.csv\"\n",
    "\n",
    "final_subtitle_file = \"../Script/script.srt\"\n",
    "\n",
    "xml_folder = \"../Interview XML/\"\n",
    "exported_xml_project_name= 'testy'\n",
    "extract_method = 'project_timecode'  # video_timecode or project_timecode \n",
    "\n",
    "final_clip_list = []\n",
    "id_mapping = {}\n",
    "# global sequence_start\n",
    "# global sequence_end\n",
    "\n",
    "sequence_start=0\n",
    "sequence_end=0\n",
    "xml_file_assigned=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Helper functions </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45194"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def timecode_to_frames(text):\n",
    "    if len(text.split(\":\"))==2:\n",
    "        frames=(int(text.split(\":\")[0])*60+int(text.split(\":\")[1]))*24\n",
    "    elif len(text.split(\":\"))==3:\n",
    "        frames=(int(text.split(\":\")[0])*3600+int(text.split(\":\")[1])*60+int(text.split(\":\")[2]))*24\n",
    "    elif len(text.split(\":\"))==4:\n",
    "        frames=(int(text.split(\":\")[0])*3600+int(text.split(\":\")[1])*60+int(text.split(\":\")[2]))*24+int(text.split(\":\")[3])\n",
    "    else:\n",
    "        print(text+\"timecode parse error\")\n",
    "    return frames\n",
    "\n",
    "timecode_to_frames(\"00:31:23:02\")  #test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def frames_to_timecode(frames):\n",
    "    frames=int(frames)\n",
    "    hours = frames // (3600*24)\n",
    "    remaining_frames = frames % (3600*24)\n",
    "    minutes=remaining_frames // (60*24)\n",
    "    remaining_frames=remaining_frames % (60*24)\n",
    "    seconds=remaining_frames // (24)\n",
    "    remaining_frames =remaining_frames %(24)\n",
    "    frames=remaining_frames\n",
    "\n",
    "\n",
    "\n",
    "    timecode=\"{:02d}\".format(hours)+\":\"+\"{:02d}\".format(minutes)+\":\"+\"{:02d}\".format(seconds)+\":\"+\"{:02d}\".format(frames)\n",
    "\n",
    "    return timecode\n",
    "\n",
    "#frames_to_timecode(45194)   #test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Remove special characters from the text\n",
    "    cleaned_text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    return cleaned_text\n",
    "\n",
    "#clean_text(\"abcd$$\")   #test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_line(line, narrator, df):\n",
    "    cleaned_line = clean_text(line.lower())  \n",
    "    matched_rows = []\n",
    "\n",
    "    #df=df[df[\"NARRATOR\"].str.lower()==narrator]\n",
    "#    print(df)\n",
    "\n",
    "    for index,row in df.iterrows():\n",
    "        text = clean_text(str(row['TEXT']).lower())\n",
    "        if cleaned_line in text:\n",
    "            matched_rows.append(row) \n",
    "    matched_rows_df = pd.concat(matched_rows, axis=1).transpose() if matched_rows else pd.DataFrame()\n",
    "    return matched_rows_df\n",
    "\n",
    "\n",
    "##add test here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_character_indices(full_string, substring):\n",
    "    full_list = list(full_string.lower())\n",
    "    sub_list = list(substring.lower())\n",
    "    length = len(sub_list)\n",
    "    \n",
    "    for i in range(len(full_list)):\n",
    "        if full_list[i:i+length] == sub_list:\n",
    "            return i, i+length\n",
    "    return None, None\n",
    "\n",
    "get_character_indices(\"abc def iopoi\",\"def\")   #test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Convert Script to coded CSV </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The match_script_to_csv() function performs a matching operation between a script file and a\n",
    "#  folder containing data from multiple CSV files\n",
    "# in order to generate a csv version of the script with links to files and timecodes\n",
    "\n",
    "def match_script_to_csv(script_path):\n",
    "\n",
    "    combined_df = pd.DataFrame()\n",
    "\n",
    "    for filename in os.listdir(csv_folder_path):\n",
    "        if filename.endswith(\"csv\"):\n",
    "            file_path = os.path.join(csv_folder_path, filename)\n",
    "            df = pd.read_csv(file_path)\n",
    "            df[\"NARRATOR\"]=(filename.split(\" \")[1])\n",
    "            df['FILEPATH'] = file_path\n",
    "            combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "\n",
    "    matched_rows = []\n",
    "\n",
    "    with open(script_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    narrator = None\n",
    "    for line in lines:\n",
    "        line=line.strip()\n",
    "        if line==\"\":\n",
    "            pass\n",
    "        elif line[:3]==\"###\":\n",
    "            narrator=line.strip()[3:]\n",
    "        else:\n",
    "            matched_rows_df = match_line(line, narrator, combined_df)\n",
    "            cleaned_line = clean_text(line)\n",
    "            if not matched_rows_df.empty:\n",
    "                for index,row in matched_rows_df.iterrows():\n",
    "                    print(row)\n",
    "                    time_range = [s.strip() for s in row['TIME'].split(\"-\")]\n",
    "                    start_time = timecode_to_frames(time_range[0])\n",
    "                    end_time = timecode_to_frames(time_range[1])\n",
    "                    total_duration = end_time - start_time\n",
    "\n",
    "                    text = clean_text(str(row['TEXT']).lower())\n",
    "\n",
    "                    ##if the row matches completely, the new and original start/end times should match\n",
    "\n",
    "                    print(text,cleaned_line)\n",
    "\n",
    "                    start_index, end_index = get_character_indices(text, cleaned_line)\n",
    "                    total_characters = len(list(text))\n",
    "\n",
    "                    print(start_time,total_duration,total_characters,start_index)\n",
    "\n",
    "                    new_start_time = start_time + total_duration/total_characters*start_index\n",
    "                    new_end_time = start_time + total_duration/total_characters*end_index\n",
    "\n",
    "                    new_row = {\n",
    "                        'Text': line,\n",
    "                        'Narrator': narrator,\n",
    "                        'Timecode Range': frames_to_timecode(new_start_time) +\" - \" + frames_to_timecode(new_end_time),\n",
    "                        'FilePath': row['FILEPATH']\n",
    "                        }\n",
    "            else:\n",
    "                ##if no match is found, the line is added anyway but with no timecode or filepath\n",
    "                new_row = {\n",
    "                        'Text': line,\n",
    "                        'Narrator': narrator,\n",
    "                        'Timecode Range': None,\n",
    "                        'FilePath': None\n",
    "                    }\n",
    "            matched_rows.append(new_row)\n",
    "\n",
    "    matched_df = pd.DataFrame.from_records(matched_rows)\n",
    "    return matched_df\n",
    "\n",
    "# match_script_to_csv(script_path).to_csv(script_csv_output_path) #test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Generate subtitles from coded script csv </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertTimecodeToSubFormat(timecode):\n",
    "    timecodeSplit=timecode.split(\":\")\n",
    "    timecodeSplit[3]=str(int(int(timecodeSplit[3])/24*1000))\n",
    "    timecodeNew = \":\".join(timecodeSplit[:3])+\",\"+timecodeSplit[3]\n",
    "    return timecodeNew\n",
    "\n",
    "#convertTimecodeToSubFormat(\"01:02:03:04\")   #test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "\n",
    "# the generate_subtitles() function reads a script CSV file, performs time calculations\n",
    "# and formatting, and writes the generated subtitles to a final subtitle file in the SRT format. if no time is found\n",
    "# it adds 5 seconds to the last time.\n",
    "\n",
    "def generate_subtitles(script_csv_file,final_subtitle_file):\n",
    "\n",
    "    with open(final_subtitle_file, 'w') as srt_file:\n",
    "        script_csv=pd.read_csv(script_csv_file)\n",
    "        counter = 1\n",
    "        last_time = 0\n",
    "        for index,row in script_csv.iterrows():\n",
    "            srt_file.write(str(counter) + '\\n')\n",
    "            \n",
    "            new_start_frames=last_time\n",
    "\n",
    "            if not pd.isna(row[\"Timecode Range\"]):  # If Timecode Range is not empty\n",
    "\n",
    "                start_time, end_time = [s.strip() for s in row[\"Timecode Range\"].split('-')]\n",
    "                start_frames=timecode_to_frames(start_time)\n",
    "                end_frames=timecode_to_frames(end_time)\n",
    "\n",
    "                new_end_frames= last_time+ end_frames - start_frames\n",
    "                last_time=new_end_frames\n",
    "\n",
    "            else:\n",
    "                new_end_frames = new_start_frames+120\n",
    "                last_time=new_end_frames\n",
    "\n",
    "            srt_file.write(convertTimecodeToSubFormat(frames_to_timecode(new_start_frames)) +' --> ' + convertTimecodeToSubFormat(frames_to_timecode(new_end_frames)) + '\\n')\n",
    "            \n",
    "            srt_file.write(clean_text(row[\"Text\"]) + '\\n\\n')  # Cleaned text\n",
    "            counter += 1\n",
    "\n",
    "generate_subtitles(script_csv_output_path,final_subtitle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converts Time to Frames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78662"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_time_to_frames(time, rate):\n",
    "    # print('Time', time, 'Rate', rate)\n",
    "    parts = time.split(\":\")\n",
    "    hours = int(parts[0])\n",
    "    minutes = int(parts[1])\n",
    "    seconds = int(parts[2])\n",
    "    frames = int(parts[3])\n",
    "    \n",
    "    # Calculate the total duration in frames\n",
    "    total_frames = (\n",
    "        hours * 3600 * rate +  # Convert hours to frames\n",
    "        minutes * 60 * rate +  # Convert minutes to frames\n",
    "        seconds * rate +  # Convert seconds to frames\n",
    "        frames\n",
    "    )\n",
    "    \n",
    "    return total_frames\n",
    "\n",
    "convert_time_to_frames('00:54:36:38', 24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate New ids for the each Clip item in seperate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'clipitem-f29fcb19004d4b8886803a67b6a1f4b0'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_unique_id():\n",
    "    unique_id = f\"clipitem-{uuid.uuid4().hex}\"\n",
    "    return unique_id\n",
    "\n",
    "generate_unique_id()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the id of clips in specific XML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_xml_ids(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    print('Assigning unique IDs to clipitem elements...')\n",
    "\n",
    "    # Generate unique IDs for clipitem elements\n",
    "      # Store the mapping of old IDs to new unique IDs\n",
    "    for clip_item in root.findall('.//clipitem'):  # Adjust the XPath expression based on the actual location of clipitem elements\n",
    "        current_id = clip_item.attrib['id']\n",
    "        unique_id = generate_unique_id()\n",
    "        id_mapping[current_id] = unique_id\n",
    "        clip_item.attrib['id'] = unique_id\n",
    "\n",
    "    \n",
    "        # Update the references in the links section\n",
    "    for link in root.findall('.//link'):\n",
    "        linkclipref = link.find('linkclipref')\n",
    "        if linkclipref is not None and linkclipref.text in id_mapping:\n",
    "            linkclipref.text = id_mapping[linkclipref.text]\n",
    "    print(id_mapping)\n",
    "\n",
    "    # Save the modified XML file\n",
    "    tree.write(xml_file, encoding=\"utf-8\")\n",
    "\n",
    "# update_xml_ids(xml_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract time in  start and end time format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Time 00:00:00:00 End Time 00:23:00:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('00:00:00:00', '00:23:00:00')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_timecode(timecode_range):\n",
    "    start_time, end_time = timecode_range.split(\" - \")\n",
    "    start_time = start_time.strip().replace(\" \", \"\")\n",
    "    end_time = end_time.strip().replace(\" \", \"\")\n",
    "    print('Start Time',start_time,'End Time', end_time)\n",
    "    return start_time, end_time\n",
    "\n",
    "extract_timecode(\"00:00:00:00 - 00:23:00:00\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert frame to tick number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_to_ticks(frame_number, frame_rate):\n",
    "    total_ticks_in_a_second = 254016000000\n",
    "    tick_value = int((frame_number * total_ticks_in_a_second) / frame_rate)\n",
    "    return tick_value\n",
    "\n",
    "# frame_to_ticks(24, 24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract sequences through xml file and extract the clips that match with the start and end time using frame comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sequence_info(\n",
    "    xml_file, start_time, end_time, extract_method=\"project_timecode\"\n",
    "):\n",
    "    global sequence_start, sequence_end\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Extract sequence information\n",
    "    sequence = root.find(\"sequence\")\n",
    "    sequence_info = {\n",
    "        \"duration\": int(sequence.find(\"duration\").text),\n",
    "        \"rate\": {\n",
    "            \"timebase\": int(sequence.find(\"rate/timebase\").text),\n",
    "            \"ntsc\": sequence.find(\"rate/ntsc\").text == \"TRUE\",\n",
    "        },\n",
    "    }\n",
    "    sequence_rate = sequence_info[\"rate\"][\"timebase\"]\n",
    "\n",
    "    # Convert start and end times to frames\n",
    "    start_frame = convert_time_to_frames(start_time, 24)\n",
    "    end_frame = convert_time_to_frames(end_time, 24)\n",
    "    proTickIn = frame_to_ticks(start_frame, 24)\n",
    "    proTickOut = frame_to_ticks(end_frame, 24)\n",
    "\n",
    "    total_clip_frames = end_frame - start_frame\n",
    "    total_clip_proticks = proTickOut - proTickIn\n",
    "\n",
    "    # print('Start and End Frame',start_frame ,end_frame)\n",
    "    # print(sequence_rate,'sequence_rate')\n",
    "\n",
    "    # Extract video clip information\n",
    "    video_clips = []\n",
    "    for track_index, track in enumerate(\n",
    "        root.findall(\".//video/track\")\n",
    "    ):  # Iterate over all tracks within the <video> tag\n",
    "        # track_idx = 0\n",
    "        track_targeted = track.attrib[\"MZ.TrackTargeted\"]\n",
    "        for clip_item in track.findall(\n",
    "            \"clipitem\"\n",
    "        ):  # Only consider clip items within the <video> tag\n",
    "            links = clip_item.findall(\"link\")\n",
    "            track_idx = [\n",
    "                int(link.find(\"trackindex\").text)\n",
    "                for link in clip_item.findall(\"link\")\n",
    "                if link.find(\"mediatype\").text == \"video\"\n",
    "            ]\n",
    "            print(\"Track Index\", track_idx)\n",
    "            print(\"Clip ID\", clip_item.attrib[\"id\"])\n",
    "\n",
    "            clip_info = {\n",
    "                \"id\": clip_item.attrib[\"id\"],  # Get the clip ID\n",
    "                \"name\": clip_item.find(\"name\").text,\n",
    "                \"duration\": int(clip_item.find(\"duration\").text),\n",
    "                \"rate\": {\n",
    "                    \"timebase\": int(clip_item.find(\"rate/timebase\").text),\n",
    "                    \"ntsc\": clip_item.find(\"rate/ntsc\").text == \"TRUE\",\n",
    "                },\n",
    "                \"in\": int(clip_item.find(\"in\").text),\n",
    "                \"out\": int(clip_item.find(\"out\").text),\n",
    "                \"start\": int(clip_item.find(\"start\").text),\n",
    "                \"end\": int(clip_item.find(\"end\").text),\n",
    "                \"track_index\": track_idx[0],\n",
    "                \"MZ_TrackTargeted\": track_targeted,\n",
    "                \"links\": [],  # Initialize an empty list to store links,\n",
    "                \"video_clip_element\": None,  # Store the clip item element for later use\n",
    "                \"linked_audio_clip_elements_list\": [],  # Initialize an empty list to store linked clip items\n",
    "            }\n",
    "\n",
    "            if extract_method == \"video_timecode\":\n",
    "                clip_comparison = (\n",
    "                    clip_info[\"in\"] <= start_frame <= clip_info[\"out\"]\n",
    "                ) or (clip_info[\"in\"] <= end_frame <= clip_info[\"out\"])\n",
    "            else:\n",
    "                clip_comparison = (\n",
    "                    clip_info[\"start\"] <= start_frame <= clip_info[\"end\"]\n",
    "                ) or (clip_info[\"start\"] <= end_frame <= clip_info[\"end\"])\n",
    "\n",
    "            \n",
    "\n",
    "            for link in links:\n",
    "                link_info = {\n",
    "                    \"linkclipref\": link.find(\"linkclipref\").text,\n",
    "                    \"mediatype\": link.find(\"mediatype\").text,\n",
    "                    \"trackindex\": int(link.find(\"trackindex\").text),\n",
    "                    \"clipindex\": int(link.find(\"clipindex\").text),\n",
    "                }\n",
    "                if link.find(\"groupindex\") is not None:\n",
    "                    link_info[\"groupindex\"] = int(link.find(\"groupindex\").text)\n",
    "                clip_info[\"links\"].append(link_info)\n",
    "                if link.find(\"mediatype\").text == \"audio\":\n",
    "                    audio_clip_items = root.findall(\".//audio//clipitem\")\n",
    "                    for audio_clip_item in audio_clip_items:\n",
    "                        if (\n",
    "                            audio_clip_item.attrib[\"id\"]\n",
    "                            == link.find(\"linkclipref\").text\n",
    "                        ):\n",
    "                            audio_clip_item.find(\"in\").text = str(start_frame)\n",
    "                            audio_clip_item.find(\"out\").text = (\n",
    "                                str(end_frame)\n",
    "                                if extract_method == \"video_timecode\"\n",
    "                                else str(start_frame + total_clip_frames)\n",
    "                            )\n",
    "                            audio_clip_item.find(\"start\").text = str(sequence_start)\n",
    "                            audio_clip_item.find(\"end\").text = str(sequence_end)\n",
    "                            audio_clip_item.find(\"pproTicksIn\").text = str(proTickIn)\n",
    "                            audio_clip_item.find(\"pproTicksOut\").text = (\n",
    "                                str(proTickOut)\n",
    "                                if extract_method == \"video_timecode\"\n",
    "                                else str(proTickIn + total_clip_proticks)\n",
    "                            )\n",
    "                            clip_info[\"linked_audio_clip_elements_list\"].append(\n",
    "                                {\n",
    "                                    \"audio_clip_item\": audio_clip_item,\n",
    "                                    \"trackindex\": int(link.find(\"trackindex\").text),\n",
    "                                    \"sourceindex\": int(\n",
    "                                        audio_clip_item.find(\n",
    "                                            \".//sourcetrack/trackindex\"\n",
    "                                        ).text\n",
    "                                    ),\n",
    "                                }\n",
    "                            )\n",
    "\n",
    "            # Check if the clip's in or out frame falls within the given start and end frames\n",
    "            # print('Clip Frame Inside file Found: ',clip_info['in'] <= start_frame <= clip_info['out'])\n",
    "            print(\n",
    "                \"Clip Frame Inside file Found: \",\n",
    "                clip_info[\"start\"] <= start_frame <= clip_info[\"end\"]\n",
    "                or clip_info[\"start\"] <= end_frame <= clip_info[\"end\"],\n",
    "            )\n",
    "            print(\"clip_comparison\", clip_comparison)\n",
    "            print(\"In - Matching - Out\")\n",
    "            # print(clip_info['in'],start_frame,clip_info['out'])\n",
    "            print(clip_info[\"start\"], start_frame, clip_info[\"end\"])\n",
    "            print(clip_info[\"start\"], end_frame, clip_info[\"end\"])\n",
    "            if clip_comparison:\n",
    "                clip_item.find(\"in\").text = str(start_frame)\n",
    "                clip_item.find(\"out\").text = (\n",
    "                    str(end_frame)\n",
    "                    if extract_method == \"video_timecode\"\n",
    "                    else str(start_frame + total_clip_frames)\n",
    "                )\n",
    "                clip_item.find(\"start\").text = str(sequence_start)\n",
    "                clip_item.find(\"end\").text = str(sequence_end)\n",
    "                clip_item.find(\"pproTicksIn\").text = str(proTickIn)\n",
    "                clip_item.find(\"pproTicksOut\").text = (\n",
    "                    str(proTickOut)\n",
    "                    if extract_method == \"video_timecode\"\n",
    "                    else str(proTickIn + total_clip_proticks)\n",
    "                )\n",
    "                clip_info[\"video_clip_element\"] = clip_item\n",
    "                video_clips.append(clip_info)\n",
    "                print(\"Next Sequence Start\", sequence_start)\n",
    "                print(\"Next Sequence End\", sequence_end)\n",
    "\n",
    "    # print(clip_info, start_frame, end_frame)\n",
    "\n",
    "    # Create result dictionary\n",
    "    result = {\"sequence_info\": sequence_info, \"video_clips\": video_clips}\n",
    "    # print('Result',result)\n",
    "\n",
    "    if not video_clips:  # Check if video_clips list is empty\n",
    "        return None\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions go through all the xml files and call the  extract clips function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_xml_files(xml_folder, start_time, end_time, narrator_name):\n",
    "    global xml_file_assigned,final_clip_list, sequence_start, sequence_end\n",
    "    for filename in os.listdir(xml_folder):\n",
    "        if filename.endswith(\".xml\") and narrator_name.lower() in filename.lower():\n",
    "            # print(filename,narrator_name)\n",
    "            xml_file = os.path.join(xml_folder, filename)\n",
    "            if xml_file not in xml_file_assigned:\n",
    "                update_xml_ids(xml_file)\n",
    "                xml_file_assigned.append(xml_file)\n",
    "            matched_clips = extract_sequence_info(xml_file, start_time, end_time,extract_method)\n",
    "            if matched_clips:\n",
    "                start_frame = convert_time_to_frames(start_time, 24)\n",
    "                end_frame = convert_time_to_frames(end_time, 24)\n",
    "                sequence_start = sequence_end + 120\n",
    "                sequence_end = sequence_start + (end_frame - start_frame)\n",
    "            final_clip_list.append(matched_clips)\n",
    "\n",
    "\n",
    "\n",
    "def process_csv_file(csv_file):\n",
    "    xml_folder = \"../Interview XML/\"\n",
    "    with open(csv_file, \"r\") as file:\n",
    "        csv_reader = csv.DictReader(file)\n",
    "        for row in csv_reader:\n",
    "            timecode_range = row[\"Timecode Range\"]\n",
    "            if timecode_range:\n",
    "                start_time, end_time = extract_timecode(timecode_range)\n",
    "                narrator_name = row[\"Narrator\"]\n",
    "                print('Narrator Name:' ,narrator_name)\n",
    "                process_xml_files(xml_folder, start_time, end_time, narrator_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Create Basic XML Structure </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_xml(xml_name):\n",
    "    \n",
    "    # Create the root element\n",
    "    root = ET.Element(\"xmeml\", version=\"4\")\n",
    "    \n",
    "    # Create the sequence element with attributes\n",
    "    sequence = ET.SubElement(root, \"sequence\", id=\"sequence-2\", TL_SQAudioVisibleBase=\"0\", TL_SQVideoVisibleBase=\"0\",\n",
    "                             TL_SQVisibleBaseTime=\"0\", TL_SQAVDividerPosition=\"0.5\", TL_SQHideShyTracks=\"0\",\n",
    "                             TL_SQHeaderWidth=\"236\", TL_SQDataTrackViewControlState=\"0\",\n",
    "                             Monitor_ProgramZoomOut=\"340011984312000\", Monitor_ProgramZoomIn=\"0\",\n",
    "                             TL_SQTimePerPixel=\"1.6034289012958367\", MZ_EditLine=\"333083126376000\",\n",
    "                             MZ_Sequence_PreviewFrameSizeHeight=\"1080\", MZ_Sequence_PreviewFrameSizeWidth=\"1920\",\n",
    "                             MZ_Sequence_AudioTimeDisplayFormat=\"200\", MZ_Sequence_PreviewUseMaxRenderQuality=\"false\",\n",
    "                             MZ_Sequence_PreviewUseMaxBitDepth=\"false\", MZ_Sequence_VideoTimeDisplayFormat=\"110\",\n",
    "                             MZ_WorkOutPoint=\"15235011792000\", MZ_WorkInPoint=\"0\", MZ_ZeroPoint=\"0\", explodedTracks=\"true\")\n",
    "    \n",
    "    # Add the uuid element\n",
    "    uuid = ET.SubElement(sequence, \"uuid\")\n",
    "    uuid.text = \"50e61931-251f-4069-8193-a3fbad7f93ff\"\n",
    "    \n",
    "    # Add the duration element\n",
    "    duration = ET.SubElement(sequence, \"duration\")\n",
    "    duration.text = \"31533\"\n",
    "    \n",
    "    # Add the rate element with nested timebase and ntsc elements\n",
    "    rate = ET.SubElement(sequence, \"rate\")\n",
    "    timebase = ET.SubElement(rate, \"timebase\")\n",
    "    timebase.text = \"24\"\n",
    "    ntsc = ET.SubElement(rate, \"ntsc\")\n",
    "    ntsc.text = \"TRUE\"\n",
    "    \n",
    "    # Add the name element\n",
    "    name_element = ET.SubElement(sequence, \"name\")\n",
    "    name_element.text = xml_name\n",
    "    \n",
    "    # Add the media element with nested video and audio elements\n",
    "    media = ET.SubElement(sequence, \"media\")\n",
    "\n",
    "    \n",
    " \n",
    "    \n",
    "    # Add the timecode element with nested rate, string, frame, and displayformat elements\n",
    "    timecode = ET.SubElement(sequence, \"timecode\")\n",
    "    rate = ET.SubElement(timecode, \"rate\")\n",
    "    timebase = ET.SubElement(rate, \"timebase\")\n",
    "    timebase.text = \"24\"\n",
    "    ntsc = ET.SubElement(rate, \"ntsc\")\n",
    "    ntsc.text = \"TRUE\"\n",
    "    string = ET.SubElement(timecode, \"string\")\n",
    "    string.text = \"00:00:00:00\"\n",
    "    frame = ET.SubElement(timecode, \"frame\")\n",
    "    frame.text = \"0\"\n",
    "    displayformat = ET.SubElement(timecode, \"displayformat\")\n",
    "    displayformat.text = \"NDF\"\n",
    "    \n",
    "    # Add the labels element with nested label2 element\n",
    "    labels = ET.SubElement(sequence, \"labels\")\n",
    "    label2 = ET.SubElement(labels, \"label2\")\n",
    "    label2.text = \"Forest\"\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    # Create the ElementTree object with the root element\n",
    "    tree = ET.ElementTree(root)\n",
    "    \n",
    "    # Generate a random Idd\n",
    "    idd = str(random.randint(1, 1000))\n",
    "    \n",
    "    # Save the XML to a file\n",
    "    filename = f\"{xml_name.replace(' ', '_')}-{idd}.xml\"\n",
    "    tree.write(f\"../xml exports/{filename}\", encoding=\"utf-8\", xml_declaration=True)\n",
    "    print(f\"XML saved to {filename}\")\n",
    "\n",
    "    return filename \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append Video to XML File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_video_to_xml(file_name, xml_json_data):\n",
    "    print(f\"Adding Video Tracks to {file_name}\")\n",
    "    print(xml_json_data)\n",
    "    # Parse the XML data\n",
    "    tree = ET.parse(file_name)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Find the media element\n",
    "    media = root.find('.//media')\n",
    "\n",
    "    # Append the provided code inside the media element\n",
    "    video = ET.SubElement(media, \"video\")\n",
    "\n",
    "    # Add the format element with nested samplecharacteristics element\n",
    "    format_ = ET.SubElement(video, \"format\")\n",
    "    samplecharacteristics = ET.SubElement(format_, \"samplecharacteristics\")\n",
    "    \n",
    "    # Add the rate element with nested timebase and ntsc elements inside samplecharacteristics\n",
    "    rate = ET.SubElement(samplecharacteristics, \"rate\")\n",
    "    timebase = ET.SubElement(rate, \"timebase\")\n",
    "    timebase.text = \"24\"\n",
    "    ntsc = ET.SubElement(rate, \"ntsc\")\n",
    "    ntsc.text = \"TRUE\"\n",
    "    \n",
    "    # Add the codec element with nested name and appspecificdata elements\n",
    "    codec = ET.SubElement(samplecharacteristics, \"codec\")\n",
    "    name = ET.SubElement(codec, \"name\")\n",
    "    name.text = \"Apple ProRes 422\"\n",
    "    appspecificdata = ET.SubElement(codec, \"appspecificdata\")\n",
    "    \n",
    "    # Add the appname, appmanufacturer, and appversion elements inside appspecificdata\n",
    "    appname = ET.SubElement(appspecificdata, \"appname\")\n",
    "    appname.text = \"Final Cut Pro\"\n",
    "    appmanufacturer = ET.SubElement(appspecificdata, \"appmanufacturer\")\n",
    "    appmanufacturer.text = \"Apple Inc.\"\n",
    "    appversion = ET.SubElement(appspecificdata, \"appversion\")\n",
    "    appversion.text = \"7.0\"\n",
    "    \n",
    "    # Add the data element with nested qtcodec element inside appspecificdata\n",
    "    data = ET.SubElement(appspecificdata, \"data\")\n",
    "    qtcodec = ET.SubElement(data, \"qtcodec\")\n",
    "    codecname = ET.SubElement(qtcodec, \"codecname\")\n",
    "    codecname.text = \"Apple ProRes 422\"\n",
    "    codectypename = ET.SubElement(qtcodec, \"codectypename\")\n",
    "    codectypename.text = \"Apple ProRes 422\"\n",
    "    codectypecode = ET.SubElement(qtcodec, \"codectypecode\")\n",
    "    codectypecode.text = \"apcn\"\n",
    "    codecvendorcode = ET.SubElement(qtcodec, \"codecvendorcode\")\n",
    "    codecvendorcode.text = \"appl\"\n",
    "    spatialquality = ET.SubElement(qtcodec, \"spatialquality\")\n",
    "    spatialquality.text = \"1024\"\n",
    "    temporalquality = ET.SubElement(qtcodec, \"temporalquality\")\n",
    "    temporalquality.text = \"0\"\n",
    "    keyframerate = ET.SubElement(qtcodec, \"keyframerate\")\n",
    "    keyframerate.text = \"0\"\n",
    "    datarate = ET.SubElement(qtcodec, \"datarate\")\n",
    "    datarate.text = \"0\"\n",
    "    \n",
    "    # Add the width, height, anamorphic, pixelaspectratio, fielddominance, and colordepth elements inside samplecharacteristics\n",
    "    width = ET.SubElement(samplecharacteristics, \"width\")\n",
    "    width.text = \"1920\"\n",
    "    height = ET.SubElement(samplecharacteristics, \"height\")\n",
    "    height.text = \"1080\"\n",
    "    anamorphic = ET.SubElement(samplecharacteristics, \"anamorphic\")\n",
    "    anamorphic.text = \"FALSE\"\n",
    "    pixelaspectratio = ET.SubElement(samplecharacteristics, \"pixelaspectratio\")\n",
    "    pixelaspectratio.text = \"square\"\n",
    "    fielddominance = ET.SubElement(samplecharacteristics, \"fielddominance\")\n",
    "    fielddominance.text = \"none\"\n",
    "    colordepth = ET.SubElement(samplecharacteristics, \"colordepth\")\n",
    "    colordepth.text = \"24\"\n",
    "    video_tracks = []\n",
    "    # Get the track elements\n",
    "    for clip in xml_json_data:\n",
    "        for video_clip in clip[\"video_clips\"]:\n",
    "            if video_clip[\"track_index\"] not in video_tracks:\n",
    "                video_tracks.append({'MZ_TrackTargeted':video_clip[\"MZ_TrackTargeted\"],'track_index':video_clip[\"track_index\"]})\n",
    "\n",
    "    \n",
    "    # print(video_tracks,\"total video tracks\")\n",
    "    appended_video_clip=[]\n",
    "\n",
    "    # Create video track elements and append video clips\n",
    "    for track in video_tracks:\n",
    "        video_track = ET.SubElement(video, \"track\", TL_SQTrackShy=\"0\", TL_SQTrackExpandedHeight=\"25\",\n",
    "                                    TL_SQTrackExpanded=\"0\", MZ_TrackTargeted=f\"{track['MZ_TrackTargeted']}\")\n",
    "        for clip in xml_json_data:\n",
    "            for video_clip in clip[\"video_clips\"]:\n",
    "                if int(track['track_index']) == int(video_clip[\"track_index\"]) and video_clip[\"id\"] not in appended_video_clip:\n",
    "                    video_track.append(copy.deepcopy(video_clip[\"video_clip_element\"]))\n",
    "                    appended_video_clip.append(video_clip[\"id\"])\n",
    "\n",
    "\n",
    "    # final_track = ET.SubElement(video, \"track\", TL_SQTrackShy=\"0\", TL_SQTrackExpandedHeight=\"25\",\n",
    "    #                             TL_SQTrackExpanded=\"0\", MZ_TrackTargeted=\"0\")\n",
    "\n",
    "    # # Add the enabled and locked elements\n",
    "    # enabled = ET.SubElement(final_track, \"enabled\")\n",
    "    # enabled.text = \"TRUE\"\n",
    "    # locked = ET.SubElement(final_track, \"locked\")\n",
    "    # locked.text = \"FALSE\"\n",
    "\n",
    "    # Save the modified XML to a new file\n",
    "    modified_tree = ET.ElementTree(root)\n",
    "    modified_tree.write(file_name)    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append Audio to XML File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def append_audio_to_xml(file_name, xml_json_data):\n",
    "    print(f\"Adding Audio Tracks to {file_name}\")\n",
    "    # Parse the XML data\n",
    "    audio_tracks = []\n",
    "    track_index = []\n",
    "    source_index = []\n",
    "    for clip in xml_json_data:\n",
    "        for video_clip in clip[\"video_clips\"]:\n",
    "            audio_track_indexes = video_clip[\"linked_audio_clip_elements_list\"]\n",
    "            for audio_track_index in audio_track_indexes:\n",
    "                if audio_track_index['trackindex'] not in track_index:\n",
    "                    track_index.append(audio_track_index['trackindex'])\n",
    "                    source_index.append(audio_track_index['sourceindex'])\n",
    "                    audio_tracks.append({'track_index': audio_track_index['trackindex'], 'source_index': audio_track_index['sourceindex']})\n",
    "\n",
    "    audio_track_count = len(set(source_index))\n",
    "\n",
    "    # print('audio_tracks',audio_tracks)\n",
    "    # print('track_index',track_index)\n",
    "    # print('source_index',source_index)\n",
    "    # print('audio_track_count',audio_track_count)\n",
    "    \n",
    "    tree = ET.parse(file_name)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Find the media element\n",
    "    media = root.find('.//media')\n",
    "\n",
    "    # Add the audio element inside media\n",
    "    audio = ET.SubElement(media, \"audio\")\n",
    "\n",
    "    # constant stuff\n",
    "\n",
    "    # Create subelements and append them to the audio element\n",
    "    num_output_channels = ET.SubElement(audio, 'numOutputChannels')\n",
    "    num_output_channels.text = '2'\n",
    "\n",
    "    format_element = ET.SubElement(audio, 'format')\n",
    "    sample_characteristics = ET.SubElement(format_element, 'samplecharacteristics')\n",
    "    depth = ET.SubElement(sample_characteristics, 'depth')\n",
    "    depth.text = '16'\n",
    "    sample_rate = ET.SubElement(sample_characteristics, 'samplerate')\n",
    "    sample_rate.text = '48000'\n",
    "\n",
    "    outputs = ET.SubElement(audio, 'outputs')\n",
    "\n",
    "    group_1 = ET.SubElement(outputs, 'group')\n",
    "    index_1 = ET.SubElement(group_1, 'index')\n",
    "    index_1.text = '1'\n",
    "    num_channels_1 = ET.SubElement(group_1, 'numchannels')\n",
    "    num_channels_1.text = '1'\n",
    "    downmix_1 = ET.SubElement(group_1, 'downmix')\n",
    "    downmix_1.text = '0'\n",
    "    channel_1 = ET.SubElement(group_1, 'channel')\n",
    "    channel_index_1 = ET.SubElement(channel_1, 'index')\n",
    "    channel_index_1.text = '1'\n",
    "\n",
    "    group_2 = ET.SubElement(outputs, 'group')\n",
    "    index_2 = ET.SubElement(group_2, 'index')\n",
    "    index_2.text = '2'\n",
    "    num_channels_2 = ET.SubElement(group_2, 'numchannels')\n",
    "    num_channels_2.text = '1'\n",
    "    downmix_2 = ET.SubElement(group_2, 'downmix')\n",
    "    downmix_2.text = '0'\n",
    "    channel_2 = ET.SubElement(group_2, 'channel')\n",
    "    channel_index_2 = ET.SubElement(channel_2, 'index')\n",
    "    channel_index_2.text = '2'\n",
    "\n",
    "     # Create audio track elements and append audio clips\n",
    "    for audio_track_index in audio_tracks:\n",
    "        audio_track = ET.SubElement(audio, \"track\", TL_SQTrackAudioKeyframeStyle=\"0\", TL_SQTrackShy=\"0\",\n",
    "                                    TL_SQTrackExpandedHeight=\"25\", TL_SQTrackExpanded=\"0\",\n",
    "                                    MZ_TrackTargeted=\"1\", PannerCurrentValue=\"0.5\", PannerIsInverted=\"true\",\n",
    "                                    PannerStartKeyframe=\"-91445760000000000,0.5,0,0,0,0,0,0\", PannerName=\"Balance\",\n",
    "                                    currentExplodedTrackIndex=f\"{audio_track_index['source_index']-1}\", totalExplodedTrackCount=f\"{audio_track_count}\",\n",
    "                                    premiereTrackType=\"Stereo\")\n",
    "\n",
    "        for clip in xml_json_data:\n",
    "            for video_clip in clip[\"video_clips\"]:\n",
    "                audio_clip_elements = video_clip[\"linked_audio_clip_elements_list\"]\n",
    "                \n",
    "                for audio_clip in audio_clip_elements:\n",
    "                    if audio_track_index['source_index'] == audio_clip['sourceindex'] and audio_track_index['track_index'] == audio_clip['trackindex']:\n",
    "                        audio_track.append(copy.deepcopy(audio_clip['audio_clip_item']))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Save the modified XML to a new file\n",
    "    modified_tree = ET.ElementTree(root)\n",
    "    modified_tree.write(file_name)\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracts the given clips from the xml files and saves them in a seperate xml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the run_extraction() function serves as the main entry point for running the extraction process. \n",
    "# It calls functions to process a CSV file, filter the resulting list of clips, and create an XML file based on the filtered clips.\n",
    "\n",
    "def run_extraction(script_csv_file,exported_xml_project_name):\n",
    "    global final_clip_list    \n",
    "    process_csv_file(script_csv_file)\n",
    "    final_clip_list = [item for item in final_clip_list if item is not None]\n",
    "    print(final_clip_list)\n",
    "    filename = create_xml(exported_xml_project_name)\n",
    "    append_video_to_xml(f\"../xml exports/{filename}\", final_clip_list)\n",
    "    append_audio_to_xml(f\"../xml exports/{filename}\", final_clip_list)\n",
    "# print(final_clip_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code Run Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Time 00:00:00:00 End Time 00:00:05:00\n",
      "Narrator Name: fnite\n",
      "Assigning unique IDs to clipitem elements...\n",
      "{'clipitem-fefb4012dd9c4e94a3045e01d845a659': 'clipitem-00030874f68d42cdb07780af21cc8edc', 'clipitem-f48de77ed3b248ef88aa6a65641d740e': 'clipitem-d4d7f0c30e2f4046896b4900894f56cb', 'clipitem-62dd6f40bbf9453491e6088074bbabb2': 'clipitem-1a332175a6e5425c8532a87d7ea817b6', 'clipitem-d75b4adebb5a45f4aed709dd7cdd6c70': 'clipitem-4c475e976c724a98bf50ead147399f51', 'clipitem-599eef6eb33d42a1a115abad2d1885f6': 'clipitem-2bc09267863244e99e1714acb7d12f47', 'clipitem-4788b815fa6549959e811495b72d1005': 'clipitem-5b681461a3714572a24b58dfea5c3c60', 'clipitem-1272215d18ce43fa9836b45c56aee693': 'clipitem-f85591ca371a446b84636bad72adc637', 'clipitem-f8cced905d2744ec9f17d4f6b9b3729c': 'clipitem-d3b52a92b6504357a9813e8619138862', 'clipitem-73c1278d631347c5b35ef87ee9a78a4f': 'clipitem-182dfb6ae7d7412f83e6781a45fd6193', 'clipitem-df39b62aeb28442cb7e3288600088a12': 'clipitem-db4c5f045fdc42acab5f2490dadc0739', 'clipitem-15b4a6892ad44c8583d86bad3633c6f1': 'clipitem-84ca21d206b14d88b566e03944a20497', 'clipitem-446c2a3cb98246398d10d582d81d528d': 'clipitem-11612fff618344e7bb1aa4ec62855315'}\n",
      "Track Index [1]\n",
      "Clip ID clipitem-00030874f68d42cdb07780af21cc8edc\n",
      "Clip Frame Inside file Found:  True\n",
      "clip_comparison True\n",
      "In - Matching - Out\n",
      "0 0 729\n",
      "0 120 729\n",
      "Next Sequence Start 0\n",
      "Next Sequence End 0\n",
      "Track Index [1]\n",
      "Clip ID clipitem-d4d7f0c30e2f4046896b4900894f56cb\n",
      "Clip Frame Inside file Found:  False\n",
      "clip_comparison False\n",
      "In - Matching - Out\n",
      "3052 0 3771\n",
      "3052 120 3771\n",
      "Track Index [2]\n",
      "Clip ID clipitem-1a332175a6e5425c8532a87d7ea817b6\n",
      "Clip Frame Inside file Found:  False\n",
      "clip_comparison False\n",
      "In - Matching - Out\n",
      "1615 0 2334\n",
      "1615 120 2334\n",
      "Track Index [2]\n",
      "Clip ID clipitem-4c475e976c724a98bf50ead147399f51\n",
      "Clip Frame Inside file Found:  False\n",
      "clip_comparison False\n",
      "In - Matching - Out\n",
      "3052 0 3771\n",
      "3052 120 3771\n",
      "Start Time 00:02:07:00 End Time 00:02:14:00\n",
      "Narrator Name: fnite\n",
      "Track Index [1]\n",
      "Clip ID clipitem-00030874f68d42cdb07780af21cc8edc\n",
      "Clip Frame Inside file Found:  False\n",
      "clip_comparison False\n",
      "In - Matching - Out\n",
      "0 3048 729\n",
      "0 3216 729\n",
      "Track Index [1]\n",
      "Clip ID clipitem-d4d7f0c30e2f4046896b4900894f56cb\n",
      "Clip Frame Inside file Found:  True\n",
      "clip_comparison True\n",
      "In - Matching - Out\n",
      "3052 3048 3771\n",
      "3052 3216 3771\n",
      "Next Sequence Start 120\n",
      "Next Sequence End 240\n",
      "Track Index [2]\n",
      "Clip ID clipitem-1a332175a6e5425c8532a87d7ea817b6\n",
      "Clip Frame Inside file Found:  False\n",
      "clip_comparison False\n",
      "In - Matching - Out\n",
      "1615 3048 2334\n",
      "1615 3216 2334\n",
      "Track Index [2]\n",
      "Clip ID clipitem-4c475e976c724a98bf50ead147399f51\n",
      "Clip Frame Inside file Found:  True\n",
      "clip_comparison True\n",
      "In - Matching - Out\n",
      "3052 3048 3771\n",
      "3052 3216 3771\n",
      "Next Sequence Start 120\n",
      "Next Sequence End 240\n",
      "Start Time 00:31:10:00 End Time 00:31:20:00\n",
      "Narrator Name: fnite\n",
      "Track Index [1]\n",
      "Clip ID clipitem-00030874f68d42cdb07780af21cc8edc\n",
      "Clip Frame Inside file Found:  False\n",
      "clip_comparison False\n",
      "In - Matching - Out\n",
      "0 44880 729\n",
      "0 45120 729\n",
      "Track Index [1]\n",
      "Clip ID clipitem-d4d7f0c30e2f4046896b4900894f56cb\n",
      "Clip Frame Inside file Found:  False\n",
      "clip_comparison False\n",
      "In - Matching - Out\n",
      "3052 44880 3771\n",
      "3052 45120 3771\n",
      "Track Index [2]\n",
      "Clip ID clipitem-1a332175a6e5425c8532a87d7ea817b6\n",
      "Clip Frame Inside file Found:  False\n",
      "clip_comparison False\n",
      "In - Matching - Out\n",
      "1615 44880 2334\n",
      "1615 45120 2334\n",
      "Track Index [2]\n",
      "Clip ID clipitem-4c475e976c724a98bf50ead147399f51\n",
      "Clip Frame Inside file Found:  False\n",
      "clip_comparison False\n",
      "In - Matching - Out\n",
      "3052 44880 3771\n",
      "3052 45120 3771\n",
      "[{'sequence_info': {'duration': 3771, 'rate': {'timebase': 24, 'ntsc': False}}, 'video_clips': [{'id': 'clipitem-00030874f68d42cdb07780af21cc8edc', 'name': 'Fortnite  NA PlayStation Cup  PlayStation Esports Game 1.mp4', 'duration': 7687, 'rate': {'timebase': 24, 'ntsc': False}, 'in': 0, 'out': 729, 'start': 0, 'end': 729, 'track_index': 1, 'MZ_TrackTargeted': '1', 'links': [{'linkclipref': 'clipitem-00030874f68d42cdb07780af21cc8edc', 'mediatype': 'video', 'trackindex': 1, 'clipindex': 1}, {'linkclipref': 'clipitem-2bc09267863244e99e1714acb7d12f47', 'mediatype': 'audio', 'trackindex': 1, 'clipindex': 1, 'groupindex': 1}, {'linkclipref': 'clipitem-f85591ca371a446b84636bad72adc637', 'mediatype': 'audio', 'trackindex': 2, 'clipindex': 1, 'groupindex': 1}], 'video_clip_element': <Element 'clipitem' at 0x000001E50E29A980>, 'linked_audio_clip_elements_list': [{'audio_clip_item': <Element 'clipitem' at 0x000001E50E2E4680>, 'trackindex': 1, 'sourceindex': 1}, {'audio_clip_item': <Element 'clipitem' at 0x000001E50E2E67A0>, 'trackindex': 2, 'sourceindex': 2}]}]}, {'sequence_info': {'duration': 3771, 'rate': {'timebase': 24, 'ntsc': False}}, 'video_clips': [{'id': 'clipitem-d4d7f0c30e2f4046896b4900894f56cb', 'name': 'Fortnite  NA PlayStation Cup  PlayStation Esports Game 1.mp4', 'duration': 7687, 'rate': {'timebase': 24, 'ntsc': False}, 'in': 1448, 'out': 2167, 'start': 3052, 'end': 3771, 'track_index': 1, 'MZ_TrackTargeted': '1', 'links': [{'linkclipref': 'clipitem-d4d7f0c30e2f4046896b4900894f56cb', 'mediatype': 'video', 'trackindex': 1, 'clipindex': 2}, {'linkclipref': 'clipitem-5b681461a3714572a24b58dfea5c3c60', 'mediatype': 'audio', 'trackindex': 1, 'clipindex': 2, 'groupindex': 1}, {'linkclipref': 'clipitem-d3b52a92b6504357a9813e8619138862', 'mediatype': 'audio', 'trackindex': 2, 'clipindex': 2, 'groupindex': 1}], 'video_clip_element': <Element 'clipitem' at 0x000001E50E2BE480>, 'linked_audio_clip_elements_list': [{'audio_clip_item': <Element 'clipitem' at 0x000001E50E2E15D0>, 'trackindex': 1, 'sourceindex': 1}, {'audio_clip_item': <Element 'clipitem' at 0x000001E50E2E3560>, 'trackindex': 2, 'sourceindex': 2}]}, {'id': 'clipitem-4c475e976c724a98bf50ead147399f51', 'name': 'Fortnite  NA PlayStation Cup  PlayStation Esports Game 1.mp4', 'duration': 7687, 'rate': {'timebase': 24, 'ntsc': False}, 'in': 729, 'out': 1448, 'start': 3052, 'end': 3771, 'track_index': 2, 'MZ_TrackTargeted': '0', 'links': [{'linkclipref': 'clipitem-4c475e976c724a98bf50ead147399f51', 'mediatype': 'video', 'trackindex': 2, 'clipindex': 2}, {'linkclipref': 'clipitem-db4c5f045fdc42acab5f2490dadc0739', 'mediatype': 'audio', 'trackindex': 3, 'clipindex': 2, 'groupindex': 1}, {'linkclipref': 'clipitem-11612fff618344e7bb1aa4ec62855315', 'mediatype': 'audio', 'trackindex': 4, 'clipindex': 2, 'groupindex': 1}], 'video_clip_element': <Element 'clipitem' at 0x000001E50E298C20>, 'linked_audio_clip_elements_list': [{'audio_clip_item': <Element 'clipitem' at 0x000001E50E2D6C00>, 'trackindex': 3, 'sourceindex': 1}, {'audio_clip_item': <Element 'clipitem' at 0x000001E50E2D4AE0>, 'trackindex': 4, 'sourceindex': 2}]}]}]\n",
      "XML saved to testy-431.xml\n",
      "Adding Video Tracks to ../xml exports/testy-431.xml\n",
      "[{'sequence_info': {'duration': 3771, 'rate': {'timebase': 24, 'ntsc': False}}, 'video_clips': [{'id': 'clipitem-00030874f68d42cdb07780af21cc8edc', 'name': 'Fortnite  NA PlayStation Cup  PlayStation Esports Game 1.mp4', 'duration': 7687, 'rate': {'timebase': 24, 'ntsc': False}, 'in': 0, 'out': 729, 'start': 0, 'end': 729, 'track_index': 1, 'MZ_TrackTargeted': '1', 'links': [{'linkclipref': 'clipitem-00030874f68d42cdb07780af21cc8edc', 'mediatype': 'video', 'trackindex': 1, 'clipindex': 1}, {'linkclipref': 'clipitem-2bc09267863244e99e1714acb7d12f47', 'mediatype': 'audio', 'trackindex': 1, 'clipindex': 1, 'groupindex': 1}, {'linkclipref': 'clipitem-f85591ca371a446b84636bad72adc637', 'mediatype': 'audio', 'trackindex': 2, 'clipindex': 1, 'groupindex': 1}], 'video_clip_element': <Element 'clipitem' at 0x000001E50E29A980>, 'linked_audio_clip_elements_list': [{'audio_clip_item': <Element 'clipitem' at 0x000001E50E2E4680>, 'trackindex': 1, 'sourceindex': 1}, {'audio_clip_item': <Element 'clipitem' at 0x000001E50E2E67A0>, 'trackindex': 2, 'sourceindex': 2}]}]}, {'sequence_info': {'duration': 3771, 'rate': {'timebase': 24, 'ntsc': False}}, 'video_clips': [{'id': 'clipitem-d4d7f0c30e2f4046896b4900894f56cb', 'name': 'Fortnite  NA PlayStation Cup  PlayStation Esports Game 1.mp4', 'duration': 7687, 'rate': {'timebase': 24, 'ntsc': False}, 'in': 1448, 'out': 2167, 'start': 3052, 'end': 3771, 'track_index': 1, 'MZ_TrackTargeted': '1', 'links': [{'linkclipref': 'clipitem-d4d7f0c30e2f4046896b4900894f56cb', 'mediatype': 'video', 'trackindex': 1, 'clipindex': 2}, {'linkclipref': 'clipitem-5b681461a3714572a24b58dfea5c3c60', 'mediatype': 'audio', 'trackindex': 1, 'clipindex': 2, 'groupindex': 1}, {'linkclipref': 'clipitem-d3b52a92b6504357a9813e8619138862', 'mediatype': 'audio', 'trackindex': 2, 'clipindex': 2, 'groupindex': 1}], 'video_clip_element': <Element 'clipitem' at 0x000001E50E2BE480>, 'linked_audio_clip_elements_list': [{'audio_clip_item': <Element 'clipitem' at 0x000001E50E2E15D0>, 'trackindex': 1, 'sourceindex': 1}, {'audio_clip_item': <Element 'clipitem' at 0x000001E50E2E3560>, 'trackindex': 2, 'sourceindex': 2}]}, {'id': 'clipitem-4c475e976c724a98bf50ead147399f51', 'name': 'Fortnite  NA PlayStation Cup  PlayStation Esports Game 1.mp4', 'duration': 7687, 'rate': {'timebase': 24, 'ntsc': False}, 'in': 729, 'out': 1448, 'start': 3052, 'end': 3771, 'track_index': 2, 'MZ_TrackTargeted': '0', 'links': [{'linkclipref': 'clipitem-4c475e976c724a98bf50ead147399f51', 'mediatype': 'video', 'trackindex': 2, 'clipindex': 2}, {'linkclipref': 'clipitem-db4c5f045fdc42acab5f2490dadc0739', 'mediatype': 'audio', 'trackindex': 3, 'clipindex': 2, 'groupindex': 1}, {'linkclipref': 'clipitem-11612fff618344e7bb1aa4ec62855315', 'mediatype': 'audio', 'trackindex': 4, 'clipindex': 2, 'groupindex': 1}], 'video_clip_element': <Element 'clipitem' at 0x000001E50E298C20>, 'linked_audio_clip_elements_list': [{'audio_clip_item': <Element 'clipitem' at 0x000001E50E2D6C00>, 'trackindex': 3, 'sourceindex': 1}, {'audio_clip_item': <Element 'clipitem' at 0x000001E50E2D4AE0>, 'trackindex': 4, 'sourceindex': 2}]}]}]\n",
      "Adding Audio Tracks to ../xml exports/testy-431.xml\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "csv_folder_path = \"../Interview CSV\"\n",
    "\n",
    "script_path = \"../Script/test script.txt\"\n",
    "script_csv_output_path = \"../Script/test.csv\"\n",
    "\n",
    "final_subtitle_file = \"../Script/script.srt\"\n",
    "\n",
    "exported_xml_project_name= 'testy'\n",
    "\n",
    "\n",
    "#convert_txt_to_csv()\n",
    "\n",
    "# match_script_to_csv(script_path)\n",
    "\n",
    "# generate_subtitles(script_csv_output_path,final_subtitle_file)\n",
    "\n",
    "run_extraction(script_csv_output_path,exported_xml_project_name)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
